{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"My Searchable Notebook For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server (http://127.0.0.1:8000). mkdocs build - Build the documentation site. mkdocs -h - Print this help message. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"#my-searchable-notebook","text":"For full documentation visit mkdocs.org .","title":"My Searchable Notebook"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server (http://127.0.0.1:8000). mkdocs build - Build the documentation site. mkdocs -h - Print this help message.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"alacarte/","text":"How to edit program shortcuts in Gnome Shell Method 1: Alacarte menu editor Gnome Shell, unlike KDE Plasma 5, does not have a built-in program shortcut editor. So, if you\u2019re on Gnome and feel the need to create a custom shortcut, or edit an existing one, you won\u2019t be able to with the default Gnome apps. Instead, you must install a third-party application like Alacarte. Installing the Alacarte application on a Linux PC starts by launching a terminal window. Press Ctrl + Shift + T or Ctrl + Alt + T on the keyboard. Then, follow the command-line instructions below that match your Linux OS to get the app working. Ubuntu To install Alacarte on Ubuntu, use the following Apt command. sudo apt install alacarte Debian On Debian, users can install the Alacarte application by entering the Apt-get command below. sudo apt-get install alacarte Arch Linux Arch Linux users can install the Alacarte app with the following Pacman command. sudo pacman -S alacarte Fedora For Fedora Linux, install the Alacarte application by using the Dnf command. sudo dnf install alacarte OpenSUSE Install the Alacarte menu editor application on OpenSUSE Linux with the following Zypper command. sudo zypper install alacarte Edit shortcuts in Gnome Shell with Alacarte To edit existing program shortcuts on the Gnome desktop, open up the Alacarte application. The app can be opened by pressing Win on the keyboard, typing \u201cMain Menu,\u201d and launching the app that shows up in the results. You\u2019ll also be able to launch Alacarte by pressing Alt + F2 on the keyboard, and typing in the command below into the app launcher. alacarte With the Alacarte application open, and ready to use, follow the step-by-step instructions below to learn how to modify program shortcuts on the Gnome Shell desktop. Step 1: In Alacarte, look to the left-hand side of the program. You will see a descending list. The list is called \u201cApplications.\u201d It has various sub-menus, with different program categories to look through. Find a sub-menu, and click on it with the mouse to access the program shortcuts in the menu. Step 2: By clicking on the sub-menu, program shortcuts will appear in the main window. Sort through the different programs listed, and click on the one you\u2019d like to modify with the mouse. Step 3: After selecting a program shortcut with the mouse, it will be highlighted in Alacarte. From there, find the \u201cProperties\u201d button on the right-hand side and select it to access the shortcut settings. Step 4: In the shortcut settings (AKA \u201cLauncher Properties\u201d), you will see a \u201cCommand\u201d box and a \u201cComment\u201d box. Click on either box to modify the program shortcut how you see fit. Step 5: Once your shortcut is modified in Alacarte, click the \u201cOK\u201d button to save the changes. As soon as you do, the shortcut should automatically update. Feel free to repeat this process to modify and tweak as many program shortcuts as you need. Or, to delete program shortcuts, select one in the list, and click the \u201cDelete\u201d button. Method 2: Terminal The Alacarte application is pretty useful for advanced shortcut editing in the GUI. However, if you\u2019re a fan of the terminal, you may want to learn how to edit program shortcuts in Gnome Shell from the command-line. Follow the step-by-step instructions below to learn how. Step 1: Open up a terminal window on the Gnome Shell desktop by pressing Ctrl + Shift + T or Ctrl + Alt + T. Then, use the CD command to move the terminal window into the \u201capplications\u201d directory on your Linux PC. cd /usr/share/applications/ Step 2: To modify program shortcuts in the \u201capplications\u201d folder on your Linux PC, you must elevate the terminal session from the standard user to the root user. Using the sudo -s command, log into the root account. Please note that we are using the sudo -s command, as it allows the user to log into the root account rather than su, as it will keep the terminal in the same directory while elevating the privileges. sudo -s Step 3: Now that the terminal session has root access via the root account, you must use the ls command, and the grep command to filter through all of the program shortcuts in the \u201capplication\u201d directory for the file you\u2019d like to modify. ls | grep \"name-of-app\" Step 4: Take the name of the program file and plug it into the Nano text editor. For example, to edit the Firefox app in Nano, you\u2019d do the following. nano -w firefox.desktop Step 5: Look through the program shortcut and edit what you see fit. For help on editing desktop shortcut files, check out this guide here. It goes over how to create new desktop files, which should help explain what each item in the file does. When done editing, save your changes by pressing Ctrl + O on the keyboard. You can close Nano with Ctrl + X. When the Nano text editor is closed, your shortcut should be updated with the changes made. Source: https://www.addictivetips.com/ubuntu-linux-tips/edit-program-shortcuts-in-gnome-shell/","title":"Alacarte"},{"location":"bacula/","text":"Heading ----------------: ------------- Bacula Services: service bacula-dir start service bacula-fd start service bacula-sd start systemctl enable bacula-dir systemctl enable bacula-fd systemctl enable bacula-sd systemctl status bacula-dir systemctl status bacula-fd systemctl status bacula-sd ss -lt < -(Should show all three services listening) Bacula Cheat Sheet Bacula is a nifty backup software that is network-capable and stores data in the database for faster retrieval in case you need a certain file back. As a big fan of cheat sheets I created this cheat sheet. What\u2019s up? Which files shall be backed up? show filesets I=Included, E=Excluded What\u2019s the server doing? status dir What\u2019s the status of a certain job? status jobid=xx What\u2019s the client doing? status client What\u2019s the streamer doing? status storage Anything new? messages Backing up: Start a backup run \u2026and choose the backup job Label a new tape label \u2026and run mount afterwards Restoring: The common way (a user accidentally removed a file and wants the newest version back from the tapes: Use the restore command. Choose option 5 (Select the most recent backup for a client). Commands: cd ls dir mark markdir unmark unmarkdir lsmark estimate pwd count find can use find * to show the files. done Jobs Last jobs list jobs \u2026or list jobid=xx for a specific job Statistics about last jobs list jobtotal Which files were backed up? list files jobid=xx Job status Status means\u2026 T Terminated normally C Created but not yet running R Running B Blocked E Terminated in Error e Non-fatal error f Fatal error D Verify Differences A Canceled by the user F Waiting on the File daemon S Waiting on the Storage daemon m Waiting for a new Volume to be mounted M Waiting for a Mount s Waiting for Storage resource j Waiting for Job resource c Waiting for Client resource d Wating for Maximum jobs t Waiting for Start Time p Waiting for higher priority job to finish W Terminated with warnings Tapes (bconsole commands) add - Assign a tape to a certain pool. delete media - Remove a tape. list files jobid=nn - List the files that were saved for JobId nn. list jobid=rn - Lists JobId nn from the Catalog. list jobmedia - List the media information for each Job run. list jobs - Lists all jobs in the Catalog that have run. list jobtotals - Lists totals for all jobs in the Catalog. list media - Lists all the media defined in the Catalog. list pools - List the pools defined in the Catalog (normally only Default is used). list volumes - Shows the volumes that bconsole knows about. messages - Prints any messages that have been directed to the console. mount storage=storage-name - Causes the drive associated with the storage device to be mounted again. When Bacula reaches the end of a volume and requests you to mount a new volume, you must issue this command after you have placed the new volume in the drive. In effect, it is the signal needed by Bacula to know to start reading or writing the new volume. quit - Exit or quit the console program. status dir - Print a status of all running jobs and jobs scheduled in the next 24 hours. status jobid=rn - Print a status of JobId nn if it is running. The Storage daemon is contacted and requested to print a current status of the job as well. status - The console program will prompt you to select a daemon type, then will request the daemon's status. unmount storage=storage-name - Unmounts the drive associated with the storage device with the name storage-name if the drive is not currently being used. This command is used if you wish Bacula to free the drive so that you can use it to label a tape. update volume - Change parameters of a tape. Most of the commands given above, with the exception of list, will prompt you for the necessary arguments if you simply enter the command name. Terminology Catalog It is data in a SQL database running on the server. The catalog stores information about all assets like jobs, clients and media. Without the catalog Bacula had no idea which files were backed up and cannot restore them. In case of a disastrous loss of the catalog you need to take the latest bootstrap and start restoring the catalog first using that information. So the catalog itself is also backed up because without it the system is useless. Volumes Volumes (also called \u201cmedia\u201d) are either files on disk or physical tapes. When backups run they save their data to volumes. Bacula keeps track in the catalog which data can be found on each volume. Usually multiple backups run in parallel leading to a multiplexed stream of data written to volumes. A volume always belongs to exactly one pool. Volumes have names/labels \u2013 tapes have the name that is printed on the barcode sticker if the library have a barcode scanner. Pool A set of volumes. The pool can define a maximum number of volumes, the type of volumes (e.g. disk or tape) and the retention period. For example you can have short-lived disk pools for small frequent backups. On the other hand you may have long-lived tape pools that store data for several weeks or months. Job A specific action like a backup, restore or copy (e.g. from disk to tape). Jobs are usually started automatically by the director following a pre-defined schedule. Multiple jobs can run in parallel and share their resources. The catalog keeps track of which jobs have run in the past in order to know which volumes would be required to restore data from them. In the bconsole you can see the running, past and scheduled jobs by running \u201cstat dir\u201d. Job definition (aka jobdef) The definition of a job. It is not stored in the catalog but in text files in /etc/bacula. Client A server to be backed up. Usually a file-daemon runs on the client. The director will talk to the client to run jobs. Fileset Defines which files or directories to backup from a certain server. A job defines which fileset to use for a backup. Bootstrap A small text file usually sent out via email frequently. It is required in case of a catalog loss to find the volume that contains the last backup of the catalog. The upstream documents reads: \u201cThe bootstrap \ufb01le contains ASCII information that permits precise speci\ufb01cation of what \ufb01les should be restored, what volume they are on, and where they are on the volume. It is a relatively compact form of specifying the information, is human readable, and can be edited with any text editor.\u201d The bootstrap data is not confidential and should be forwarded to an external location in case of a disaster. Message Bacula can send messages to the console or via email. Results of jobs are sent via email. Schedule A definition of how often and at what time a job can be run. Storage Defines a way to write volumes. It is used by the storage daemon. A storage can be a path on the local disks or the name of the tape device. Autochangers (aka \u201ctape libraries\u201d) are also supported. Retention A volume is locked after being written to. The retention period defines when the volume can be overwritten again. Scratch This applies to tape volumes only. New tapes can be introduced into the \u201cScratch\u201d pool. If a pool is out of volumes to use then Bacula will take a volume from the Scratch pool and take it into its own pool. Levels Backups can happen in three different levels: Full, Differential and Incremental. Only Full backups are required. The other levels can be used to save space on volumes. Full: every single file defined in assigned fileset is saved to the volume Differential: only new files that were not contained in the last Full backup are backed up Incremental: only new files that were not contained in the last Differential or Incremental backup are backed up Using only Full backups is secure because if you lose a full backup then you take the full backup before it. However you are stubbornly backing up the same files time and again thus wasting space on the volumes. Complete restores are fastest though because only the last full backup has to be considered. Using Full and Differential backups saves some space. During restores the last Full and last Differential backup are considered. However multiple Differential backups may store files redundantly thus wasting a little space. Using Full and Incremental backups saves most space. However for a restore all Incremental backups since the last Full backup need to be working. If one Incremental backup is broken in the chain then only the last Full backup can be restored. Using Full + Differential + Incremental backups saves most space while still keeping the risk of losing data low. A restore requires the Incremental backups back up to the last Differential backup + the last Full backup. This could look like: Full Differential Incremental Incremental Incremental Incremental Differential Incremental Incremental Incremental < \u2013 Incremental Full \u2026 To restore the highlighted Incremental backup you would need the previous Differential and Full backups printed in bold letters. Which mode to use depends on the type of data to backup. Database directories usually change in its entirety so a Full backup is the best solution. File servers with millions of files gain some advantage from using Full, Differential and Incremental backups. Dangerous configurations: Using a rare Full backup and rely on many intermediate Incremental backups. If any of the many Incremental backups were faulty you would lose all data back to that time. Losing the Full backup and only keeping Incremental backups. This may occur if the retention periods are not adequately configured for Full backups. Eject the tape. mt -f /dev/st0 eject For bacula: use bconsole to unmount the tape drive then exit the program and eject the tape using the command above. username@servername:/home/username $ sudo bconsole *unmount Automatically selected Catalog: MyCatalog Using Catalog \"MyCatalog\" The defined Storage resources are: 1: File1 2: File2 3: LTO-4 4: LTO-4_SD Select Storage resource (1-4): 4 3001 Device \"\"LTO-4\" (/dev/st0)\" unmounted. * quit username@servername:/home/username $ mt -f /dev/st0 eject username@servername:/home/username $ sudo bconsole * mount Automatically selected Catalog: MyCatalog Using Catalog \"MyCatalog\" The defined Storage resources are: 1: File1 2: File2 3: LTO-4 4: LTO-4_SD Select Storage resource (1-4): 4 3001 Device \"\"LTO-4\" (/dev/st0)\" is mounted with Volume \"Tape-0004\" You have messages. Troubleshooting Erase a label on the tape <span style=\"color: #3366ff;\">mt rewind && mt weof && mt rewind</span> Tape drive full and could not be written to: Solution was to use bconsole to unmount, then eject the tape from the commandline, then insert Tape-0004 and mount from bconsole. 27-May 08:00 bacula-sd JobId 219: Warning: Director wanted Volume \"Tape-0004\". Current Volume \"Tape-0003\" not acceptable because: 1998 Volume \"Tape-0003\" catalog status is Error, but should be Append, Purged or Recycle. I think the command \"mount storage=LTO-4_SD\" would have worked also but I am not sure how I would have ejected the full tape out. Source for some of the data here: https://www.bacula-web.org/docs/install/selinux/","title":"Bacula"},{"location":"bacula/#heading","text":"----------------: ------------- Bacula Services: service bacula-dir start service bacula-fd start service bacula-sd start systemctl enable bacula-dir systemctl enable bacula-fd systemctl enable bacula-sd systemctl status bacula-dir systemctl status bacula-fd systemctl status bacula-sd ss -lt < -(Should show all three services listening) Bacula Cheat Sheet Bacula is a nifty backup software that is network-capable and stores data in the database for faster retrieval in case you need a certain file back. As a big fan of cheat sheets I created this cheat sheet. What\u2019s up? Which files shall be backed up? show filesets I=Included, E=Excluded What\u2019s the server doing? status dir What\u2019s the status of a certain job? status jobid=xx What\u2019s the client doing? status client What\u2019s the streamer doing? status storage Anything new? messages Backing up: Start a backup run \u2026and choose the backup job Label a new tape label \u2026and run mount afterwards Restoring: The common way (a user accidentally removed a file and wants the newest version back from the tapes: Use the restore command. Choose option 5 (Select the most recent backup for a client). Commands: cd ls dir mark markdir unmark unmarkdir lsmark estimate pwd count find can use find * to show the files. done Jobs Last jobs list jobs \u2026or list jobid=xx for a specific job Statistics about last jobs list jobtotal Which files were backed up? list files jobid=xx Job status Status means\u2026 T Terminated normally C Created but not yet running R Running B Blocked E Terminated in Error e Non-fatal error f Fatal error D Verify Differences A Canceled by the user F Waiting on the File daemon S Waiting on the Storage daemon m Waiting for a new Volume to be mounted M Waiting for a Mount s Waiting for Storage resource j Waiting for Job resource c Waiting for Client resource d Wating for Maximum jobs t Waiting for Start Time p Waiting for higher priority job to finish W Terminated with warnings Tapes (bconsole commands) add - Assign a tape to a certain pool. delete media - Remove a tape. list files jobid=nn - List the files that were saved for JobId nn. list jobid=rn - Lists JobId nn from the Catalog. list jobmedia - List the media information for each Job run. list jobs - Lists all jobs in the Catalog that have run. list jobtotals - Lists totals for all jobs in the Catalog. list media - Lists all the media defined in the Catalog. list pools - List the pools defined in the Catalog (normally only Default is used). list volumes - Shows the volumes that bconsole knows about. messages - Prints any messages that have been directed to the console. mount storage=storage-name - Causes the drive associated with the storage device to be mounted again. When Bacula reaches the end of a volume and requests you to mount a new volume, you must issue this command after you have placed the new volume in the drive. In effect, it is the signal needed by Bacula to know to start reading or writing the new volume. quit - Exit or quit the console program. status dir - Print a status of all running jobs and jobs scheduled in the next 24 hours. status jobid=rn - Print a status of JobId nn if it is running. The Storage daemon is contacted and requested to print a current status of the job as well. status - The console program will prompt you to select a daemon type, then will request the daemon's status. unmount storage=storage-name - Unmounts the drive associated with the storage device with the name storage-name if the drive is not currently being used. This command is used if you wish Bacula to free the drive so that you can use it to label a tape. update volume - Change parameters of a tape. Most of the commands given above, with the exception of list, will prompt you for the necessary arguments if you simply enter the command name. Terminology Catalog It is data in a SQL database running on the server. The catalog stores information about all assets like jobs, clients and media. Without the catalog Bacula had no idea which files were backed up and cannot restore them. In case of a disastrous loss of the catalog you need to take the latest bootstrap and start restoring the catalog first using that information. So the catalog itself is also backed up because without it the system is useless. Volumes Volumes (also called \u201cmedia\u201d) are either files on disk or physical tapes. When backups run they save their data to volumes. Bacula keeps track in the catalog which data can be found on each volume. Usually multiple backups run in parallel leading to a multiplexed stream of data written to volumes. A volume always belongs to exactly one pool. Volumes have names/labels \u2013 tapes have the name that is printed on the barcode sticker if the library have a barcode scanner. Pool A set of volumes. The pool can define a maximum number of volumes, the type of volumes (e.g. disk or tape) and the retention period. For example you can have short-lived disk pools for small frequent backups. On the other hand you may have long-lived tape pools that store data for several weeks or months. Job A specific action like a backup, restore or copy (e.g. from disk to tape). Jobs are usually started automatically by the director following a pre-defined schedule. Multiple jobs can run in parallel and share their resources. The catalog keeps track of which jobs have run in the past in order to know which volumes would be required to restore data from them. In the bconsole you can see the running, past and scheduled jobs by running \u201cstat dir\u201d. Job definition (aka jobdef) The definition of a job. It is not stored in the catalog but in text files in /etc/bacula. Client A server to be backed up. Usually a file-daemon runs on the client. The director will talk to the client to run jobs. Fileset Defines which files or directories to backup from a certain server. A job defines which fileset to use for a backup. Bootstrap A small text file usually sent out via email frequently. It is required in case of a catalog loss to find the volume that contains the last backup of the catalog. The upstream documents reads: \u201cThe bootstrap \ufb01le contains ASCII information that permits precise speci\ufb01cation of what \ufb01les should be restored, what volume they are on, and where they are on the volume. It is a relatively compact form of specifying the information, is human readable, and can be edited with any text editor.\u201d The bootstrap data is not confidential and should be forwarded to an external location in case of a disaster. Message Bacula can send messages to the console or via email. Results of jobs are sent via email. Schedule A definition of how often and at what time a job can be run. Storage Defines a way to write volumes. It is used by the storage daemon. A storage can be a path on the local disks or the name of the tape device. Autochangers (aka \u201ctape libraries\u201d) are also supported. Retention A volume is locked after being written to. The retention period defines when the volume can be overwritten again. Scratch This applies to tape volumes only. New tapes can be introduced into the \u201cScratch\u201d pool. If a pool is out of volumes to use then Bacula will take a volume from the Scratch pool and take it into its own pool. Levels Backups can happen in three different levels: Full, Differential and Incremental. Only Full backups are required. The other levels can be used to save space on volumes. Full: every single file defined in assigned fileset is saved to the volume Differential: only new files that were not contained in the last Full backup are backed up Incremental: only new files that were not contained in the last Differential or Incremental backup are backed up Using only Full backups is secure because if you lose a full backup then you take the full backup before it. However you are stubbornly backing up the same files time and again thus wasting space on the volumes. Complete restores are fastest though because only the last full backup has to be considered. Using Full and Differential backups saves some space. During restores the last Full and last Differential backup are considered. However multiple Differential backups may store files redundantly thus wasting a little space. Using Full and Incremental backups saves most space. However for a restore all Incremental backups since the last Full backup need to be working. If one Incremental backup is broken in the chain then only the last Full backup can be restored. Using Full + Differential + Incremental backups saves most space while still keeping the risk of losing data low. A restore requires the Incremental backups back up to the last Differential backup + the last Full backup. This could look like: Full Differential Incremental Incremental Incremental Incremental Differential Incremental Incremental Incremental < \u2013 Incremental Full \u2026 To restore the highlighted Incremental backup you would need the previous Differential and Full backups printed in bold letters. Which mode to use depends on the type of data to backup. Database directories usually change in its entirety so a Full backup is the best solution. File servers with millions of files gain some advantage from using Full, Differential and Incremental backups. Dangerous configurations: Using a rare Full backup and rely on many intermediate Incremental backups. If any of the many Incremental backups were faulty you would lose all data back to that time. Losing the Full backup and only keeping Incremental backups. This may occur if the retention periods are not adequately configured for Full backups. Eject the tape. mt -f /dev/st0 eject For bacula: use bconsole to unmount the tape drive then exit the program and eject the tape using the command above. username@servername:/home/username $ sudo bconsole *unmount Automatically selected Catalog: MyCatalog Using Catalog \"MyCatalog\" The defined Storage resources are: 1: File1 2: File2 3: LTO-4 4: LTO-4_SD Select Storage resource (1-4): 4 3001 Device \"\"LTO-4\" (/dev/st0)\" unmounted. * quit username@servername:/home/username $ mt -f /dev/st0 eject username@servername:/home/username $ sudo bconsole * mount Automatically selected Catalog: MyCatalog Using Catalog \"MyCatalog\" The defined Storage resources are: 1: File1 2: File2 3: LTO-4 4: LTO-4_SD Select Storage resource (1-4): 4 3001 Device \"\"LTO-4\" (/dev/st0)\" is mounted with Volume \"Tape-0004\" You have messages. Troubleshooting Erase a label on the tape <span style=\"color: #3366ff;\">mt rewind && mt weof && mt rewind</span> Tape drive full and could not be written to: Solution was to use bconsole to unmount, then eject the tape from the commandline, then insert Tape-0004 and mount from bconsole. 27-May 08:00 bacula-sd JobId 219: Warning: Director wanted Volume \"Tape-0004\". Current Volume \"Tape-0003\" not acceptable because: 1998 Volume \"Tape-0003\" catalog status is Error, but should be Append, Purged or Recycle. I think the command \"mount storage=LTO-4_SD\" would have worked also but I am not sure how I would have ejected the full tape out. Source for some of the data here: https://www.bacula-web.org/docs/install/selinux/","title":"Heading"},{"location":"barcodes/","text":"You will need to install the barcode application and ImageMagick. sudo dnf -y install barcode sudo dnf -y install ImageMagick Test create a postscript file that contains a barcode then convert it to .png: barcode -b \"1234567890\" -e \"code128\" -o aaa.ps magick aaa.ps aaa.png barcode -i out2.tab -o ouput.ps The following will read serial numbers from a file and print Code 128 barcodes in table format (5 columns x 20 rows) on an 8.5x11 inch sheet of paper. barcode -e \"code128\" -t 5x20 -p \"8.5x11in\" -i serials.txt -o serials.pdf The following will read serial numbers from a file and print Code 39 barcodes in table format (5 columns x 20 rows) on an 8.5x11 inch sheet of paper. (Code 39 does not seem to recognize lowercase letters). barcode -e \"code39\" -t 5x20 -p \"8.5x11in\" -i serials.txt -o serials.pdf The following will read serial numbers from a file and print Code 39 barcodes in table format (5 columns x 5 rows with a barcode margin of 20x and 50y) on an 8.5x11 inch sheet of paper. (Code 39 does not seem to recognize lowercase letters). barcode -e \"code39\" -t \"5x5 +96x+48+96+48\" -m \"20x50\" -p \"8.5x11in\" -i serials.txt -o serials.pdf The following will create a single barcode 39 .ps file with geometry of 250x100 and generate a .png that is the same size as the barcode. source barcode -b \"343110\" -e \"code39\" -g \"250x100\" -E -o aaa.ps;magick aaa.ps aaa.png Other barcode software: https://github.com/larsschenk/ActiveBarcodeCLI.git https://www.activebarcode.com/commandline/ ./ActiveBarcodeCLI --text=192837465012 --code=ean13 --width=400 --height=200 ean.wmf Strockscribe: https://www.youtube.com/watch?v=Ur2hA-AaDG0 https://strokescribe.com/en/barcode-libreoffice-calc.html?t=1752080693587 Tools->Macros-->Organize-->Basic Google Sheets: Print Barcode Labels Using ONLY Google Sheets: https://www.youtube.com/watch?v=QZi2pQcxRsw QREncode: dnf -y install qrencode","title":"Barcodes"},{"location":"base64/","text":"Base 64 Source: https://ioflood.com/blog/base64-linux-command/ Using single-quotes around the data that is being encoded seems to produce the expected output. I got different results using double-quotes. echo 'This is a text with some #$@% non-alphabet characters.' | base64 -i echo 'VGhpcyBpcyBhIHRleHQgd2l0aCBzb21lICMkQCUgbm9uLWFscGhhYmV0IGNoYXJhY3RlcnMuCg==' | base64 -d Large files: base64 -w 0 large_file.txt > encoded_file.txt","title":"Base64"},{"location":"base64/#base-64","text":"Source: https://ioflood.com/blog/base64-linux-command/ Using single-quotes around the data that is being encoded seems to produce the expected output. I got different results using double-quotes. echo 'This is a text with some #$@% non-alphabet characters.' | base64 -i echo 'VGhpcyBpcyBhIHRleHQgd2l0aCBzb21lICMkQCUgbm9uLWFscGhhYmV0IGNoYXJhY3RlcnMuCg==' | base64 -d Large files: base64 -w 0 large_file.txt > encoded_file.txt","title":"Base 64"},{"location":"bashstuff/","text":"Bash Stuff Bash ALIASES #alias ports='ss -lt' #alias ports1='netstat -pantu' alias netsettings='nmcli' alias diskdata='duf' alias foldershow='ncdu' alias LSBlk='lsblk -o +UUID,PARTUUID' alias LSBlk1='lsblk -o +UUID,FSTYPE,PARTUUID' alias LSBLK='lsblk -o \\\"NAME,MAJ:MIN,RM,SIZE,RO,FSTYPE,MOUNTPOINT,UUID\\\"' alias diskbyid='ls -lF /dev/disk/by-id' alias disku='duf' alias rootcompare='sudo QT_GRAPHICSSYSTEM=native bcompare' alias showdisks='sudo lshw -short -C disk' alias minecraft='~/.minecraft/launcher/minecraft-launcher' alias lsblk2='lsblk -o type,name,label,partlabel,size,fstype,model,serial,wwn,uuid' #alias youtube='echo yt-dlp ' alias ssh='ssh -XC' Bash ARRAYS: Are you finding it challenging to determine the length of an array in Bash? You\u2019re not alone. Many developers find themselves puzzled when it comes to handling arrays in Bash, but we\u2019re here to help. Think of Bash\u2019s array length command as a measuring tape \u2013 allowing us to quickly and accurately gauge the size of our arrays, providing a versatile and handy tool for various tasks. In this guide, we\u2019ll walk you through the process of determining the length of an array in Bash, from the basics to more advanced techniques. We\u2019ll cover everything from the simple use of the ${#array[@]} syntax to more complex scenarios, as well as alternative approaches. Let\u2019s get started! How Do I Find the Length of an Array in Bash? To find the length of an array in Bash, you can use the ${#array[@]} syntax. This command will return the number of elements in the array. Here\u2019s a simple example: array=(\"apple\" \"banana\" \"cherry\") echo \"${#array[@]}\" Output the number of elements in the array: 3 In this example, we\u2019ve created an array with three elements: \u2018apple\u2019, \u2018banana\u2019, and \u2018cherry\u2019. The ${#array[@]} syntax is used to find the length of the array, which in this case is 3. Bash Array Length: The Basics Before we dive into complex scenarios, let\u2019s start with the basics of finding the length of an array in Bash. The syntax for finding the length of an array is ${#array[@]} . Let\u2019s look at a simple example: fruits=(\"apple\" \"banana\" \"orange\" \"grape\" \"pineapple\") echo \"${#fruits[@]}\" Output the length of an array: 5 In this example, we\u2019ve created an array named \u2018fruits\u2019 with five elements. We then use the ${#fruits[@]} syntax to find the length of the array, which returns 5, as there are five elements in the array. This basic usage of the ${#array[@]} syntax is the foundation for finding the length of an array in Bash. As you become more comfortable with this concept, you can start to explore more advanced scenarios. Intermediate Bash: Length of Multi-Dimensional Arrays and Empty Elements As you gain more experience with Bash, you\u2019ll likely encounter more complex scenarios. For example, you may need to determine the length of a multi-dimensional array or handle arrays with empty elements. Let\u2019s take a closer look at these situations. Multi-Dimensional Arrays In Bash, multi-dimensional arrays aren\u2019t supported directly. However, you can simulate them using one-dimensional arrays. Here\u2019s an example: matrix=(\"1 2 3\" \"4 5 6\" \"7 8 9 0\") for row in \"${matrix[@]}\"; do set -- $row echo \"${#matrix[@]}\" done Output the number of elements in each row of the array: 3 3 3 In this example, we\u2019ve created a simulated 3\u00d73 matrix. Each element of the \u2018matrix\u2019 array is a string representing a row of the matrix. The set -- $row command splits the string into separate elements, and ${#*[@]} gives the number of elements in each row, effectively giving us the \u2018length\u2019 of each dimension. Handling Empty Elements in an array: Bash considers an empty string as a valid array element. Therefore, it contributes to the length of the array. Let\u2019s see this in action: array=(\"apple\" \"\" \"cherry\") echo \"${#array[@]}\" Array with empty string output: 3 In this example, \u2018apple\u2019, an empty string, and \u2018cherry\u2019 are the elements of the array. Even though the second element is an empty string, Bash counts it as a valid element, so the length of the array is 3. These are some of the more complex scenarios you might encounter when finding the length of an array in Bash. Understanding these concepts will help you handle arrays more effectively in your scripts. Alternative Methods: Bash Array Length While the ${#array[@]} syntax is the most straightforward way to determine the length of an array in Bash, there are alternative approaches you can use. Let\u2019s explore some of these methods, their benefits, drawbacks, and when to use them. Using a Loop Find the length of an array: One way to find the length of an array is by using a loop to iterate over the array elements. Here\u2019s an example: fruits=(\"apple\" \"banana\" \"orange\" \"grape\" \"pineapple\") length=0 for fruit in \"${fruits[@]}\"; do length=$((length+1)) done echo $length Length of an array output: 5 In this example, we initialize a counter (length) to zero. Then, for each element in the array, we increment the counter by one. After the loop, length holds the number of elements in the array. This method provides more control and can be useful in scenarios where you want to perform additional operations on each element. However, it\u2019s more verbose and less efficient than the ${#array[@]} syntax. Using External Commands Length of array using printf and wc: You can also use external commands like awk or wc to find the length of an array. Here\u2019s an example using printf and wc: fruits=(\"apple\" \"banana\" \"orange\" \"grape\" \"pineapple\") length=$(printf '%s\\n' \"${fruits[@]}\" | wc -l) echo $length Length of array using printf and wc output: 5 In this example, we use printf to print each element on a new line, then pipe the output to wc -l to count the number of lines. This gives us the number of elements in the array. This method can handle large arrays and complex string manipulations, but it\u2019s slower and less readable than the ${#array[@]} syntax. It also depends on external commands, which may not be available in all environments. In conclusion, while the ${#array[@]} syntax is generally the best way to find the length of an array in Bash, understanding these alternative methods can broaden your scripting skills and help you tackle a wider range of problems. Troubleshooting Bash Array Length While finding the length of an array in Bash is generally straightforward, there are some common issues that you might encounter. In this section, we\u2019ll discuss these potential problems and provide solutions to overcome them. Special Characters in Array Elements Bash treats some characters as special, which can cause unexpected behavior when they\u2019re included in array elements. Let\u2019s look at an example: array=(\"apple\" \"banana \\n cherry\") echo \"${#array[@]}\" Special chracters output: 2 In this example, the array has two elements: \u2018apple\u2019 and \u2018banana \\n cherry\u2019. Despite the newline character (\\n) in the second element, Bash still counts it as a single element, so the length of the array is 2. To handle special characters in array elements, you can use quotes to treat the entire string as a single element. Large Arrays When dealing with large arrays, the ${#array[@]} syntax can become slow. In these cases, you might want to consider using an external command like wc, as discussed in the \u2018Alternative Approaches\u2019 section. Here\u2019s a code example for handling large arrays: large_array=($(seq 1 10000)) length=$(printf '%s\\n' \"${large_array[@]}\" | wc -l) echo $length Large array count output: 10000 In this example, we\u2019ve created a large array with 10,000 elements using the seq command. We then use printf and wc to find the length of the array. Remember, while this method can handle large arrays, it\u2019s slower and less readable than the ${#array[@]} syntax. It also depends on external commands, which may not be available in all environments. By understanding these common issues and their solutions, you can handle arrays more effectively in your Bash scripts. Understanding Arrays in Bash Before we delve deeper into the nuances of determining the length of arrays in Bash, it\u2019s crucial to understand what arrays are and how they function in Bash. What is an Array? An array is a data structure that stores a collection of elements. These elements, also known as values, are stored in a specific order and can be accessed by their index, which is their position in the array. In Bash, arrays are zero-indexed, meaning the first element is at index 0, the second element is at index 1, and so on. Here\u2019s a simple example of an array in Bash: fruits=(\"apple\" \"banana\" \"cherry\") echo \"${fruits[0]}\" Simple array output: apple In this example, \u2018apple\u2019, \u2018banana\u2019, and \u2018cherry\u2019 are the elements of the array. The command echo \"${fruits[0]}\" prints the first element of the array, which is \u2018apple\u2019. Manipulating Arrays in Bash Add element to an array: Bash provides various commands to manipulate arrays, such as adding elements, removing elements, and finding the length of an array. For instance, to add an element to an array, you can use the following syntax: fruits=(\"apple\" \"banana\" \"cherry\") fruits+=(\"orange\") echo \"${fruits[@]}\" Add element to an array output: apple banana cherry orange In this example, we\u2019ve added \u2018orange\u2019 to the \u2018fruits\u2019 array. The += operator is used to append elements to an array in Bash. Data Structures in Bash In addition to arrays, Bash supports other data structures like strings and associative arrays. While strings are simple data structures that hold a sequence of characters, associative arrays (also known as hash maps) are more complex and hold pairs of keys and values. Understanding these fundamental concepts about arrays and data structures in Bash is crucial for effective scripting. With this knowledge, you can better understand how to determine and manipulate the length of an array in Bash. The Power of Arrays in Bash Scripting Arrays are incredibly versatile and powerful tools in Bash scripting. They are fundamental to a multitude of tasks and operations, making them an indispensable part of any Bash programmer\u2019s toolkit. Arrays in File Handling List of files: Arrays can be used to handle files and directories in Bash. For instance, you can store the list of files in a directory in an array and perform operations on each file. Here\u2019s an example: files=(/path/to/directory/*) for file in \"${files[@]}\"; do echo \"Processing $file\" done List of files in array output: Processing /path/to/directory/file1 Processing /path/to/directory/file2 ... In this example, we\u2019ve stored all the files in a directory in an array. We then iterate over the array and print a message for each file. Arrays in Data Processing Processing lines in a .csv file: Arrays also play a crucial role in data processing tasks in Bash. They can be used to store and manipulate data, making it easier to perform complex operations. For instance, you can use an array to store the lines of a CSV file and process each line. Here\u2019s an example: IFS=$' ' lines=($(cat data.csv)) for line in \"${lines[@]}\"; do echo \"Processing $line\" done Processing lines of a .csv file output: Processing line1 Processing line2 ... In this example, we\u2019ve read a CSV file line by line into an array using the cat command. We then iterate over the array and process each line. Source1: Source2: Bash FUNCTIONS: thefunctionname() { if [ $# -eq 0 ] then echo \"Usage: thefunctionname someargument\" echo \"Example: Blah blah blah.\" echo \" thefunctionname someargument\" else echo \"Running thefunctionname... \" $1 thefunctionname $1 fi } A function using if/case: anotherfunction() { if [ $# -eq 0 ] then echo \"anotherfunction someargument\" else case $1 in argument1) do some work ;; argument2) do some work ;; *) message=\"Default message if no argument is supplied.\" echo $message ;; esac fi } STAT command: stat -c \"%a %n %C\" filename.txt Multiple search using grep: grep 'word1.*word2' logs ls -al |grep 'rob.*Nov.*mp3' |grep -v \".sh\" ip addr |grep -i 'inet.*global' The following examples prints numbers from 1 to 10 using the for and while loops echo \"for(i=1;i<=10;i++) {i;}\" | bc echo \"i=1; while(i<=10) {i; i+=1}\" | bc For loop (count): y=1 for x in *.jpg do echo $y mv $x 20241215_sequentially_numbered_file_$y.jpg ((y++)) done For loop on multiple file extensions: for i in { .gz, .rar} do ls -al > \"$i\" done rm -f .gz .rar While loop (count): counter=0 while [ $counter -lt 5 ]; do echo \"Counter: $counter\" ((counter++)) done Increment a variable inside a bash loop: FILE=$1 tail -n40 mylog > $FILE #Send the contents of mylog to $FILE while read country _; do if [ \"US\" = \"$country\" ]; then #Search for US in the $country variable. USCOUNTER=$(expr $USCOUNTER + 1) #Increment by one for each US found. echo \"Found $USCOUNTER US\" #Display the incremented count. fi done < \"$FILE\" echo \"Found a total of $USCOUNTER US.\" #Display the final count of US. Source: Other options for counting \"US\" from above: grep -cE \"^([^ ]* ){0}US\" mylog # -c count # ([^ ]* ) To detect a column # {0} the column number # US your pattern Increment with array example to convert png files to jpg using ImageMagick: #files=(/home/rob/Pictures/Screenshots/{ .png, .jpg}) files=(/home/rob/Pictures/Screenshots/*.png) #TIMESTAMP=`date +\"%Y%m%d%H%M%S%Z\"` TIMESTAMP=`date +\"%Y%m%d%H%M\"` y=$TIMESTAMP\"0000000\" #Adjust the number of zeros according to the number of digits in the date (19 digits max on 64bit systems). echo \"\" > $TIMESTAMP\"_log.txt\" for file in \"${files[@]}\"; do #echo \"cp \\\"$file\\\" /home/rob/Pictures/Screenshots/xyz/$y.png\" echo \"magick '$file[800x600]' /home/rob/Pictures/Screenshots/xyz/$y.jpg\" echo \"\\\"$file\\\" = $y.jpg\" >> $TIMESTAMP\"_log.txt\" ((y++)) done Using the following 1 line command for renaming files in linux using a specific phrase: find -type f -name ' .jpg' | rename 's/holiday/honeymoon/' For all files with the extension \".jpg\", if they contain the string \"holiday\", replace it with \"honeymoon\". For instance, this command would rename the file \"ourholiday001.jpg\" to \"ourhoneymoon001.jpg\". This example also illustrates how to use the find command to send a list of files (-type f) with the extension .jpg (-name ' .jpg') to rename via a pipe (|). rename then reads its file list from standard input. Source: Grep for multiple things at once: The '-e' option allows you to search for multiple things. It is kind of like an 'or' statement. Example below, find postfix or mailx. rpm -qa |grep -e postfix -e mailx Find Graphics or Video Card Information: lspci -k | grep -EA3 'VGA|3D|Display'","title":"Bash Stuff"},{"location":"bashstuff/#bash-stuff","text":"","title":"Bash Stuff"},{"location":"bashstuff/#bash-aliases","text":"#alias ports='ss -lt' #alias ports1='netstat -pantu' alias netsettings='nmcli' alias diskdata='duf' alias foldershow='ncdu' alias LSBlk='lsblk -o +UUID,PARTUUID' alias LSBlk1='lsblk -o +UUID,FSTYPE,PARTUUID' alias LSBLK='lsblk -o \\\"NAME,MAJ:MIN,RM,SIZE,RO,FSTYPE,MOUNTPOINT,UUID\\\"' alias diskbyid='ls -lF /dev/disk/by-id' alias disku='duf' alias rootcompare='sudo QT_GRAPHICSSYSTEM=native bcompare' alias showdisks='sudo lshw -short -C disk' alias minecraft='~/.minecraft/launcher/minecraft-launcher' alias lsblk2='lsblk -o type,name,label,partlabel,size,fstype,model,serial,wwn,uuid' #alias youtube='echo yt-dlp ' alias ssh='ssh -XC'","title":"Bash ALIASES"},{"location":"bashstuff/#bash-arrays","text":"Are you finding it challenging to determine the length of an array in Bash? You\u2019re not alone. Many developers find themselves puzzled when it comes to handling arrays in Bash, but we\u2019re here to help. Think of Bash\u2019s array length command as a measuring tape \u2013 allowing us to quickly and accurately gauge the size of our arrays, providing a versatile and handy tool for various tasks. In this guide, we\u2019ll walk you through the process of determining the length of an array in Bash, from the basics to more advanced techniques. We\u2019ll cover everything from the simple use of the ${#array[@]} syntax to more complex scenarios, as well as alternative approaches. Let\u2019s get started!","title":"Bash ARRAYS:"},{"location":"bashstuff/#how-do-i-find-the-length-of-an-array-in-bash","text":"To find the length of an array in Bash, you can use the ${#array[@]} syntax. This command will return the number of elements in the array. Here\u2019s a simple example: array=(\"apple\" \"banana\" \"cherry\") echo \"${#array[@]}\"","title":"How Do I Find the Length of an Array in Bash?"},{"location":"bashstuff/#output-the-number-of-elements-in-the-array","text":"3 In this example, we\u2019ve created an array with three elements: \u2018apple\u2019, \u2018banana\u2019, and \u2018cherry\u2019. The ${#array[@]} syntax is used to find the length of the array, which in this case is 3.","title":"Output the number of elements in the array:"},{"location":"bashstuff/#bash-array-length-the-basics","text":"Before we dive into complex scenarios, let\u2019s start with the basics of finding the length of an array in Bash. The syntax for finding the length of an array is ${#array[@]} . Let\u2019s look at a simple example: fruits=(\"apple\" \"banana\" \"orange\" \"grape\" \"pineapple\") echo \"${#fruits[@]}\"","title":"Bash Array Length: The Basics"},{"location":"bashstuff/#output-the-length-of-an-array","text":"5 In this example, we\u2019ve created an array named \u2018fruits\u2019 with five elements. We then use the ${#fruits[@]} syntax to find the length of the array, which returns 5, as there are five elements in the array. This basic usage of the ${#array[@]} syntax is the foundation for finding the length of an array in Bash. As you become more comfortable with this concept, you can start to explore more advanced scenarios. Intermediate Bash: Length of Multi-Dimensional Arrays and Empty Elements As you gain more experience with Bash, you\u2019ll likely encounter more complex scenarios. For example, you may need to determine the length of a multi-dimensional array or handle arrays with empty elements. Let\u2019s take a closer look at these situations.","title":"Output the length of an array:"},{"location":"bashstuff/#multi-dimensional-arrays","text":"In Bash, multi-dimensional arrays aren\u2019t supported directly. However, you can simulate them using one-dimensional arrays. Here\u2019s an example: matrix=(\"1 2 3\" \"4 5 6\" \"7 8 9 0\") for row in \"${matrix[@]}\"; do set -- $row echo \"${#matrix[@]}\" done","title":"Multi-Dimensional Arrays"},{"location":"bashstuff/#output-the-number-of-elements-in-each-row-of-the-array","text":"3 3 3 In this example, we\u2019ve created a simulated 3\u00d73 matrix. Each element of the \u2018matrix\u2019 array is a string representing a row of the matrix. The set -- $row command splits the string into separate elements, and ${#*[@]} gives the number of elements in each row, effectively giving us the \u2018length\u2019 of each dimension.","title":"Output the number of elements in each row of the array:"},{"location":"bashstuff/#handling-empty-elements-in-an-array","text":"Bash considers an empty string as a valid array element. Therefore, it contributes to the length of the array. Let\u2019s see this in action: array=(\"apple\" \"\" \"cherry\") echo \"${#array[@]}\"","title":"Handling Empty Elements in an array:"},{"location":"bashstuff/#array-with-empty-string-output","text":"3 In this example, \u2018apple\u2019, an empty string, and \u2018cherry\u2019 are the elements of the array. Even though the second element is an empty string, Bash counts it as a valid element, so the length of the array is 3. These are some of the more complex scenarios you might encounter when finding the length of an array in Bash. Understanding these concepts will help you handle arrays more effectively in your scripts. Alternative Methods: Bash Array Length While the ${#array[@]} syntax is the most straightforward way to determine the length of an array in Bash, there are alternative approaches you can use. Let\u2019s explore some of these methods, their benefits, drawbacks, and when to use them. Using a Loop","title":"Array with empty string output:"},{"location":"bashstuff/#find-the-length-of-an-array","text":"One way to find the length of an array is by using a loop to iterate over the array elements. Here\u2019s an example: fruits=(\"apple\" \"banana\" \"orange\" \"grape\" \"pineapple\") length=0 for fruit in \"${fruits[@]}\"; do length=$((length+1)) done echo $length","title":"Find the length of an array:"},{"location":"bashstuff/#length-of-an-array-output","text":"5 In this example, we initialize a counter (length) to zero. Then, for each element in the array, we increment the counter by one. After the loop, length holds the number of elements in the array. This method provides more control and can be useful in scenarios where you want to perform additional operations on each element. However, it\u2019s more verbose and less efficient than the ${#array[@]} syntax. Using External Commands","title":"Length of an array output:"},{"location":"bashstuff/#length-of-array-using-printf-and-wc","text":"You can also use external commands like awk or wc to find the length of an array. Here\u2019s an example using printf and wc: fruits=(\"apple\" \"banana\" \"orange\" \"grape\" \"pineapple\") length=$(printf '%s\\n' \"${fruits[@]}\" | wc -l) echo $length","title":"Length of array using printf and wc:"},{"location":"bashstuff/#length-of-array-using-printf-and-wc-output","text":"5 In this example, we use printf to print each element on a new line, then pipe the output to wc -l to count the number of lines. This gives us the number of elements in the array. This method can handle large arrays and complex string manipulations, but it\u2019s slower and less readable than the ${#array[@]} syntax. It also depends on external commands, which may not be available in all environments. In conclusion, while the ${#array[@]} syntax is generally the best way to find the length of an array in Bash, understanding these alternative methods can broaden your scripting skills and help you tackle a wider range of problems. Troubleshooting Bash Array Length While finding the length of an array in Bash is generally straightforward, there are some common issues that you might encounter. In this section, we\u2019ll discuss these potential problems and provide solutions to overcome them.","title":"Length of array using printf and wc output:"},{"location":"bashstuff/#special-characters-in-array-elements","text":"Bash treats some characters as special, which can cause unexpected behavior when they\u2019re included in array elements. Let\u2019s look at an example: array=(\"apple\" \"banana \\n cherry\") echo \"${#array[@]}\"","title":"Special Characters in Array Elements"},{"location":"bashstuff/#special-chracters-output","text":"2 In this example, the array has two elements: \u2018apple\u2019 and \u2018banana \\n cherry\u2019. Despite the newline character (\\n) in the second element, Bash still counts it as a single element, so the length of the array is 2. To handle special characters in array elements, you can use quotes to treat the entire string as a single element. Large Arrays When dealing with large arrays, the ${#array[@]} syntax can become slow. In these cases, you might want to consider using an external command like wc, as discussed in the \u2018Alternative Approaches\u2019 section. Here\u2019s a code example for handling large arrays: large_array=($(seq 1 10000)) length=$(printf '%s\\n' \"${large_array[@]}\" | wc -l) echo $length","title":"Special chracters output:"},{"location":"bashstuff/#large-array-count-output","text":"10000 In this example, we\u2019ve created a large array with 10,000 elements using the seq command. We then use printf and wc to find the length of the array. Remember, while this method can handle large arrays, it\u2019s slower and less readable than the ${#array[@]} syntax. It also depends on external commands, which may not be available in all environments. By understanding these common issues and their solutions, you can handle arrays more effectively in your Bash scripts. Understanding Arrays in Bash Before we delve deeper into the nuances of determining the length of arrays in Bash, it\u2019s crucial to understand what arrays are and how they function in Bash. What is an Array? An array is a data structure that stores a collection of elements. These elements, also known as values, are stored in a specific order and can be accessed by their index, which is their position in the array. In Bash, arrays are zero-indexed, meaning the first element is at index 0, the second element is at index 1, and so on. Here\u2019s a simple example of an array in Bash: fruits=(\"apple\" \"banana\" \"cherry\") echo \"${fruits[0]}\"","title":"Large array count output:"},{"location":"bashstuff/#simple-array-output","text":"apple In this example, \u2018apple\u2019, \u2018banana\u2019, and \u2018cherry\u2019 are the elements of the array. The command echo \"${fruits[0]}\" prints the first element of the array, which is \u2018apple\u2019. Manipulating Arrays in Bash","title":"Simple array output:"},{"location":"bashstuff/#add-element-to-an-array","text":"Bash provides various commands to manipulate arrays, such as adding elements, removing elements, and finding the length of an array. For instance, to add an element to an array, you can use the following syntax: fruits=(\"apple\" \"banana\" \"cherry\") fruits+=(\"orange\") echo \"${fruits[@]}\"","title":"Add element to an array:"},{"location":"bashstuff/#add-element-to-an-array-output","text":"apple banana cherry orange In this example, we\u2019ve added \u2018orange\u2019 to the \u2018fruits\u2019 array. The += operator is used to append elements to an array in Bash. Data Structures in Bash In addition to arrays, Bash supports other data structures like strings and associative arrays. While strings are simple data structures that hold a sequence of characters, associative arrays (also known as hash maps) are more complex and hold pairs of keys and values. Understanding these fundamental concepts about arrays and data structures in Bash is crucial for effective scripting. With this knowledge, you can better understand how to determine and manipulate the length of an array in Bash. The Power of Arrays in Bash Scripting Arrays are incredibly versatile and powerful tools in Bash scripting. They are fundamental to a multitude of tasks and operations, making them an indispensable part of any Bash programmer\u2019s toolkit. Arrays in File Handling","title":"Add element to an array output:"},{"location":"bashstuff/#list-of-files","text":"Arrays can be used to handle files and directories in Bash. For instance, you can store the list of files in a directory in an array and perform operations on each file. Here\u2019s an example: files=(/path/to/directory/*) for file in \"${files[@]}\"; do echo \"Processing $file\" done","title":"List of files:"},{"location":"bashstuff/#list-of-files-in-array-output","text":"Processing /path/to/directory/file1 Processing /path/to/directory/file2 ... In this example, we\u2019ve stored all the files in a directory in an array. We then iterate over the array and print a message for each file. Arrays in Data Processing","title":"List of files in array output:"},{"location":"bashstuff/#processing-lines-in-a-csv-file","text":"Arrays also play a crucial role in data processing tasks in Bash. They can be used to store and manipulate data, making it easier to perform complex operations. For instance, you can use an array to store the lines of a CSV file and process each line. Here\u2019s an example: IFS=$' ' lines=($(cat data.csv)) for line in \"${lines[@]}\"; do echo \"Processing $line\" done","title":"Processing lines in a .csv file:"},{"location":"bashstuff/#processing-lines-of-a-csv-file-output","text":"Processing line1 Processing line2 ... In this example, we\u2019ve read a CSV file line by line into an array using the cat command. We then iterate over the array and process each line. Source1: Source2:","title":"Processing lines of a .csv file output:"},{"location":"bashstuff/#bash-functions","text":"thefunctionname() { if [ $# -eq 0 ] then echo \"Usage: thefunctionname someargument\" echo \"Example: Blah blah blah.\" echo \" thefunctionname someargument\" else echo \"Running thefunctionname... \" $1 thefunctionname $1 fi } A function using if/case: anotherfunction() { if [ $# -eq 0 ] then echo \"anotherfunction someargument\" else case $1 in argument1) do some work ;; argument2) do some work ;; *) message=\"Default message if no argument is supplied.\" echo $message ;; esac fi }","title":"Bash FUNCTIONS:"},{"location":"bashstuff/#stat-command","text":"stat -c \"%a %n %C\" filename.txt","title":"STAT command:"},{"location":"bashstuff/#multiple-search-using-grep","text":"grep 'word1.*word2' logs ls -al |grep 'rob.*Nov.*mp3' |grep -v \".sh\" ip addr |grep -i 'inet.*global'","title":"Multiple search using grep:"},{"location":"bashstuff/#the-following-examples-prints-numbers-from-1-to-10-using-the-for-and-while-loops","text":"echo \"for(i=1;i<=10;i++) {i;}\" | bc echo \"i=1; while(i<=10) {i; i+=1}\" | bc","title":"The following examples prints numbers from 1 to 10 using the for and while loops"},{"location":"bashstuff/#for-loop-count","text":"y=1 for x in *.jpg do echo $y mv $x 20241215_sequentially_numbered_file_$y.jpg ((y++)) done","title":"For loop (count):"},{"location":"bashstuff/#for-loop-on-multiple-file-extensions","text":"for i in { .gz, .rar} do ls -al > \"$i\" done rm -f .gz .rar","title":"For loop on multiple file extensions:"},{"location":"bashstuff/#while-loop-count","text":"counter=0 while [ $counter -lt 5 ]; do echo \"Counter: $counter\" ((counter++)) done","title":"While loop (count):"},{"location":"bashstuff/#increment-a-variable-inside-a-bash-loop","text":"FILE=$1 tail -n40 mylog > $FILE #Send the contents of mylog to $FILE while read country _; do if [ \"US\" = \"$country\" ]; then #Search for US in the $country variable. USCOUNTER=$(expr $USCOUNTER + 1) #Increment by one for each US found. echo \"Found $USCOUNTER US\" #Display the incremented count. fi done < \"$FILE\" echo \"Found a total of $USCOUNTER US.\" #Display the final count of US. Source:","title":"Increment a variable inside a bash loop:"},{"location":"bashstuff/#other-options-for-counting-us-from-above","text":"grep -cE \"^([^ ]* ){0}US\" mylog # -c count # ([^ ]* ) To detect a column # {0} the column number # US your pattern","title":"Other options for counting \"US\" from above:"},{"location":"bashstuff/#increment-with-array-example-to-convert-png-files-to-jpg-using-imagemagick","text":"#files=(/home/rob/Pictures/Screenshots/{ .png, .jpg}) files=(/home/rob/Pictures/Screenshots/*.png) #TIMESTAMP=`date +\"%Y%m%d%H%M%S%Z\"` TIMESTAMP=`date +\"%Y%m%d%H%M\"` y=$TIMESTAMP\"0000000\" #Adjust the number of zeros according to the number of digits in the date (19 digits max on 64bit systems). echo \"\" > $TIMESTAMP\"_log.txt\" for file in \"${files[@]}\"; do #echo \"cp \\\"$file\\\" /home/rob/Pictures/Screenshots/xyz/$y.png\" echo \"magick '$file[800x600]' /home/rob/Pictures/Screenshots/xyz/$y.jpg\" echo \"\\\"$file\\\" = $y.jpg\" >> $TIMESTAMP\"_log.txt\" ((y++)) done","title":"Increment with array example to convert png files to jpg using ImageMagick:"},{"location":"bashstuff/#using-the-following-1-line-command-for-renaming-files-in-linux-using-a-specific-phrase","text":"find -type f -name ' .jpg' | rename 's/holiday/honeymoon/' For all files with the extension \".jpg\", if they contain the string \"holiday\", replace it with \"honeymoon\". For instance, this command would rename the file \"ourholiday001.jpg\" to \"ourhoneymoon001.jpg\". This example also illustrates how to use the find command to send a list of files (-type f) with the extension .jpg (-name ' .jpg') to rename via a pipe (|). rename then reads its file list from standard input. Source:","title":"Using the following 1 line command for renaming files in linux using a specific phrase:"},{"location":"bashstuff/#grep-for-multiple-things-at-once","text":"The '-e' option allows you to search for multiple things. It is kind of like an 'or' statement. Example below, find postfix or mailx. rpm -qa |grep -e postfix -e mailx","title":"Grep for multiple things at once:"},{"location":"bashstuff/#find-graphics-or-video-card-information","text":"lspci -k | grep -EA3 'VGA|3D|Display'","title":"Find Graphics or Video Card Information:"},{"location":"blueparrot/","text":"How to connect BlueParrott headset to computer: With the headset powered off, press the MFB until the light rapidly flashes blue and you hear the audio prompt \u201cpower on .\u201d Keep holding the MFB for approximately 10 seconds until you hear \u201cPair Mode .\u201d The headset will be visible for pairing to devices for 120 seconds.","title":"Blue Parrot"},{"location":"blueparrot/#how-to-connect-blueparrott-headset-to-computer","text":"With the headset powered off, press the MFB until the light rapidly flashes blue and you hear the audio prompt \u201cpower on .\u201d Keep holding the MFB for approximately 10 seconds until you hear \u201cPair Mode .\u201d The headset will be visible for pairing to devices for 120 seconds.","title":"How to connect BlueParrott headset to computer:"},{"location":"exiftool/","text":"Frequently Asked Questions: https://exiftool.org/faq.html#Q1 Source: : https://exiftool.org/forum/index.php?topic=10562.0 To write a new copyright, use something like this exiftool -IPTC:CopyrightNotice=\"\u00a9 [Year], [Your Name]\" [image file] exiftool -IPTC:CopyrightNotice=\"\u00a9 2023, John Doe\" my_photo.jpg exiftool -Copyright=\"New Notice\" -CopyrightNotice=\"New Notice\" -Rights=\"New Notice\" <FileOrDir> exiftool -Copyright=\"Copyright 2002, Robert Holland\" -CopyrightNotice=\"\u00a9 2002, Robert Holland\" -Rights=\"All rights reserved.\" *.jpg That will set the three major copyright tags to what you want. If you want to batch recurse into subdirectories, use the -r (recurse) option. This command will make backup files. Use the Overwrite_Original option to suppress that. Add the -P (preserve) option to keep the current file system modify date. Source: : https://exiftool.org/forum/index.php?topic=4837.0 Set the copyright flag to true: exiftool -all= -Holland:CopyrightFlag='True' soccer*.webm Exiftool function: gpsinfo() { case $1 in #-n = Put the coordinates in decimal format. #-csv = Put the output in .csv format. #-T = Put the output in wide format. #-t = Put the output in column format. #-ext = Look for the following file extension. #DIR1 = The directory to look in for photos. #DIR2 = The directory to output the csv file. #exiftool -filename -gpslatitude -gpslongitude -gpsaltitude -createdate -relativealtitude -T -n -csv -ext JPG DIR1 > DIR2\\out.csv ##exiftool -T -FileName -GPSPosition -c \"%.6f\" * > GPSInfo.txt #exiftool -T -Filename -createdate -gpsposition -c \"%.6f degrees\" -Filename *| sed 's/://g'| sed 's/,\\ /_/g'| sed 's/\\ degrees\\ /_/g' > GPSInfo.sh;chmod +x GPSInfo.sh ##exiftool -T -Filename -createdate -gpsposition -c \"%.6f degrees\" -Filename *| sed 's/://g'| sed 's/,\\ /_/g'| sed 's/\\ degrees\\ /_/g'|awk '{print \"mv \" $1 \" \"$2$3\".\"$4\".\"$5}' > GPSInfo.sh ##exiftool -T -Filename -DateTimeOriginal -gpsposition -c \"%.6f degrees\" -Filename * | sed 's/://g'| sed 's/,\\ /_/g'| sed 's/\\ degrees\\ /_/g'|awk '{print \"mv \" $1 \" \"$2$3\".\"$4\".\"$5}' > GPSInfo.sh ##exiftool -T -Filename -FileModifyDate -gpsposition -c \"%.6f degrees\" -Filename * | sed 's/://g'| sed 's/,\\ /_/g'| sed 's/\\ degrees\\ /_/g'|awk '{print \"mv \" $1 \" \"$2$3\".\"$4\".\"$5}' > GPSInfo.sh ##exiftool -T -Filename -DateTimeOriginal -gpsposition -c \"%.6f degrees\" -Filename * | sed 's/://g'| sed 's/,\\ /_/g'| sed 's/\\ degrees\\ /_/g'|awk '{print \"mv \" $1 \" \"$2$3\".\"$4\".\"$5}' > GPSInfo.sh #!#TESTING: Change the timezone for DateTimeOriginal to -7. #!# exiftool -T -Filename \"-DateTimeOriginal-=0:0:0 7:0:0\" -gpsposition -c \"%.6f degrees\" -Filename * | sed 's/://g'| sed 's/,\\ /_/g'| sed 's/\\ degrees\\ /_/g'|awk '{print \"mv \" $1 \" \"$2$3\".\"$4\".\"$5}' > GPSInfo.sh #This works: exiftool -n -filename -gpslatitude -gpslongitude -csv -r . >> out.csv #Source: https://exiftool.org/forum/index.php?topic=3075.0 crdate) exiftool -T -FileName -GPSPosition -c \"%.6f\" * > GPSInfo.txt exiftool -T -Filename -createdate -gpsposition -c \"%.6f degrees\" -Filename *| sed 's/://g'| sed 's/,\\ /_/g'| sed 's/\\ degrees\\ //g'|awk '{print \"mv \" $1 \" \"$2$3\".\"$4\".\"$5}' > GPSInfo.sh ;chmod +x GPSInfo.sh ;; dttimeorig) exiftool -T -FileName -GPSPosition -c \"%.6f\" * > GPSInfo.txt exiftool -T -Filename -DateTimeOriginal -gpsposition -c \"%.6f degrees\" -Filename * | sed 's/://g'| sed 's/,\\ /_/g'| sed 's/\\ degrees\\ //g'|awk '{print \"mv \" $1 \" \"$2$3\".\"$4\".\"$5}' > GPSInfo.sh;chmod +x GPSInfo.sh ;; filemoddt) exiftool -T -FileName -GPSPosition -c \"%.6f\" * > GPSInfo.txt exiftool -T -Filename -FileModifyDate -gpsposition -c \"%.6f degrees\" -Filename * | sed 's/://g'| sed 's/,\\ /_/g'| sed 's/\\ degrees\\ //g'|awk '{print \"mv \" $1 \" \"$2$3\".\"$4\".\"$5}' > GPSInfo.sh ;chmod +x GPSInfo.sh ;; subsecdtorig) exiftool -T -FileName -GPSPosition -c \"%.6f\" * > GPSInfo.txt exiftool -T -Filename -SubSecDateTimeOriginal -gpsposition -c \"%.6f degrees\" -Filename * | sed 's/://g'| sed 's/,\\ /_/g'| sed 's/\\ degrees\\ //g'|awk '{print \"mv \" $1 \" \"$2$3\".\"$4\".\"$5}' > GPSInfo.sh;chmod +x GPSInfo.sh ;; showdates_allfiles) exiftool -a -G1 -s -time:all * ;; *) Message=\"Usage:\" Message0=\"----- gpsinfo crdate\" Message1=\"----- gpsinfo dttimeorig\" Message2=\"----- gpsinfo filemoddt\" Message3=\"----- gpsinfo subsecdtorig\" Message4=\"----- gpsinfo showdates_allfiles\" Message5=\"----- Type: \\\"exiftool -t filename\\\" to see the fields available.\" echo $Message echo $Message0 echo $Message1 echo $Message2 echo $Message3 echo $Message4 echo $Message5 ;; esac } Show all dates from a file: exiftool -time:all -a -G0:1 -s 01590009.jpg Change date: exiftool -exif:createdate=\"2002:04:20 16:00:00.00-07:00\" *.jpg exiftool -exif:dateTimeOriginal=\"2002:04:20 16:00:00.00-07:00\" *.jpg Add date (only if dateTimeOriginal is not there, otherwise there will be a duplicate dateTimeOriginal). exiftool -xmp:dateTimeOriginal=\"2002:04:20 16:00:00.00-07:00\" *.jpg Display the UserComment and Filename of a file: exiftool -UserComment -FileName *.jpg Copy Exif data from sourcefile to destinationfile: exiftool -TagsFromFile source.jpg destination.jpg Extract Exif data to a file: exiftool -ee source.jpg > somefilename.txt Extract Exif data to a .GPX file: First: git clone https://github.com/exiftool/exiftool.git Second: Find the correct file format that you want to use (gpx.fmt) located in the fmt_files folder. Syntax: -p = means to use the .gpx format when creating the output filename. -ext mp4 = means to only look at .mp4 files. -ee = means to extract everything (metadata). -w = means to write out the data. %f = means to write the .gpx filename with the same name as the original filename. exiftool -p gpx.fmt -ee -ext mp4 -w %f.gpx .","title":"Exiftool"},{"location":"fedora_keyring/","text":"KeyRing File Location Important points: Location of keyring files: The keyring files are usually located in the \"~/.local/share/keyrings\" directory. Alternative method (command line): If you prefer using the command line, you can navigate to the keyring directory and delete the relevant keyring files, but be cautious as this can cause data loss if not done correctly.","title":"Fedora Keyring"},{"location":"fedora_keyring/#keyring-file-location","text":"Important points: Location of keyring files: The keyring files are usually located in the \"~/.local/share/keyrings\" directory. Alternative method (command line): If you prefer using the command line, you can navigate to the keyring directory and delete the relevant keyring files, but be cautious as this can cause data loss if not done correctly.","title":"KeyRing File Location"},{"location":"ffmpeg/","text":"FFMPEG Convert m4a to mp3: ffmpeg -i input.m4a -c:a libmp3lame -q:a 8 output.mp3 Convert .flv videos to .mp4\" ffmpeg -i Videoname.flv -vcodec copy -acodec copy Videoname.mp4 Convert file1 to file2: ffmpeg -i $1 -vcodec copy -acodec copy $2 Convert mp4 to webm: ffmpeg -i test.mp4 -c:v libvpx-vp9 -crf 30 -b:v 0 -b:a 128k -c:a libopus test.webm Bash script to convert multiple Sony mts files to mp4 files: ffmpegbatch(){ if [ $# -ne 2 ] then echo . Usage: ffmpegbatch MTS mp4 else for f in *.$1; do ffmpeg -i $f -vcodec copy -acodec copy ${f%$1}$2; done fi } Bash script to convert multiple .wav files to .mp3 and .ogg files: Source: https://superuser.com/questions/373889/batch-convert-wav-to-mp3-and-ogg for f in *.{wav,WAV}; do ffmpeg -i \"$f\" -c:a libmp3lame -q:a 2 \"${f%.*}.mp3\" -c:a libvorbis -q:a 4 \"${f%.*}.ogg\"; done","title":"FFMEG"},{"location":"ffmpeg/#ffmpeg","text":"Convert m4a to mp3: ffmpeg -i input.m4a -c:a libmp3lame -q:a 8 output.mp3 Convert .flv videos to .mp4\" ffmpeg -i Videoname.flv -vcodec copy -acodec copy Videoname.mp4 Convert file1 to file2: ffmpeg -i $1 -vcodec copy -acodec copy $2 Convert mp4 to webm: ffmpeg -i test.mp4 -c:v libvpx-vp9 -crf 30 -b:v 0 -b:a 128k -c:a libopus test.webm Bash script to convert multiple Sony mts files to mp4 files: ffmpegbatch(){ if [ $# -ne 2 ] then echo . Usage: ffmpegbatch MTS mp4 else for f in *.$1; do ffmpeg -i $f -vcodec copy -acodec copy ${f%$1}$2; done fi } Bash script to convert multiple .wav files to .mp3 and .ogg files: Source: https://superuser.com/questions/373889/batch-convert-wav-to-mp3-and-ogg for f in *.{wav,WAV}; do ffmpeg -i \"$f\" -c:a libmp3lame -q:a 2 \"${f%.*}.mp3\" -c:a libvorbis -q:a 4 \"${f%.*}.ogg\"; done","title":"FFMPEG"},{"location":"git/","text":"Configuring git: For all users on the system: git --config system For user level: git --config global Set username and email address: git config --global user.name \"Robert Holland\" git config --global user.email rob@example.com Set the colors for git: git config --global color.ui auto git config --global color.ui true Set the pager for git diff: git config --global core.pager 'less -R' The git config --global command is also used to create aliases. Reset author: After updating my username and email address I had to reset the author by typing: git commit --amend --reset-author (can use this to reset the author for the latest commit) View git configuration: If you want to see what is already configured: git config --list View git username and email address: If you want to see the username or email address: git config user.name git config user.email To configure the preferred editor: git config --global core.editor \"EditorNameHere\" git config --global core.editor \"mate -wl1\" (wait for textmate to finish and put the cursor on line one). git config --system color.ui true Exploring Git Auto-completion: Download git-completion.bash and rename it to .git-completion.bash. Download it from here: curl -OL https://github.com/git/git/raw/master/contrib/completion/git-completion.bash Rename the file to .git-completion.bash (notice the leading dot (.): mv git-completion.bash .git-completion.bash Enter this in the .bash_profile or equivalent: #Git configuration file: if [ -f ~/.git-completion.bash ]; then source ~/.git-completion.bash fi Create a new repository on the command line make a new directory then type: touch README.md git init git add README.md git commit -m \"first commit\" git remote add origin https://github.com/username/reponame.git To add a local repository on Widows: git remote add origin c:/Users/Rob/Documents/Github/php.git git push -u origin master //Only need to do this the first time you push to the server so that the upstream branch gets set. Push an existing repository from the command line: git remote add origin https://github.com/username/reponame.git git push -u origin master //Only need to do this the first time you push to the server so that the upstream branch gets set. Git checkout: Undo changes to the git repository: I changed a file and saved it but I have not staged (git add) it yet. Git status shows what was changed and I want to undo my changes. To replace the file in the local directory with a copy of what you have in the working area type: git checkout -- filename This will replace the file that you changed with an original version before the change. If you only use git checkout filename (without the dashes), you may accidentally checkout a branch that has the same name as the file you are trying to restore (unlikely because branches don't have extensions). The double dashes -- tells git to stay in the current branch and look for the file you want to restore. Branching: If you want to make another version of your files just make a branch. To create a new branch type: git branch newbranchname Git will automatically copy the master repo into your new branch. Change into the new branch by typing: git checkout newbranchname git checkout -b newbranchname : Will create the new branch and change into it. You can make changes without disturbing the master files. If all goes well you can merge your changes into the master branch. Track a branch If you have a branch that is not tracking you can add it to be tracked by typing: git config branch.branchname.remote origin or git config branch.branchname.merge refs/heads/master or git branch --set-upstream branchname origin/branchname (This works with version 1.7 and later). or git branch --set-upstream-to=origin/<branch> master Merge branch: To merge your new branch into master, first go to the master branch by typing: git checkout master then type: git merge branchname The master branch will now have the same changes as branchname To back out of a merge conflict type: git merge --abort This will leave your changes alone and not do the merge. To update a branch with the latest changes from master: You have two options: The first is a merge, but this creates an extra commit for the merge. Checkout each branch: git checkout branch1 Then merge: git merge origin/master Then push: git push origin branch1 Alternatively, you can do a rebase (easier): git fetch git rebase origin/master If you want to change or revert the master branch to the previous commit: Checkout previous commit on master git checkout abc123... While in the abc123... detached branch, create branch for new master git checkout -b new_master Delete old master git branch -D master Make new_master master git branch -mv new_master master Alternatively you can reset current branch to one commit ago on master (See git reflog for recovery of local branches). git reset --hard abc123... Then you will have to force push to the repository: git push --force origin master Try this if you get an error force pushing \"error: denying non-fast forward refs/heads/master (you should pull first)\" and you have access to the remote git server in ssh, you can go into the git remote directory and set: git config receive.denyNonFastforwards false If all fails or you don't have access to the remote repository, just make an update commit correcting the error. If you want to delete the branch (make sure you are on the master branch) type: git branch -D branchname If you want to see all of the branches: git branch -a git branch show-all <-- Doesn't seem to show all branches unless you have checked them out at some point. If you want to see only the remote branches: git branch -r If you want to see only local branches: git branch If you want to see the branches along with the latest commit message: git branch -v How to find out if one branch has all of the commits of another branch. git branch --merged (This will show a list of all of the branches that contain what is in your current branch. This will allow you to delete the other matching branches without causing any harm). Git diff To see all of the changes made to the files type: git diff You can see a line by line difference between what is in the repository or staging area compared to what is in the working area. If you just want to see what is in a single file type: git diff singlefilename If you have already staged a file and want to see the differences between that staged file and what you have in the repository then type: git diff --staged diff between two different commits in the same branch, you can put the SHA of the oldest commit first then the SHA of the latest commit last to see what is not in (or missing) from the first file. git diff d861a745:/path/to/filename.txt 118192cf:/path/to/filename.txt diff between two different commits in the same branch, you can put the SHA of the latest commit first then the SHA of the older commit last to see what was added to the file. git diff 118192cf:/path/to/filename.txt d861a745:/path/to/filename.txt diff but don't show file mode changes. git diff -G\".\" Word Wrap When you are in the diff view you can use the (minus sign + shift + S) to word wrap the long lines. Repeat the same key combination to undo the word wrap. Also you can see the changes side by side by typing: git diff --color-words filename Git blame: To see all the changes line by line in a file and who made the change over time type: git blame -w filename The -w does not show differences in whitespace. Commits If you want to commit a file and add a message: commit --message=\"This is my message.\" \"filename.txt\" If you want to see a particular commit type: git show [SHA Key] To see the commits for only one file: git log --follow filename To see the SHA for files for a specific commit (-r will recurse directories): git ls-tree -r HEAD #This will show the current head. or git ls-tree -r HEAD ab12cd34ef56 #This will show a specific commit. or git ls-tree -r HEAD^^ #This will show two commits ago. or git ls-tree -r HEAD~2 #This will show two commits ago. Undo changes in the staging area: I have made a change to a file and it shows up as changed in the working area. I used git add filename to add the file to the staging area. Now I want to take the file out of the staging area and put it back in the working area. git reset HEAD filename You will see an \"M\" next to the file that indicates that the staging area was modified. The -a option sends the commit directly to the repository skipping the staging area: git commit -am \"Message\" You cannot use the \"-am\" option when committing modified files individually. This is used in situations where you have multiple files that have been modified but you only want to commit some of them. The \"-a\" will have to be left out, only use \"-m\". Example: git commit -m \"Commit message\" \"File1.txt\" \"File2.txt\" Amending Commits: You can only amend the last commit because it doesn't have any more commits after it. Once you have added another commit you can't amend a previous commit. If you need to change previous commit just make a new commit with the changes that you need. I have already committed a file and then I make another change to the file and add it to the staging area. I want to commit the additional change into the previous commit: git commit --amend -m \"Same message or different one.\" Add a \"Sign-off\" to the commit type: git commit -s -am \"Message\" To use GPG/PGP to sign a commit you must first configure Git with your GPG/PGP key so that it can be used. git config user.signingkey <HEX KEY ID> or for global setting using the same key for every repository. git config --global user.signingkey <HEX KEY ID> To GPG/PGP sign a commit type: git commit -S -am \"Message\" <--(Uppercase S for GPG signed commits). Can use the same command to change the commit message. You can amend a commit that is previous to the most recent commit. You will have to use git to checkout the commit using the SHA hash and then re-commit it with the new changes. git checkout 2d2323d23423d -- filename This will put the file in the staging area and not the working area. When you checkout a file from the staging area it will go to the working area. (git diff --staged) Git Revert: Undo the changes made by a commit. It will take all of the changes and add everything that was deleted and delete everything that was added. git revert SHA Git reset: Moves the HEAD pointer. Similar to making a recording on a tape then rewinding 10 seconds and recording again. Has 3 options. git reset --soft sha Does not change the staging index or working directory. Only the repository is set back to an earlier version. git reset --mixed sha (default) Changes the staging index to match the repository. Does not change the working directory. --mixed is almost as safe as --soft. git reset --hard sha changes staging index and working directory to match the repository. (Rewinding 10 seconds and pressing record.) It removes every change that was made before the commit that you select. How to undo almost anything: git reflog Git clean: Remove unwanted files from your git directory. git clean -n (does a dry run) git clean -f (permanently deletes the untracked files from your directory) (see cached option under git ignore below for how to remove files that have been previously tracked but you don't want to track them anymore. Git Ignore Create a file in the root directory called .gitignore and place files and extensions in .gitignore that you want git to ignore. Can use regular expressions: * ? [aeiou] [0-9] Negate expressions with ! Example: !index.php tells git to not ignore index.php. Ignore all files in a directory with a trailing slash. DirectoryName/DirectoryName/ Comment with # Global Ignore Put all of your git ignore commands in one file and point git to it using: git config --global The file can be named anything you want. You just have to tell git where it is. git config --global core.excludesfile path/to/filename (Ex: .ignore_global) Ignore files that have been previously tracked but you don't want to track them anymore. You can use the git rm command to delete the file from your directory and git will automatically remove it from being tracked by the repository. If you want to keep the file but remove it from being tracked you can use: git rm --cached filename This removes the file from being tracked by git. If you do a git status it will show as \"deleted\" but it really isn't. It is just no longer being tracked. Git does not track empty directories. If you want to track a directory you will have to put a file in it. Most commonly people put a file named .gitkeep or placeholder.txt inside the directory so that git will watch the directory. Comparing Branches: git diff master..newbranch The branch listed second in your command is the \"b\" branch in the diff output. A different view for diff: git diff --color-words newbranch..master If you want to compare two branches but not the latest commit of one branch (the previous commit): git --color-words master..newbranch^ If you want to compare a file from the most recent commit on the master branch to the most recent commit on the 32a79a7 branch (the number 0 is the most recent commit of that branch, 1 would be the second most commit): git diff master~0 32a79a7~0 php/update_cal.php If you wanted to compare the same file between two different branches. *The branch listed second is the \"b\" branch in the diff output: git diff master newtest -- testing.txt Rename branches: Switch to the branch that you want to rename. git branch -m oldbranchname newbranchname git branch --move oldbranchname newbranchname Using fast-forward vs true merge: Example: If you make a new branch from master and make changes to the new branch without making any changes to master, then merge the new changes into master, you are doing a fast forward merge. No new commit will need to be made because you are just adding more or to \"updating\" master. If you make a new branch and make changes to the new branch and also make changes to master and do a merge then you are doing a true merge and you will have a merge conflict and will need to specify the differences that you want to keep or discard. If you want to specify a merge tool to use when merging files you can do so by typing: git mergetool --tool=NameOfMergeTool Rebase: Process Tracking (rebase) Process tracking is when you merge the master branch into your working branch to update your working branch with new stuff from the master branch. This helps you reduce the number of merge conflicts that occur when you finally have to merge your changes back into master. Stash/Stashing A stash is not a commit and they do not have a SHA associated with them. You use \"stash\" when you are in one branch then try to checkout another branch without first saving the changes for the branch you are in. You will get a message telling you that you will lose the changes that you have already made. You can save them by stashing them and then continue to checkout the other branch. To stash type: git stash save \"Message for stash.\" If you want to see a list of items in the stash type: git stash list You will see stash{0}, stash{1}, etc. It doesn't matter which branch you are on, you will still be able to see the stash and pull it out of the stash. This is helpful if you realize you are making changes to the wrong branch. Just stash the changes and checkout the branch you need to apply the changes to and apply the stash. If you want to see a particular stash, you will have to reference it by its number. For example: If I wanted to see what was in stash{0} I would type: git stash show stash@{0} To see the stash in a more detailed way (diff), you will have to use the \"Patch\" option. Type: git stash show -p stash@{0} To take the stash out of the stash repository you can use two commands: git stash pop git stash apply The difference is that git stash pop will remove the stash from the stash repository and git stash apply will leave a copy in the stash repository. Delete single items that are in the stash type: git stash drop 0 Delete all items in the stash by typing: git stash clear Remote Branches: If you want to see all of the branches on the remote type: git remote git remote -v (more verbose information) If you want to add a remote repository type: git remote add <alias> <url> Example: git remote add origin https://github.com/rlholland/reponame.git You don't have to use the name \"origin\" you can change it to anything you want. You can clone a repository that you don't own and make changes to it then push your changes to your own repository. Just use git remote add and create another path to your repository. Example: git remote add new-origin path-to-new-repository Now you can push-pull to the new-origin and also pull updates from the old origin that you don't own. Change/Update URL: If you want to change/update the URL in .git/config to point to a different repository: git remote set-url <alias> <url> Example: git remote set-url origin B:/Millennium/mPage/gitrepositories/azb_custom_components.git This method defaults to SSH. git remote set-url origin git@github.com:rlholland/remoterepositoryname.git This method specifically uses SSH. git remote add origin ssh://username@servername/path/to/repository.git If you want to remove a remote repository type: git remote rm remoterepositoryname Example: git remote rm origin If you want to look at the remote SHA you can type: cat .git/refs/remotes/origin/master This will show you the latest SHA on the remote Clone: If you want to clone a remote repository into a folder that you name type: git clone https://github.com/rlholland/reponame.git newlocalfoldername You can also clone a specific branch by using the -b option. Example: git clone -b <branch> <remote_repo> git clone -b thebranchname git@github.com:user/myproject.git If you want to clone using SSH: git clone ssh://username@servername/absolute/path/to/git/repo.git Push: If you want to push all changes: git push --all \"https://github.com/rlholland/reponame.git\" Log: If you want to see the commits that were made to the git repo, type: git log This will show you all of the commits and the messages that were entered when the commit was made. If you want to limit the display of message to a certain number then type: git log -n 10 This will limit the number of messages displayed on the screen to 10. If you want to see all of the commits from the beginning up to a certain date type: git log --until=2014-05-25 If you want to see all of the commits since a certain date to the present type: git log --since=2014-05-25 You can use both commands together to see commits between two dates. git log --since=\"two weeks ago\" --until=\"3 days ago\" git log --since=\"two.weeks\" --until=\"3.days\" You can see commits made by a specific person (author) by typing: git log --author=\"Robert\" (can use quotes if search term has a space). You can search the commit messages for an expression by using grep (Global Regular Expression). Type: git log --grep=\"Text you are looking for\" (this is case sensitive). You can ignore case with: git log --grep=\"Text you are looking for\" -i (the dash \"i\" will ignore case). You can show the log file by SHA: git log SHA1..SHA2 Example: git log 23fadf323..938533arad --oneline The --oneline shows part of the SHA and the commit on one line. git log --format=oneline shows the complete SHA and message on one line. You can show the log on just one file from a certain point and view the changes. git log -p SHA.. index.html git log -p --since=\"2014-04-01\" index.html (The -p shows the differences) To see the status or summary of the commits you can use: git log --stat git log --summary git log --stat --summary Git can search diffs with the -S option (it's called pickaxe in the docs) http://stackoverflow.com/questions/4468361/search-all-of-git-history-for-a-string Search: It's also possible to search for commits that introduce or remove a particular line of source code. This is called a pickaxe, and it takes the form of -S\" \". For example, if you want to know when the string Hello, World! was added to any file in the project, you would use the following command: git log -S\"Hello, World!\" Find any commit that added or removed the string password. git log -Spassword Patch: git log -p will show the diffs. If you provide a file (-p file), it will generate a patch for you. git log -G looks for differences whose added or removed line matches the given regexp, as opposed to -S, which \"looks for differences that introduce or remove an instance of string\". git log --all searches over all branches and tags; alternatively, use --branches[=<pattern>] or --tags[=<pattern>] If you want to search using a regular expression instead of a string, you can use the -G\" \" flag instead. This is a very powerful debugging tool, as it lets you locate all of the commits that affect a particular line of code. It can even show you when a line was copied or moved to another file. To see a GPG signature: git log --show-signature A good Git log command to show a lot of detail is: git log --graph --oneline --decorate --all If you want to see the log for a specific branch type: git log specificbranch --oneline -3 (the -3 shows the latest 3 logs) If you want to see the log differences in patch mode type: git log -p branchname..origin/branchname If you only want to see the log entries for particurlar files type: git log -- foo.txt bar.txt Git Fetch This synchronizes any remote branches we don't have locally so when you type git branch it will show you all of the branches. If you want to fetch type: git fetch origin If you are tracking you don't need to type the \"origin\" just type: git fetch Three basic guidelines: Always fetch before you work. Fetch before you push Fetch often You can also use \"git pull\" Git Pull git pull does the same thing as git fetch except it automatically does the merge. git pull = git fetch + git merge Checkout Remote Branches These commands will checkout the branch and track them: git branch newbranchname HEAD git branch newbranchname anycommitSHA git branch newbranchname origin/branchname To delete a remote branch use a colon: git push origin :branchname A little information history on the git push command. It used to be done like this: git push origin branchname:branchname. The colon between them means that you are telling git to push to origin the local branchname to the remote branchname. If you don't specify the colon and you only have one branchname, git assumes they are the same. So the git push origin :branchname means to push to origin nothing locally to the remote branchname. The remote branchname is now getting nothing pushed to it and is deleted. The new way to delete a branch is: git push origin --delete branchname If you want to modify someones elses code that you find on GitHub, you will have to \"Fork\" it then make your changes. Once you are done with your changes, you can create a \"Pull Request\" so that the original owner can look at your code and decide to incorporate it into theirs. Configure the prompt to show the git branch when in a git repo: Edit the .bashrc file and enter below BEGIN: # Git specific environment and startup programs if [ -f ~/.git-prompt.sh ]; then source ~/.git-prompt.sh fi #Git Prompt PS1=\"[\\u:\\w]\\$(__git_ps1)$ \" #<-- On Fedora Linux export PS1='\\W$(__git_ps1 \"(%s)\") > ' #<-- On Mac OSX setopt PROMPT_SUBST ; PS1='[%n@%m %c$(__git_ps1 \" (%s)\")]\\$ ' #<-- On Mac OSX ZSH END: Source: https://stackoverflow.com/questions/15883416/adding-git-branch-on-the-bash-command-prompt If the shell does not load the .git_prompt.sh file you may see the following error on the command line. __git_ps1: command not found If you want to see the current prompt string \"PS1\" settings type \"echo $PS1\" Configuring Git Aliases You can create aliases for Git in the .gitconfig file two ways. You can edit the file directly or you can use the git config --global command. For example: I didn't want to type the entire log line below so I created a shortcut for it in the .gitconfig file by using the git config --global command. git log --graph --oneline --decorate --all I created an alias for it named \"logg\" by typing: git config --global alias.logg \"log --graph --oneline --decorate --all\" Now I only have to enter \"git logg\" to get the same output. Re-install Git icons on Windows github --reinstall-shortcuts Here are some more common Git aliases: git config --global alias.co checkout git config --global alias.cm commit git config --global alias.br branch git config --global alias.dfs \"diff --staged\" git config --global alias.logg \"log --graph --oneline --decorate --all\" Setup Two-Factor Authentication: Git credentials: Immediately stop the credential manager on a Mac if you have your password stored/cached for a specific amount of time. git credential-cache exit On a MAC: To remove your credentials from the OSX Keychain and configure for two-factor authentication, type the following at the command prompt: git credential-osxkeychain erase protocol=https host=github.com (press enter twice to finish) You now need to get a personal access token from Github. Log into Github and select \"Security\" and enable two-factor authentication. Click on \"Developer settings\" then \"Personal Access Token\" and click the \"Generate New Token\" button. If you use more than one computer, it is a good idea to include the name of your computer in the name of the token so that you can revoke it if necessary. Copy the token and paste it in when you are prompted for your password during a commit. On Windows: You have to install Github Desktop which has the two-factor authentication built in (just sign in with your Github.com account and that should get two-factor setup for the GUI part. If you want to use the same two-factor from the command line, you will have to install \"Git for Windows (https://git-scm.com/download/win)\". Once that is installed, go to Github desktop and click the \"Repository\" dropdown and depending on which shell you have configured under \"Options\" --> \"Advanced\", either select \"Open Git Command Prompt\", \"Open Git Powershell\", or \"Open Git in Bash\". (If you try to push without the correct configuration in the .gitconfig file, you may see a message similar to the one below: fatal: unable to access 'https://github.com/rlholland/gitnotes.git/': SSL certificate problem: unable to get local issuer certificate) Once you have your favorite command prompt open, edit the .gitconfig file (located in the root of your profile directory and/or in your home folder if you are on a network with an automatically mapped home directory) and enter the following so that you can push from the command line using two-factor authentication. [http] sslcainfo=C:/Program Files/Git/mingw64/ssl/certs/ca-bundle.crt sslbackend=schannel (Check for the correct path to ca-bundle.crt if you are using 32bit Windows). After the .gitconfig file has been modified and saved, do a push from your repository and you should not get prompted for a password. Your two-factor authentication is setup for your computer. If you lose your computer or misplace it, you can always log into Github and revoke your Personal Access Token for that computer. Merging Git Repositories: http://blog.caplin.com/2013/09/18/merging-two-git-repositories/ List of Gui Interfaces for Git can be found on the Git Wiki: https://git.wiki.kernel.org/index.php/InterfacesFrontendsAndTools Git Hosting There are two ways to host, Use a hosting company or host yourself. Popular Git hosting companies are: http://github.com http://bitbucket.org http://gitorious.org Self-Hosting: Gitosis - http://github.com/tv42/gitosis (development for this stopped a few years ago) Gitolite - http://github.com/sitaramc/gitolite Git Tutorials Michael's Git Tutorial - Setting Up a Git Server https://www.youtube.com/watch?v=SyMkLQLC3Kg How to Setup a Git SSH Server and Client on Ubuntu https://www.youtube.com/watch?v=lXSZUuDW4nY Creating a Git Server on a Windows OS https://www.youtube.com/watch?v=w3eRlEhzAZk&ebc=ANyPxKpNRpbhQZ_nlL7IxaYeM_5rOLOI2RPJi2kv1jJuw6DUEEe14nsBvDRHvBjQKmO7DIvaOUzprWUCtFUXdcO9X-cLOpYrHg Pushing to GitHub with HTTPS and 2-Factor authentication https://www.youtube.com/watch?v=hJLaXNMz8zw http://www.linux-magazine.com/Online/Features/Install-Your-Own-Git-Server http://studyhat.blogspot.com/2010/10/install-your-own-git-server-on-cent-os.html http://fedoracoreproject.blogspot.com/2010/02/how-to-install-vnc-server-on-fedora.html GitHub Instructions - http://git-scm.com/book/en/v2/Git-on-the-Server-The-Protocols GitHub Instructions - http://git-scm.com/book/ch4-7.html Installing on AIX, HP-UX, Solaris - http://blog.boreas.ro/2008/03/porting-git-to-hp-ux-pa-risc-and-aix.html Ubuntu Server Configuration: To find the Gateway: route -n On the server: sudo vi /etc/network/interfaces (Set the eth0 interface to a static IP address) auto lo iface lo inet loopback auto eth0 iface eth0 inet static address 192.168.1.2 netmask 255.255.255.0 gateway 192.168.1.1 From the client: sudo vi /etc/hosts (enter the Git Server's information) sudo vi /etc/ssh/sshd_config (Configure SSH to accept access by SHA key instead of tunnelled clear text passwords) #Find the line that says: PasswordAuthentication yes #and change it to read: PasswordAuthentication no #uncomment the line. sudo restart ssh If you want to use the Git user: sudo adduser git su - git mkdir .ssh chmod 700 .ssh touch .ssh/authorized_keys chmod 600 .ssh/authorized_keys (Make sure only the owner has access rights) Create an RSA key on the client and copy it to the server. ssh-keygen -t rsa ssh-keygen -t rsa -b 4096 (See below to copy the public key to the git user authorized_keys file on the server.) This method will allow ssh://git@servername/path/to/repo.git to be used for push pull operations. Another method using openssl: openssl genrsa -out id_rsa 4096 openssl rsa -in id_rsa -pubout > id_rsa.pub Send your \"public\" key to the server: cat ~/.ssh/id_rsa.pub | ssh user@remote-server \"mkdir -p ~/.ssh && cat >> ~/.ssh/authorized_keys\" Install Git on the server (if it isn't installed already): sudo apt-get -y install git Find out what shells are currently in use: cat /etc/shells Find out which shell git is using: From the git user login type: which git-shell Add the information from 'which git-shell' command to the list of valid shells in the /etc/shells file. Example /etc/shells file content: /bin/sh /bin/bash /bin/rbash /bin/dash /usr/bin/git-shell On Fedora 24 and 25, the chsh command is used to change the shell. It may not exist by default. Install the package that contains chsh: dnf install util-linux-user Change the git user login shell to git-shell: sudo chsh git Enter: /usr/bin/git-shell If you try to log into the git user from the command line after the git shell is enabled, you will see a message similar to this: fatal: Interactive git shell is not enabled. hint: ~/git-shell-commands should exist and have read and execute access. On the Server, create a git repository: mkdir -p /opt/git Give the git user access to the git folder where the repositories will live. Use with caution! This will overwrite group shared repositories if they already exist within the git repository. sudo chown -R git:git /opt/git Create a git repository and a project: mkdir -p /opt/git/project-name.git cd /opt/git/project-name.git git init --bare git init --bare --shared (if the repository will be shared by a group) If your repository is only going to be used by one user then you can just use the git user for simplicity. Change the owner of theprojectname.git to the git user and group. sudo chown -R git:git /opt/git/theprojectname.git sudo chmod o-rwx /opt/git/theprojectname.git (remove access to anyone else). If your repository will be used by multiple people, create a group for the Git repository. To create a group: sudo groupadd thegroupname or sudo addgroup thegroupname To add a user to the group: sudo usermod -a -G thegroupname theusername or sudo useradd -G thegroupname theusername To remove a user from a group (Remove the user billybob from the group hillbilly): gpasswd -d billybob hillbilly Make sure the group has access to the repository: sudo chgrp -R thegroupname thereponame.git (-R set the group ownership recursively). sudo chmod g+rws thereponame.git (set the sticky bit so changes are owned by the group). sudo chmod o-rwx thereponame.git (remove access for \"other\" so only group members can clone). On the client, create a repository: Configure the git username and email from the instructions above. Create a local git repo called project-name mkdir -p project-name Initialize the git repo git init Add some files and commit them: git add . git commit -m \"initial commit\" Link your local repository to the server. If you are using the git user (before pushing commits see generating SSH keys below): git remote add origin git@gitserver/opt/git/project-name.git If you are using your own username that is a member of the group that has access to theprojectname.git: git remote add origin ssh://username@servername/opt/git/theprojectname.git Push your files: git push origin master After the initial push you only need to type: git push Methods to push all branches: git push origin '*:*' git push origin --all git push REMOTE '*:*' git push REMOTE --all To automatically push all branches to their matching branch: git config --global push.default matching To only push the current branch to its matching branch: git config --global push.default simple If you are using the git user you will need to generate a public and private SSH key for authentication (unless you know the password for the git user). To generate the SSH keys: If there is no .ssh directory in your home directory you will have to create one. mkdir .ssh Change the permissions to 700. chmod -R 700 .ssh cd ~/.ssh ssh-keygen -t rsa -Accept the default name. -You can enter a password if you like. If you do not, you can take advantage of automatic authentication using your public SSH key (id_rsa.pub) amd private SSH key (id_rsa) pair. Add the contents of your public key to the git users authorized_keys file. Do not overwrite the git users authorized_keys file because anyone else using it will not be able to log in. SSH to GitHub with multiple usernames from the same computer. https://gist.github.com/jexchan/2351996 My steps based on above URL that I took to get this working for github.com/rlholland. I created a separate SSH key using: ssh-keygen -t rsa -b 4096 -C \"rob@robholland.info\" Then I added the SSH key to Github rlholland profile. I was able to clone my rlholland/b repository. git clone git@github.com:rlholland/b.git I was not able to push to the repository until I edited .git/config url = rlholland_github:rlholland/b.git The pattern is: rlholland_github:github_username/github_repository.git My .ssh/config file looks like this for the rlholland repository: Host rlholland_github HostName github.com User git IdentityFile ~/.ssh/rh_info Point repository to a different server and keep the history: If you want to change your repository to point to a different server and still keep the history. Pull everything from your soon-to-be-old-server into your local repository. Create the new repository on the new server. In your local repository update the URL path to the new server (git remote set-url origin ...). See above for example. \"git push origin master\" to the new location. The Git log should still show the history and all of your data will be on the new server. I installed GitExtensions on my Windows laptop and it would not push to a UNC path until I pointed it to GitHub Desktop. GitHub Desktop (Git Shell): C:\\Users\\rlholland\\AppData\\Local\\GitHub\\PortableGit_d7effa1a4a322478cd29c826b52a0c118ad3db11\\usr\\bin C:\\Users\\rlholland\\AppData\\Local\\GitHub\\GitHub.appref-ms --open-shell MINGW32 (Git Bash): C:\\Program Files\\Git\\usr\\bin \"C:\\Program Files\\Git\\git-bash.exe\" --cd-to-home Making Git auto-commit: I'd like to use git to record all the changes to a file. Is there a way I can turn git 'commit' on to automatically happen every time a file is updated - so there is a new commit for every change to a file? Ideally I'd like my users to not even know that git is running behind the scenes. A user could then potentially \"undo\" changes to a file - and this could be achieved by pulling a previous version out of git. On Linux you could use inotifywait to automatically execute a command every time a file's content is changed. Edit: the following command commits file.txt as soon as it is saved: inotifywait -q -m -e CLOSE_WRITE --format=\"git commit -m 'autocommit on change' %w\" file.txt | sh The earlier inotifywait answer is great, but it isn't quite a complete solution. As written, it is a one shot commit for a one time change in a file. It does not work for the common case where editing a file creates a new inode with the original name. inotifywait -m apparently follows files by inode, not by name. Also, after the file has changed, it is not staged for git commit without git add or git commit -a. Making some adjustments, here is what I am using on Debian to track all changes to my calendar file: /etc/rc.local: su -c /home/<username>/bin/gitwait -l <username> /home/<username>/bin/gitwait: #!/bin/bash # # gitwait - watch file and git commit all changes as they happen # while true; do inotifywait -qq -e CLOSE_WRITE ~/.calendar/calendar cd ~/.calendar; git commit -a -m 'autocommit on change' done This could be generalized to wait on a list of files and/or directories, and the corresponding inotifywait processes, and restart each inotifywait as a file is changed. Use the -r flag to inotifywait, but note that the kernel has a limit on the number of inotifywait watches it can set up. man inotifywait will tell you more. This Github repository was recommended: https://github.com/nevik/gitwatch.git. I have cloned it in my personal repository. Source: http://stackoverflow.com/questions/420143/making-git-auto-commit. The index.lock issue: I was getting an error when I made a commit. I can't remember what the error was but I had a choice to answer \"Y\" or \"N\" to retry. I selected \"N\" and then was taken back to the command prompt. I looked on StackOverflow.com and saw a post that someone had submitted about creating the .git/index.lock file and trying the commit again and if it didn't work. Delete the index.lock file which seemed to work for the person that made the post. I tried it and it worked for me. Index.lock issue cannot write to index: While the prompt is still showing \"Do you want to retry Y/N\", open another command prompt and go into the .git directory and copy the index.lock file to index.lock.bak. On Windows: type index.lock > index.lock.bak On Linux: cat index.lock > index.lock.bak Go back to the original command prompt and type \"N\" to not retry. Go back to the other command prompt and copy index.lock.bak into index. type index.lock.bak > index cat index.lock.bak > index del index.lock rm index.lock Type: git status log to see the changes. Websites: https://gist.github.com/hofmannsven/6814451 --> Someones Git notes I found on Github. Instaweb: Git local repository web server (GitWeb): If you want to check out what GitWeb would look like for your project, Git comes with a command to fire up a temporary instance if you have a lightweight web server on your system like lighttpd or webrick. On Linux machines, lighttpd is often installed, so you may be able to get it to run by typing git instaweb in your project directory. If you\u2019re running a Mac, Leopard comes preinstalled with Ruby, so webrick may be your best bet. To start instaweb with a non-lighttpd handler, you can run it with the --httpd option. $ git instaweb --httpd=webrick [2009-02-21 10:02:21] INFO WEBrick 1.3.1 [2009-02-21 10:02:21] INFO ruby 1.8.6 (2008-03-03) [universal-darwin9.0] That starts up an HTTPD server on port 1234 and then automatically starts a web browser that opens on that page. It\u2019s pretty easy on your part. When you\u2019re done and want to shut down the server, you can run the same command with the --stop option: $ git instaweb --httpd=webrick --stop Example: cd reponame git instaweb --httpd=apache2 git instaweb --httpd=apache2 --stop GitWeb source: https://git-scm.com/book/en/v2/Git-on-the-Server-GitWeb Transferring repositories. I transferred 3 repositories and for some reason, when I got the confirmation link in my email in Chrome, the transfer link didn't work. I had to open my email in Firefox and click on the confirmation link and the transfer worked.","title":"GiT"},{"location":"git/#configuring-git","text":"","title":"Configuring git:"},{"location":"git/#for-all-users-on-the-system","text":"git --config system","title":"For all users on the system:"},{"location":"git/#for-user-level","text":"git --config global","title":"For user level:"},{"location":"git/#set-username-and-email-address","text":"git config --global user.name \"Robert Holland\" git config --global user.email rob@example.com","title":"Set username and email address:"},{"location":"git/#set-the-colors-for-git","text":"git config --global color.ui auto git config --global color.ui true","title":"Set the colors for git:"},{"location":"git/#set-the-pager-for-git-diff","text":"git config --global core.pager 'less -R' The git config --global command is also used to create aliases.","title":"Set the pager for git diff:"},{"location":"git/#reset-author","text":"After updating my username and email address I had to reset the author by typing: git commit --amend --reset-author (can use this to reset the author for the latest commit)","title":"Reset author:"},{"location":"git/#view-git-configuration","text":"If you want to see what is already configured: git config --list","title":"View git configuration:"},{"location":"git/#view-git-username-and-email-address","text":"If you want to see the username or email address: git config user.name git config user.email","title":"View git username and email address:"},{"location":"git/#to-configure-the-preferred-editor","text":"git config --global core.editor \"EditorNameHere\" git config --global core.editor \"mate -wl1\" (wait for textmate to finish and put the cursor on line one). git config --system color.ui true","title":"To configure the preferred editor:"},{"location":"git/#exploring-git-auto-completion","text":"Download git-completion.bash and rename it to .git-completion.bash. Download it from here: curl -OL https://github.com/git/git/raw/master/contrib/completion/git-completion.bash Rename the file to .git-completion.bash (notice the leading dot (.): mv git-completion.bash .git-completion.bash Enter this in the .bash_profile or equivalent: #Git configuration file: if [ -f ~/.git-completion.bash ]; then source ~/.git-completion.bash fi Create a new repository on the command line make a new directory then type: touch README.md git init git add README.md git commit -m \"first commit\" git remote add origin https://github.com/username/reponame.git To add a local repository on Widows: git remote add origin c:/Users/Rob/Documents/Github/php.git git push -u origin master //Only need to do this the first time you push to the server so that the upstream branch gets set.","title":"Exploring Git Auto-completion:"},{"location":"git/#push-an-existing-repository-from-the-command-line","text":"git remote add origin https://github.com/username/reponame.git git push -u origin master //Only need to do this the first time you push to the server so that the upstream branch gets set.","title":"Push an existing repository from the command line:"},{"location":"git/#git-checkout","text":"Undo changes to the git repository: I changed a file and saved it but I have not staged (git add) it yet. Git status shows what was changed and I want to undo my changes. To replace the file in the local directory with a copy of what you have in the working area type: git checkout -- filename This will replace the file that you changed with an original version before the change. If you only use git checkout filename (without the dashes), you may accidentally checkout a branch that has the same name as the file you are trying to restore (unlikely because branches don't have extensions). The double dashes -- tells git to stay in the current branch and look for the file you want to restore.","title":"Git checkout:"},{"location":"git/#branching","text":"If you want to make another version of your files just make a branch. To create a new branch type: git branch newbranchname Git will automatically copy the master repo into your new branch. Change into the new branch by typing: git checkout newbranchname git checkout -b newbranchname : Will create the new branch and change into it. You can make changes without disturbing the master files. If all goes well you can merge your changes into the master branch.","title":"Branching:"},{"location":"git/#track-a-branch","text":"If you have a branch that is not tracking you can add it to be tracked by typing: git config branch.branchname.remote origin or git config branch.branchname.merge refs/heads/master or git branch --set-upstream branchname origin/branchname (This works with version 1.7 and later). or git branch --set-upstream-to=origin/<branch> master","title":"Track a branch"},{"location":"git/#merge-branch","text":"To merge your new branch into master, first go to the master branch by typing: git checkout master then type: git merge branchname The master branch will now have the same changes as branchname","title":"Merge branch:"},{"location":"git/#to-back-out-of-a-merge-conflict-type","text":"git merge --abort This will leave your changes alone and not do the merge.","title":"To back out of a merge conflict type:"},{"location":"git/#to-update-a-branch-with-the-latest-changes-from-master","text":"You have two options: The first is a merge, but this creates an extra commit for the merge. Checkout each branch: git checkout branch1 Then merge: git merge origin/master Then push: git push origin branch1 Alternatively, you can do a rebase (easier): git fetch git rebase origin/master","title":"To update a branch with the latest changes from master:"},{"location":"git/#if-you-want-to-change-or-revert-the-master-branch-to-the-previous-commit","text":"Checkout previous commit on master git checkout abc123... While in the abc123... detached branch, create branch for new master git checkout -b new_master Delete old master git branch -D master Make new_master master git branch -mv new_master master Alternatively you can reset current branch to one commit ago on master (See git reflog for recovery of local branches). git reset --hard abc123... Then you will have to force push to the repository: git push --force origin master Try this if you get an error force pushing \"error: denying non-fast forward refs/heads/master (you should pull first)\" and you have access to the remote git server in ssh, you can go into the git remote directory and set: git config receive.denyNonFastforwards false If all fails or you don't have access to the remote repository, just make an update commit correcting the error. If you want to delete the branch (make sure you are on the master branch) type: git branch -D branchname","title":"If you want to change or revert the master branch to the previous commit:"},{"location":"git/#if-you-want-to-see-all-of-the-branches","text":"git branch -a git branch show-all <-- Doesn't seem to show all branches unless you have checked them out at some point.","title":"If you want to see all of the branches:"},{"location":"git/#if-you-want-to-see-only-the-remote-branches","text":"git branch -r","title":"If you want to see only the remote branches:"},{"location":"git/#if-you-want-to-see-only-local-branches","text":"git branch","title":"If you want to see only local branches:"},{"location":"git/#if-you-want-to-see-the-branches-along-with-the-latest-commit-message","text":"git branch -v","title":"If you want to see the branches along with the latest commit message:"},{"location":"git/#how-to-find-out-if-one-branch-has-all-of-the-commits-of-another-branch","text":"git branch --merged (This will show a list of all of the branches that contain what is in your current branch. This will allow you to delete the other matching branches without causing any harm).","title":"How to find out if one branch has all of the commits of another branch."},{"location":"git/#git-diff","text":"To see all of the changes made to the files type: git diff You can see a line by line difference between what is in the repository or staging area compared to what is in the working area. If you just want to see what is in a single file type: git diff singlefilename If you have already staged a file and want to see the differences between that staged file and what you have in the repository then type: git diff --staged diff between two different commits in the same branch, you can put the SHA of the oldest commit first then the SHA of the latest commit last to see what is not in (or missing) from the first file. git diff d861a745:/path/to/filename.txt 118192cf:/path/to/filename.txt diff between two different commits in the same branch, you can put the SHA of the latest commit first then the SHA of the older commit last to see what was added to the file. git diff 118192cf:/path/to/filename.txt d861a745:/path/to/filename.txt diff but don't show file mode changes. git diff -G\".\"","title":"Git diff"},{"location":"git/#word-wrap","text":"When you are in the diff view you can use the (minus sign + shift + S) to word wrap the long lines. Repeat the same key combination to undo the word wrap. Also you can see the changes side by side by typing: git diff --color-words filename","title":"Word Wrap"},{"location":"git/#git-blame","text":"To see all the changes line by line in a file and who made the change over time type: git blame -w filename The -w does not show differences in whitespace.","title":"Git blame:"},{"location":"git/#commits","text":"If you want to commit a file and add a message: commit --message=\"This is my message.\" \"filename.txt\" If you want to see a particular commit type: git show [SHA Key]","title":"Commits"},{"location":"git/#to-see-the-commits-for-only-one-file","text":"git log --follow filename","title":"To see the commits for only one file:"},{"location":"git/#to-see-the-sha-for-files-for-a-specific-commit-r-will-recurse-directories","text":"git ls-tree -r HEAD #This will show the current head. or git ls-tree -r HEAD ab12cd34ef56 #This will show a specific commit. or git ls-tree -r HEAD^^ #This will show two commits ago. or git ls-tree -r HEAD~2 #This will show two commits ago.","title":"To see the SHA for files for a specific commit (-r will recurse directories):"},{"location":"git/#undo-changes-in-the-staging-area","text":"I have made a change to a file and it shows up as changed in the working area. I used git add filename to add the file to the staging area. Now I want to take the file out of the staging area and put it back in the working area. git reset HEAD filename You will see an \"M\" next to the file that indicates that the staging area was modified. The -a option sends the commit directly to the repository skipping the staging area: git commit -am \"Message\" You cannot use the \"-am\" option when committing modified files individually. This is used in situations where you have multiple files that have been modified but you only want to commit some of them. The \"-a\" will have to be left out, only use \"-m\". Example: git commit -m \"Commit message\" \"File1.txt\" \"File2.txt\"","title":"Undo changes in the staging area:"},{"location":"git/#amending-commits","text":"You can only amend the last commit because it doesn't have any more commits after it. Once you have added another commit you can't amend a previous commit. If you need to change previous commit just make a new commit with the changes that you need. I have already committed a file and then I make another change to the file and add it to the staging area. I want to commit the additional change into the previous commit: git commit --amend -m \"Same message or different one.\"","title":"Amending Commits:"},{"location":"git/#add-a-sign-off-to-the-commit-type","text":"git commit -s -am \"Message\"","title":"Add a \"Sign-off\" to the commit type:"},{"location":"git/#to-use-gpgpgp-to-sign-a-commit-you-must-first-configure-git-with-your-gpgpgp-key-so-that-it-can-be-used","text":"git config user.signingkey <HEX KEY ID> or for global setting using the same key for every repository. git config --global user.signingkey <HEX KEY ID>","title":"To use GPG/PGP to sign a commit you must first configure Git with your GPG/PGP key so that it can be used."},{"location":"git/#to-gpgpgp-sign-a-commit-type","text":"git commit -S -am \"Message\" <--(Uppercase S for GPG signed commits). Can use the same command to change the commit message. You can amend a commit that is previous to the most recent commit. You will have to use git to checkout the commit using the SHA hash and then re-commit it with the new changes. git checkout 2d2323d23423d -- filename This will put the file in the staging area and not the working area. When you checkout a file from the staging area it will go to the working area. (git diff --staged)","title":"To GPG/PGP sign a commit type:"},{"location":"git/#git-revert","text":"Undo the changes made by a commit. It will take all of the changes and add everything that was deleted and delete everything that was added. git revert SHA Git reset: Moves the HEAD pointer. Similar to making a recording on a tape then rewinding 10 seconds and recording again. Has 3 options. git reset --soft sha Does not change the staging index or working directory. Only the repository is set back to an earlier version. git reset --mixed sha (default) Changes the staging index to match the repository. Does not change the working directory. --mixed is almost as safe as --soft. git reset --hard sha changes staging index and working directory to match the repository. (Rewinding 10 seconds and pressing record.) It removes every change that was made before the commit that you select. How to undo almost anything: git reflog","title":"Git Revert:"},{"location":"git/#git-clean","text":"Remove unwanted files from your git directory. git clean -n (does a dry run) git clean -f (permanently deletes the untracked files from your directory) (see cached option under git ignore below for how to remove files that have been previously tracked but you don't want to track them anymore.","title":"Git clean:"},{"location":"git/#git-ignore","text":"Create a file in the root directory called .gitignore and place files and extensions in .gitignore that you want git to ignore. Can use regular expressions: * ? [aeiou] [0-9] Negate expressions with ! Example: !index.php tells git to not ignore index.php. Ignore all files in a directory with a trailing slash. DirectoryName/DirectoryName/ Comment with #","title":"Git Ignore"},{"location":"git/#global-ignore","text":"Put all of your git ignore commands in one file and point git to it using: git config --global The file can be named anything you want. You just have to tell git where it is. git config --global core.excludesfile path/to/filename (Ex: .ignore_global) Ignore files that have been previously tracked but you don't want to track them anymore. You can use the git rm command to delete the file from your directory and git will automatically remove it from being tracked by the repository. If you want to keep the file but remove it from being tracked you can use: git rm --cached filename This removes the file from being tracked by git. If you do a git status it will show as \"deleted\" but it really isn't. It is just no longer being tracked. Git does not track empty directories. If you want to track a directory you will have to put a file in it. Most commonly people put a file named .gitkeep or placeholder.txt inside the directory so that git will watch the directory.","title":"Global Ignore"},{"location":"git/#comparing-branches","text":"git diff master..newbranch The branch listed second in your command is the \"b\" branch in the diff output. A different view for diff: git diff --color-words newbranch..master If you want to compare two branches but not the latest commit of one branch (the previous commit): git --color-words master..newbranch^ If you want to compare a file from the most recent commit on the master branch to the most recent commit on the 32a79a7 branch (the number 0 is the most recent commit of that branch, 1 would be the second most commit): git diff master~0 32a79a7~0 php/update_cal.php If you wanted to compare the same file between two different branches. *The branch listed second is the \"b\" branch in the diff output: git diff master newtest -- testing.txt","title":"Comparing Branches:"},{"location":"git/#rename-branches","text":"Switch to the branch that you want to rename. git branch -m oldbranchname newbranchname git branch --move oldbranchname newbranchname","title":"Rename branches:"},{"location":"git/#using-fast-forward-vs-true-merge","text":"Example: If you make a new branch from master and make changes to the new branch without making any changes to master, then merge the new changes into master, you are doing a fast forward merge. No new commit will need to be made because you are just adding more or to \"updating\" master. If you make a new branch and make changes to the new branch and also make changes to master and do a merge then you are doing a true merge and you will have a merge conflict and will need to specify the differences that you want to keep or discard. If you want to specify a merge tool to use when merging files you can do so by typing: git mergetool --tool=NameOfMergeTool","title":"Using fast-forward vs true merge:"},{"location":"git/#rebase","text":"Process Tracking (rebase) Process tracking is when you merge the master branch into your working branch to update your working branch with new stuff from the master branch. This helps you reduce the number of merge conflicts that occur when you finally have to merge your changes back into master.","title":"Rebase:"},{"location":"git/#stashstashing","text":"A stash is not a commit and they do not have a SHA associated with them. You use \"stash\" when you are in one branch then try to checkout another branch without first saving the changes for the branch you are in. You will get a message telling you that you will lose the changes that you have already made. You can save them by stashing them and then continue to checkout the other branch. To stash type: git stash save \"Message for stash.\" If you want to see a list of items in the stash type: git stash list You will see stash{0}, stash{1}, etc. It doesn't matter which branch you are on, you will still be able to see the stash and pull it out of the stash. This is helpful if you realize you are making changes to the wrong branch. Just stash the changes and checkout the branch you need to apply the changes to and apply the stash. If you want to see a particular stash, you will have to reference it by its number. For example: If I wanted to see what was in stash{0} I would type: git stash show stash@{0} To see the stash in a more detailed way (diff), you will have to use the \"Patch\" option. Type: git stash show -p stash@{0} To take the stash out of the stash repository you can use two commands: git stash pop git stash apply The difference is that git stash pop will remove the stash from the stash repository and git stash apply will leave a copy in the stash repository. Delete single items that are in the stash type: git stash drop 0 Delete all items in the stash by typing: git stash clear","title":"Stash/Stashing"},{"location":"git/#remote-branches","text":"If you want to see all of the branches on the remote type: git remote git remote -v (more verbose information) If you want to add a remote repository type: git remote add <alias> <url> Example: git remote add origin https://github.com/rlholland/reponame.git You don't have to use the name \"origin\" you can change it to anything you want. You can clone a repository that you don't own and make changes to it then push your changes to your own repository. Just use git remote add and create another path to your repository. Example: git remote add new-origin path-to-new-repository Now you can push-pull to the new-origin and also pull updates from the old origin that you don't own.","title":"Remote Branches:"},{"location":"git/#changeupdate-url","text":"If you want to change/update the URL in .git/config to point to a different repository: git remote set-url <alias> <url> Example: git remote set-url origin B:/Millennium/mPage/gitrepositories/azb_custom_components.git This method defaults to SSH. git remote set-url origin git@github.com:rlholland/remoterepositoryname.git This method specifically uses SSH. git remote add origin ssh://username@servername/path/to/repository.git If you want to remove a remote repository type: git remote rm remoterepositoryname Example: git remote rm origin If you want to look at the remote SHA you can type: cat .git/refs/remotes/origin/master This will show you the latest SHA on the remote","title":"Change/Update URL:"},{"location":"git/#clone","text":"If you want to clone a remote repository into a folder that you name type: git clone https://github.com/rlholland/reponame.git newlocalfoldername You can also clone a specific branch by using the -b option. Example: git clone -b <branch> <remote_repo> git clone -b thebranchname git@github.com:user/myproject.git If you want to clone using SSH: git clone ssh://username@servername/absolute/path/to/git/repo.git","title":"Clone:"},{"location":"git/#push","text":"If you want to push all changes: git push --all \"https://github.com/rlholland/reponame.git\"","title":"Push:"},{"location":"git/#log","text":"If you want to see the commits that were made to the git repo, type: git log This will show you all of the commits and the messages that were entered when the commit was made. If you want to limit the display of message to a certain number then type: git log -n 10 This will limit the number of messages displayed on the screen to 10. If you want to see all of the commits from the beginning up to a certain date type: git log --until=2014-05-25 If you want to see all of the commits since a certain date to the present type: git log --since=2014-05-25 You can use both commands together to see commits between two dates. git log --since=\"two weeks ago\" --until=\"3 days ago\" git log --since=\"two.weeks\" --until=\"3.days\" You can see commits made by a specific person (author) by typing: git log --author=\"Robert\" (can use quotes if search term has a space). You can search the commit messages for an expression by using grep (Global Regular Expression). Type: git log --grep=\"Text you are looking for\" (this is case sensitive). You can ignore case with: git log --grep=\"Text you are looking for\" -i (the dash \"i\" will ignore case). You can show the log file by SHA: git log SHA1..SHA2 Example: git log 23fadf323..938533arad --oneline The --oneline shows part of the SHA and the commit on one line. git log --format=oneline shows the complete SHA and message on one line. You can show the log on just one file from a certain point and view the changes. git log -p SHA.. index.html git log -p --since=\"2014-04-01\" index.html (The -p shows the differences) To see the status or summary of the commits you can use: git log --stat git log --summary git log --stat --summary Git can search diffs with the -S option (it's called pickaxe in the docs) http://stackoverflow.com/questions/4468361/search-all-of-git-history-for-a-string","title":"Log:"},{"location":"git/#search","text":"It's also possible to search for commits that introduce or remove a particular line of source code. This is called a pickaxe, and it takes the form of -S\" \". For example, if you want to know when the string Hello, World! was added to any file in the project, you would use the following command: git log -S\"Hello, World!\" Find any commit that added or removed the string password. git log -Spassword","title":"Search:"},{"location":"git/#patch","text":"git log -p will show the diffs. If you provide a file (-p file), it will generate a patch for you. git log -G looks for differences whose added or removed line matches the given regexp, as opposed to -S, which \"looks for differences that introduce or remove an instance of string\". git log --all searches over all branches and tags; alternatively, use --branches[=<pattern>] or --tags[=<pattern>] If you want to search using a regular expression instead of a string, you can use the -G\" \" flag instead. This is a very powerful debugging tool, as it lets you locate all of the commits that affect a particular line of code. It can even show you when a line was copied or moved to another file. To see a GPG signature: git log --show-signature A good Git log command to show a lot of detail is: git log --graph --oneline --decorate --all If you want to see the log for a specific branch type: git log specificbranch --oneline -3 (the -3 shows the latest 3 logs) If you want to see the log differences in patch mode type: git log -p branchname..origin/branchname If you only want to see the log entries for particurlar files type: git log -- foo.txt bar.txt","title":"Patch:"},{"location":"git/#git-fetch","text":"This synchronizes any remote branches we don't have locally so when you type git branch it will show you all of the branches. If you want to fetch type: git fetch origin If you are tracking you don't need to type the \"origin\" just type: git fetch Three basic guidelines: Always fetch before you work. Fetch before you push Fetch often You can also use \"git pull\" Git Pull git pull does the same thing as git fetch except it automatically does the merge. git pull = git fetch + git merge Checkout Remote Branches These commands will checkout the branch and track them: git branch newbranchname HEAD git branch newbranchname anycommitSHA git branch newbranchname origin/branchname To delete a remote branch use a colon: git push origin :branchname A little information history on the git push command. It used to be done like this: git push origin branchname:branchname. The colon between them means that you are telling git to push to origin the local branchname to the remote branchname. If you don't specify the colon and you only have one branchname, git assumes they are the same. So the git push origin :branchname means to push to origin nothing locally to the remote branchname. The remote branchname is now getting nothing pushed to it and is deleted. The new way to delete a branch is: git push origin --delete branchname If you want to modify someones elses code that you find on GitHub, you will have to \"Fork\" it then make your changes. Once you are done with your changes, you can create a \"Pull Request\" so that the original owner can look at your code and decide to incorporate it into theirs. Configure the prompt to show the git branch when in a git repo: Edit the .bashrc file and enter below BEGIN: # Git specific environment and startup programs if [ -f ~/.git-prompt.sh ]; then source ~/.git-prompt.sh fi #Git Prompt PS1=\"[\\u:\\w]\\$(__git_ps1)$ \" #<-- On Fedora Linux export PS1='\\W$(__git_ps1 \"(%s)\") > ' #<-- On Mac OSX setopt PROMPT_SUBST ; PS1='[%n@%m %c$(__git_ps1 \" (%s)\")]\\$ ' #<-- On Mac OSX ZSH END: Source: https://stackoverflow.com/questions/15883416/adding-git-branch-on-the-bash-command-prompt If the shell does not load the .git_prompt.sh file you may see the following error on the command line. __git_ps1: command not found If you want to see the current prompt string \"PS1\" settings type \"echo $PS1\"","title":"Git Fetch"},{"location":"git/#configuring-git-aliases","text":"You can create aliases for Git in the .gitconfig file two ways. You can edit the file directly or you can use the git config --global command. For example: I didn't want to type the entire log line below so I created a shortcut for it in the .gitconfig file by using the git config --global command. git log --graph --oneline --decorate --all I created an alias for it named \"logg\" by typing: git config --global alias.logg \"log --graph --oneline --decorate --all\" Now I only have to enter \"git logg\" to get the same output. Re-install Git icons on Windows github --reinstall-shortcuts Here are some more common Git aliases: git config --global alias.co checkout git config --global alias.cm commit git config --global alias.br branch git config --global alias.dfs \"diff --staged\" git config --global alias.logg \"log --graph --oneline --decorate --all\"","title":"Configuring Git Aliases"},{"location":"git/#setup-two-factor-authentication","text":"Git credentials: Immediately stop the credential manager on a Mac if you have your password stored/cached for a specific amount of time. git credential-cache exit","title":"Setup Two-Factor Authentication:"},{"location":"git/#on-a-mac","text":"To remove your credentials from the OSX Keychain and configure for two-factor authentication, type the following at the command prompt: git credential-osxkeychain erase protocol=https host=github.com (press enter twice to finish) You now need to get a personal access token from Github. Log into Github and select \"Security\" and enable two-factor authentication. Click on \"Developer settings\" then \"Personal Access Token\" and click the \"Generate New Token\" button. If you use more than one computer, it is a good idea to include the name of your computer in the name of the token so that you can revoke it if necessary. Copy the token and paste it in when you are prompted for your password during a commit.","title":"On a MAC:"},{"location":"git/#on-windows","text":"You have to install Github Desktop which has the two-factor authentication built in (just sign in with your Github.com account and that should get two-factor setup for the GUI part. If you want to use the same two-factor from the command line, you will have to install \"Git for Windows (https://git-scm.com/download/win)\". Once that is installed, go to Github desktop and click the \"Repository\" dropdown and depending on which shell you have configured under \"Options\" --> \"Advanced\", either select \"Open Git Command Prompt\", \"Open Git Powershell\", or \"Open Git in Bash\". (If you try to push without the correct configuration in the .gitconfig file, you may see a message similar to the one below: fatal: unable to access 'https://github.com/rlholland/gitnotes.git/': SSL certificate problem: unable to get local issuer certificate) Once you have your favorite command prompt open, edit the .gitconfig file (located in the root of your profile directory and/or in your home folder if you are on a network with an automatically mapped home directory) and enter the following so that you can push from the command line using two-factor authentication. [http] sslcainfo=C:/Program Files/Git/mingw64/ssl/certs/ca-bundle.crt sslbackend=schannel (Check for the correct path to ca-bundle.crt if you are using 32bit Windows). After the .gitconfig file has been modified and saved, do a push from your repository and you should not get prompted for a password. Your two-factor authentication is setup for your computer. If you lose your computer or misplace it, you can always log into Github and revoke your Personal Access Token for that computer.","title":"On Windows:"},{"location":"git/#merging-git-repositories","text":"http://blog.caplin.com/2013/09/18/merging-two-git-repositories/","title":"Merging Git Repositories:"},{"location":"git/#list-of-gui-interfaces-for-git-can-be-found-on-the-git-wiki","text":"https://git.wiki.kernel.org/index.php/InterfacesFrontendsAndTools","title":"List of Gui Interfaces for Git can be found on the Git Wiki:"},{"location":"git/#git-hosting","text":"There are two ways to host, Use a hosting company or host yourself.","title":"Git Hosting"},{"location":"git/#popular-git-hosting-companies-are","text":"http://github.com http://bitbucket.org http://gitorious.org","title":"Popular Git hosting companies are:"},{"location":"git/#self-hosting","text":"Gitosis - http://github.com/tv42/gitosis (development for this stopped a few years ago) Gitolite - http://github.com/sitaramc/gitolite","title":"Self-Hosting:"},{"location":"git/#git-tutorials","text":"Michael's Git Tutorial - Setting Up a Git Server https://www.youtube.com/watch?v=SyMkLQLC3Kg How to Setup a Git SSH Server and Client on Ubuntu https://www.youtube.com/watch?v=lXSZUuDW4nY Creating a Git Server on a Windows OS https://www.youtube.com/watch?v=w3eRlEhzAZk&ebc=ANyPxKpNRpbhQZ_nlL7IxaYeM_5rOLOI2RPJi2kv1jJuw6DUEEe14nsBvDRHvBjQKmO7DIvaOUzprWUCtFUXdcO9X-cLOpYrHg Pushing to GitHub with HTTPS and 2-Factor authentication https://www.youtube.com/watch?v=hJLaXNMz8zw http://www.linux-magazine.com/Online/Features/Install-Your-Own-Git-Server http://studyhat.blogspot.com/2010/10/install-your-own-git-server-on-cent-os.html http://fedoracoreproject.blogspot.com/2010/02/how-to-install-vnc-server-on-fedora.html GitHub Instructions - http://git-scm.com/book/en/v2/Git-on-the-Server-The-Protocols GitHub Instructions - http://git-scm.com/book/ch4-7.html Installing on AIX, HP-UX, Solaris - http://blog.boreas.ro/2008/03/porting-git-to-hp-ux-pa-risc-and-aix.html","title":"Git Tutorials"},{"location":"git/#ubuntu-server-configuration","text":"To find the Gateway: route -n On the server: sudo vi /etc/network/interfaces (Set the eth0 interface to a static IP address) auto lo iface lo inet loopback auto eth0 iface eth0 inet static address 192.168.1.2 netmask 255.255.255.0 gateway 192.168.1.1 From the client: sudo vi /etc/hosts (enter the Git Server's information) sudo vi /etc/ssh/sshd_config (Configure SSH to accept access by SHA key instead of tunnelled clear text passwords) #Find the line that says: PasswordAuthentication yes #and change it to read: PasswordAuthentication no #uncomment the line. sudo restart ssh If you want to use the Git user: sudo adduser git su - git mkdir .ssh chmod 700 .ssh touch .ssh/authorized_keys chmod 600 .ssh/authorized_keys (Make sure only the owner has access rights) Create an RSA key on the client and copy it to the server. ssh-keygen -t rsa ssh-keygen -t rsa -b 4096 (See below to copy the public key to the git user authorized_keys file on the server.) This method will allow ssh://git@servername/path/to/repo.git to be used for push pull operations. Another method using openssl: openssl genrsa -out id_rsa 4096 openssl rsa -in id_rsa -pubout > id_rsa.pub Send your \"public\" key to the server: cat ~/.ssh/id_rsa.pub | ssh user@remote-server \"mkdir -p ~/.ssh && cat >> ~/.ssh/authorized_keys\" Install Git on the server (if it isn't installed already): sudo apt-get -y install git Find out what shells are currently in use: cat /etc/shells Find out which shell git is using: From the git user login type: which git-shell Add the information from 'which git-shell' command to the list of valid shells in the /etc/shells file. Example /etc/shells file content: /bin/sh /bin/bash /bin/rbash /bin/dash /usr/bin/git-shell On Fedora 24 and 25, the chsh command is used to change the shell. It may not exist by default. Install the package that contains chsh: dnf install util-linux-user Change the git user login shell to git-shell: sudo chsh git Enter: /usr/bin/git-shell If you try to log into the git user from the command line after the git shell is enabled, you will see a message similar to this: fatal: Interactive git shell is not enabled. hint: ~/git-shell-commands should exist and have read and execute access.","title":"Ubuntu Server Configuration:"},{"location":"git/#on-the-server-create-a-git-repository","text":"mkdir -p /opt/git Give the git user access to the git folder where the repositories will live. Use with caution! This will overwrite group shared repositories if they already exist within the git repository. sudo chown -R git:git /opt/git Create a git repository and a project: mkdir -p /opt/git/project-name.git cd /opt/git/project-name.git git init --bare git init --bare --shared (if the repository will be shared by a group) If your repository is only going to be used by one user then you can just use the git user for simplicity. Change the owner of theprojectname.git to the git user and group. sudo chown -R git:git /opt/git/theprojectname.git sudo chmod o-rwx /opt/git/theprojectname.git (remove access to anyone else). If your repository will be used by multiple people, create a group for the Git repository. To create a group: sudo groupadd thegroupname or sudo addgroup thegroupname To add a user to the group: sudo usermod -a -G thegroupname theusername or sudo useradd -G thegroupname theusername To remove a user from a group (Remove the user billybob from the group hillbilly): gpasswd -d billybob hillbilly Make sure the group has access to the repository: sudo chgrp -R thegroupname thereponame.git (-R set the group ownership recursively). sudo chmod g+rws thereponame.git (set the sticky bit so changes are owned by the group). sudo chmod o-rwx thereponame.git (remove access for \"other\" so only group members can clone).","title":"On the Server, create a git repository:"},{"location":"git/#on-the-client-create-a-repository","text":"Configure the git username and email from the instructions above. Create a local git repo called project-name mkdir -p project-name Initialize the git repo git init Add some files and commit them: git add . git commit -m \"initial commit\" Link your local repository to the server. If you are using the git user (before pushing commits see generating SSH keys below): git remote add origin git@gitserver/opt/git/project-name.git If you are using your own username that is a member of the group that has access to theprojectname.git: git remote add origin ssh://username@servername/opt/git/theprojectname.git","title":"On the client, create a repository:"},{"location":"git/#push-your-files","text":"git push origin master After the initial push you only need to type: git push","title":"Push your files:"},{"location":"git/#methods-to-push-all-branches","text":"git push origin '*:*' git push origin --all git push REMOTE '*:*' git push REMOTE --all","title":"Methods to push all branches:"},{"location":"git/#to-automatically-push-all-branches-to-their-matching-branch","text":"git config --global push.default matching","title":"To automatically push all branches to their matching branch:"},{"location":"git/#to-only-push-the-current-branch-to-its-matching-branch","text":"git config --global push.default simple If you are using the git user you will need to generate a public and private SSH key for authentication (unless you know the password for the git user).","title":"To only push the current branch to its matching branch:"},{"location":"git/#to-generate-the-ssh-keys","text":"If there is no .ssh directory in your home directory you will have to create one. mkdir .ssh","title":"To generate the SSH keys:"},{"location":"git/#change-the-permissions-to-700","text":"chmod -R 700 .ssh cd ~/.ssh ssh-keygen -t rsa -Accept the default name. -You can enter a password if you like. If you do not, you can take advantage of automatic authentication using your public SSH key (id_rsa.pub) amd private SSH key (id_rsa) pair. Add the contents of your public key to the git users authorized_keys file. Do not overwrite the git users authorized_keys file because anyone else using it will not be able to log in.","title":"Change the permissions to 700."},{"location":"git/#ssh-to-github-with-multiple-usernames-from-the-same-computer","text":"https://gist.github.com/jexchan/2351996 My steps based on above URL that I took to get this working for github.com/rlholland. I created a separate SSH key using: ssh-keygen -t rsa -b 4096 -C \"rob@robholland.info\" Then I added the SSH key to Github rlholland profile. I was able to clone my rlholland/b repository. git clone git@github.com:rlholland/b.git I was not able to push to the repository until I edited .git/config url = rlholland_github:rlholland/b.git The pattern is: rlholland_github:github_username/github_repository.git My .ssh/config file looks like this for the rlholland repository: Host rlholland_github HostName github.com User git IdentityFile ~/.ssh/rh_info","title":"SSH to GitHub with multiple usernames from the same computer."},{"location":"git/#point-repository-to-a-different-server-and-keep-the-history","text":"If you want to change your repository to point to a different server and still keep the history. Pull everything from your soon-to-be-old-server into your local repository. Create the new repository on the new server. In your local repository update the URL path to the new server (git remote set-url origin ...). See above for example. \"git push origin master\" to the new location. The Git log should still show the history and all of your data will be on the new server. I installed GitExtensions on my Windows laptop and it would not push to a UNC path until I pointed it to GitHub Desktop.","title":"Point repository to a different server and keep the history:"},{"location":"git/#github-desktop-git-shell","text":"C:\\Users\\rlholland\\AppData\\Local\\GitHub\\PortableGit_d7effa1a4a322478cd29c826b52a0c118ad3db11\\usr\\bin C:\\Users\\rlholland\\AppData\\Local\\GitHub\\GitHub.appref-ms --open-shell","title":"GitHub Desktop (Git Shell):"},{"location":"git/#mingw32-git-bash","text":"C:\\Program Files\\Git\\usr\\bin \"C:\\Program Files\\Git\\git-bash.exe\" --cd-to-home","title":"MINGW32 (Git Bash):"},{"location":"git/#making-git-auto-commit","text":"I'd like to use git to record all the changes to a file. Is there a way I can turn git 'commit' on to automatically happen every time a file is updated - so there is a new commit for every change to a file? Ideally I'd like my users to not even know that git is running behind the scenes. A user could then potentially \"undo\" changes to a file - and this could be achieved by pulling a previous version out of git. On Linux you could use inotifywait to automatically execute a command every time a file's content is changed. Edit: the following command commits file.txt as soon as it is saved: inotifywait -q -m -e CLOSE_WRITE --format=\"git commit -m 'autocommit on change' %w\" file.txt | sh The earlier inotifywait answer is great, but it isn't quite a complete solution. As written, it is a one shot commit for a one time change in a file. It does not work for the common case where editing a file creates a new inode with the original name. inotifywait -m apparently follows files by inode, not by name. Also, after the file has changed, it is not staged for git commit without git add or git commit -a. Making some adjustments, here is what I am using on Debian to track all changes to my calendar file: /etc/rc.local: su -c /home/<username>/bin/gitwait -l <username> /home/<username>/bin/gitwait: #!/bin/bash # # gitwait - watch file and git commit all changes as they happen # while true; do inotifywait -qq -e CLOSE_WRITE ~/.calendar/calendar cd ~/.calendar; git commit -a -m 'autocommit on change' done This could be generalized to wait on a list of files and/or directories, and the corresponding inotifywait processes, and restart each inotifywait as a file is changed. Use the -r flag to inotifywait, but note that the kernel has a limit on the number of inotifywait watches it can set up. man inotifywait will tell you more. This Github repository was recommended: https://github.com/nevik/gitwatch.git. I have cloned it in my personal repository. Source: http://stackoverflow.com/questions/420143/making-git-auto-commit.","title":"Making Git auto-commit:"},{"location":"git/#the-indexlock-issue","text":"I was getting an error when I made a commit. I can't remember what the error was but I had a choice to answer \"Y\" or \"N\" to retry. I selected \"N\" and then was taken back to the command prompt. I looked on StackOverflow.com and saw a post that someone had submitted about creating the .git/index.lock file and trying the commit again and if it didn't work. Delete the index.lock file which seemed to work for the person that made the post. I tried it and it worked for me. Index.lock issue cannot write to index: While the prompt is still showing \"Do you want to retry Y/N\", open another command prompt and go into the .git directory and copy the index.lock file to index.lock.bak. On Windows: type index.lock > index.lock.bak On Linux: cat index.lock > index.lock.bak Go back to the original command prompt and type \"N\" to not retry. Go back to the other command prompt and copy index.lock.bak into index. type index.lock.bak > index cat index.lock.bak > index del index.lock rm index.lock Type: git status log to see the changes. Websites: https://gist.github.com/hofmannsven/6814451 --> Someones Git notes I found on Github.","title":"The index.lock issue:"},{"location":"git/#instaweb","text":"Git local repository web server (GitWeb): If you want to check out what GitWeb would look like for your project, Git comes with a command to fire up a temporary instance if you have a lightweight web server on your system like lighttpd or webrick. On Linux machines, lighttpd is often installed, so you may be able to get it to run by typing git instaweb in your project directory. If you\u2019re running a Mac, Leopard comes preinstalled with Ruby, so webrick may be your best bet. To start instaweb with a non-lighttpd handler, you can run it with the --httpd option. $ git instaweb --httpd=webrick [2009-02-21 10:02:21] INFO WEBrick 1.3.1 [2009-02-21 10:02:21] INFO ruby 1.8.6 (2008-03-03) [universal-darwin9.0] That starts up an HTTPD server on port 1234 and then automatically starts a web browser that opens on that page. It\u2019s pretty easy on your part. When you\u2019re done and want to shut down the server, you can run the same command with the --stop option: $ git instaweb --httpd=webrick --stop Example: cd reponame git instaweb --httpd=apache2 git instaweb --httpd=apache2 --stop GitWeb source: https://git-scm.com/book/en/v2/Git-on-the-Server-GitWeb Transferring repositories. I transferred 3 repositories and for some reason, when I got the confirmation link in my email in Chrome, the transfer link didn't work. I had to open my email in Firefox and click on the confirmation link and the transfer worked.","title":"Instaweb:"},{"location":"google/","text":"Google Drive Notes Google Docs To create superscript: Ctrl + . To create subscript: Ctrl + ,","title":"Google"},{"location":"google/#google-drive-notes","text":"","title":"Google Drive Notes"},{"location":"google/#google-docs","text":"","title":"Google Docs"},{"location":"google/#to-create-superscript","text":"Ctrl + .","title":"To create superscript:"},{"location":"google/#to-create-subscript","text":"Ctrl + ,","title":"To create subscript:"},{"location":"grep_sed_awk_find/","text":"Linux Utilities: AWK: Remove duplicate lines using awk. - awk '!($0 in array) { array[$0]; print }' somefile.txt Print all lines from /etc/passwd that have the same uid and gid (if column 3 = column 4). - awk -F ':' '$3==$4' /etc/passwd GREP: Print the matched line, along with the 3 lines after it. - grep -A 3 -i \"example\" somefile.txt FIND: Search all .sql files in the system and archive them. - find / -name *.sql -type f -print | xargs tar -cvzf sqlfiles.tar.gz SED: Remove carriage return from the end of a filename. - sed 's/.$//' somefile.txt Add line number for all non-empty-lines in a file. - sed -n '1!G;h;$p' somefile.txt Search and replace all the strings/patterns without opening a file. - sed 's/Old/New/' somefile.txt Replace only the second occurrence on each line. - sed 's/Old/New/2' somefile.txt Replace the second occurance of a string in a particular line. - sed '2 s/Old/New/' somefile.txt Replace all occurrences of a string/pattern in a file. - sed 's/Old/New/g' somefile.txt Exclude lines 2-4 of a file and print the rest. - sed -n '2,4p' somefile.txt Print/display multiple consecutive lines (print lines 2 and 3, and 5 and 6). - sed -n -e '2,3p' -e '5,6p' somefile.txt Print/display lines which contain a specific word. - sed -n /operating/p somefile.txt Add a line in between each line in a file. - sed G somefile.txt Eliminate blank lines or ignore them. - sed '/^$/d' somefile.txt Remove any blank lines and any commented \"#\" lines from a file. - sed '/^#\\|^$\\| *#/d' somefile.conf Delete all lines except the range specified? - sed '3,5!d' somefile.txt Ignore the case-sensitivity when replacing a word replace all (Old or old). - sed 's/old/new/i' somefile.txt Top To display only the processes that belong to a particular user use -u option. The following will show only the top processes that belongs to oracle user. - top -u oracle XARGS: Copy all .jpg images to another directory: - ls *.jpg | xargs -n1 -i cp {} /another/directory Download all the URLs listed in filename.txt file: - cat filename.txt | xargs wget -c","title":"Grep_sed_awk_find"},{"location":"grep_sed_awk_find/#linux-utilities","text":"","title":"Linux Utilities:"},{"location":"grep_sed_awk_find/#awk","text":"","title":"AWK:"},{"location":"grep_sed_awk_find/#remove-duplicate-lines-using-awk","text":"- awk '!($0 in array) { array[$0]; print }' somefile.txt","title":"Remove duplicate lines using awk."},{"location":"grep_sed_awk_find/#print-all-lines-from-etcpasswd-that-have-the-same-uid-and-gid-if-column-3-column-4","text":"- awk -F ':' '$3==$4' /etc/passwd","title":"Print all lines from /etc/passwd that have the same uid and gid (if column 3 = column 4)."},{"location":"grep_sed_awk_find/#grep","text":"","title":"GREP:"},{"location":"grep_sed_awk_find/#print-the-matched-line-along-with-the-3-lines-after-it","text":"- grep -A 3 -i \"example\" somefile.txt","title":"Print the matched line, along with the 3 lines after it."},{"location":"grep_sed_awk_find/#find","text":"","title":"FIND:"},{"location":"grep_sed_awk_find/#search-all-sql-files-in-the-system-and-archive-them","text":"- find / -name *.sql -type f -print | xargs tar -cvzf sqlfiles.tar.gz","title":"Search all .sql files in the system and archive them."},{"location":"grep_sed_awk_find/#sed","text":"","title":"SED:"},{"location":"grep_sed_awk_find/#remove-carriage-return-from-the-end-of-a-filename","text":"- sed 's/.$//' somefile.txt","title":"Remove carriage return from the end of a filename."},{"location":"grep_sed_awk_find/#add-line-number-for-all-non-empty-lines-in-a-file","text":"- sed -n '1!G;h;$p' somefile.txt","title":"Add line number for all non-empty-lines in a file."},{"location":"grep_sed_awk_find/#search-and-replace-all-the-stringspatterns-without-opening-a-file","text":"- sed 's/Old/New/' somefile.txt","title":"Search and replace all the strings/patterns without opening a file."},{"location":"grep_sed_awk_find/#replace-only-the-second-occurrence-on-each-line","text":"- sed 's/Old/New/2' somefile.txt","title":"Replace only the second occurrence on each line."},{"location":"grep_sed_awk_find/#replace-the-second-occurance-of-a-string-in-a-particular-line","text":"- sed '2 s/Old/New/' somefile.txt","title":"Replace the second occurance of a string in a particular line."},{"location":"grep_sed_awk_find/#replace-all-occurrences-of-a-stringpattern-in-a-file","text":"- sed 's/Old/New/g' somefile.txt","title":"Replace all occurrences of a string/pattern in a file."},{"location":"grep_sed_awk_find/#exclude-lines-2-4-of-a-file-and-print-the-rest","text":"- sed -n '2,4p' somefile.txt","title":"Exclude lines 2-4 of a file and print the rest."},{"location":"grep_sed_awk_find/#printdisplay-multiple-consecutive-lines-print-lines-2-and-3-and-5-and-6","text":"- sed -n -e '2,3p' -e '5,6p' somefile.txt","title":"Print/display multiple consecutive lines (print lines 2 and 3, and 5 and 6)."},{"location":"grep_sed_awk_find/#printdisplay-lines-which-contain-a-specific-word","text":"- sed -n /operating/p somefile.txt","title":"Print/display lines which contain a specific word."},{"location":"grep_sed_awk_find/#add-a-line-in-between-each-line-in-a-file","text":"- sed G somefile.txt","title":"Add a line in between each line in a file."},{"location":"grep_sed_awk_find/#eliminate-blank-lines-or-ignore-them","text":"- sed '/^$/d' somefile.txt","title":"Eliminate blank lines or ignore them."},{"location":"grep_sed_awk_find/#remove-any-blank-lines-and-any-commented-lines-from-a-file","text":"- sed '/^#\\|^$\\| *#/d' somefile.conf","title":"Remove any blank lines and any commented \"#\" lines from a file."},{"location":"grep_sed_awk_find/#delete-all-lines-except-the-range-specified","text":"- sed '3,5!d' somefile.txt","title":"Delete all lines except the range specified?"},{"location":"grep_sed_awk_find/#ignore-the-case-sensitivity-when-replacing-a-word-replace-all-old-or-old","text":"- sed 's/old/new/i' somefile.txt","title":"Ignore the case-sensitivity when replacing a word replace all (Old or old)."},{"location":"grep_sed_awk_find/#top","text":"","title":"Top"},{"location":"grep_sed_awk_find/#to-display-only-the-processes-that-belong-to-a-particular-user-use-u-option-the-following-will-show-only-the-top-processes-that-belongs-to-oracle-user","text":"- top -u oracle","title":"To display only the processes that belong to a particular user use -u option. The following will show only the top processes that belongs to oracle user."},{"location":"grep_sed_awk_find/#xargs","text":"","title":"XARGS:"},{"location":"grep_sed_awk_find/#copy-all-jpg-images-to-another-directory","text":"- ls *.jpg | xargs -n1 -i cp {} /another/directory","title":"Copy all .jpg images to another directory:"},{"location":"grep_sed_awk_find/#download-all-the-urls-listed-in-filenametxt-file","text":"- cat filename.txt | xargs wget -c","title":"Download all the URLs listed in filename.txt file:"},{"location":"imagemagick/","text":"imagemagick Adding a background image to a current image: The background image is: zzz.png The current image is: Wisdom_from_Aiko1.png The new image with background is: WfA2.png magick -size 570x873 tile:zzz.png -gravity center Wisdom_from_Aiko1.png WfA2.png Function Resize: Resize(){ #convert -resize 1024x768 $i re_1024x768_$i #magick s1.png -resize 120x120 s1_120x120.png #magick -resize s1.png 50x50 re_50x50_s1.png if [ $# -eq 0 ] then echo \"Usage: Resize filename.xxx size\" echo \"Example: Resize picture.jpg 1024x768\" else echo \"Resizing $1 to $2 ...\" #convert -resize $1 $2 re_$1_$2 magick $1 -resize $2 re_$2_$1 fi } Function ResizeAll: ResizeAll(){ if [ $# -ne 3 ] then echo \"You can resize and convert image format or just resize.\" echo \"Example: ResizeAll png png 800x600\" echo \"or resize and convert ...\" echo \"Example: ResizeAll png jpg 800x600\" #/home/rob/Pictures/Screenshots/z_test else echo \"echo 'Resizing $1 to $2 at $3.'\" let a=1 for i in *.$1; do #echo magick \"$i\"\\'[$3]\\' ${i%.$1}_$a.$2; #echo magick \"$i\"\\'[$3]\\' ${i%.$1}_%003d.$2; echo magick \"$i\"\\'[$3]\\' ${i%.$1}_$3.$2; #/usr/bin/magick \"$i\"\\'[$3]\\' ${i%.$1}_$3.$2; #magick \"$i\" ${i%.$1}.$2; a=$(( $a + 1 )) done fi } Function Convert: Convert(){ #convert -resize 1024x768 $i re_1024x768_$i #for image in *.png;do magick \"$image\" \"${image%.*}.gif\"; done #for image in *.$1; do magick \"$image\" \"${image%.*}.$2\"; done if [ $# -ne 2 ] then echo \"Convert from one image format to another: \" echo \"Usage: Convert png jpg \" echo \" \" echo \"|-------To simultaneously convert and resize----------|\" echo \"| magick 'theimagename.jpg[800x600]' newimagename.png |\" echo \"|-----------------------------------------------------|\" else echo \"Converting $1 to $2 ...\" # for i in $( ls * |awk '{print $9}' ); do convert -resize $1 $i $1_$i ; done #for i in $( ls *.PNG |awk '{print $9}' ); do convert -resize 1024x768 $i re_1024x768_$i; done #for i in $( printf \"%s\\n\" * ); do convert -resize $1 $i $1_$i ; done for image in *.$1; do magick \"$image\" \"${image%.*}.$2\"; done fi }","title":"ImageMagick"},{"location":"imagemagick/#imagemagick","text":"Adding a background image to a current image: The background image is: zzz.png The current image is: Wisdom_from_Aiko1.png The new image with background is: WfA2.png magick -size 570x873 tile:zzz.png -gravity center Wisdom_from_Aiko1.png WfA2.png Function Resize: Resize(){ #convert -resize 1024x768 $i re_1024x768_$i #magick s1.png -resize 120x120 s1_120x120.png #magick -resize s1.png 50x50 re_50x50_s1.png if [ $# -eq 0 ] then echo \"Usage: Resize filename.xxx size\" echo \"Example: Resize picture.jpg 1024x768\" else echo \"Resizing $1 to $2 ...\" #convert -resize $1 $2 re_$1_$2 magick $1 -resize $2 re_$2_$1 fi } Function ResizeAll: ResizeAll(){ if [ $# -ne 3 ] then echo \"You can resize and convert image format or just resize.\" echo \"Example: ResizeAll png png 800x600\" echo \"or resize and convert ...\" echo \"Example: ResizeAll png jpg 800x600\" #/home/rob/Pictures/Screenshots/z_test else echo \"echo 'Resizing $1 to $2 at $3.'\" let a=1 for i in *.$1; do #echo magick \"$i\"\\'[$3]\\' ${i%.$1}_$a.$2; #echo magick \"$i\"\\'[$3]\\' ${i%.$1}_%003d.$2; echo magick \"$i\"\\'[$3]\\' ${i%.$1}_$3.$2; #/usr/bin/magick \"$i\"\\'[$3]\\' ${i%.$1}_$3.$2; #magick \"$i\" ${i%.$1}.$2; a=$(( $a + 1 )) done fi } Function Convert: Convert(){ #convert -resize 1024x768 $i re_1024x768_$i #for image in *.png;do magick \"$image\" \"${image%.*}.gif\"; done #for image in *.$1; do magick \"$image\" \"${image%.*}.$2\"; done if [ $# -ne 2 ] then echo \"Convert from one image format to another: \" echo \"Usage: Convert png jpg \" echo \" \" echo \"|-------To simultaneously convert and resize----------|\" echo \"| magick 'theimagename.jpg[800x600]' newimagename.png |\" echo \"|-----------------------------------------------------|\" else echo \"Converting $1 to $2 ...\" # for i in $( ls * |awk '{print $9}' ); do convert -resize $1 $i $1_$i ; done #for i in $( ls *.PNG |awk '{print $9}' ); do convert -resize 1024x768 $i re_1024x768_$i; done #for i in $( printf \"%s\\n\" * ); do convert -resize $1 $i $1_$i ; done for image in *.$1; do magick \"$image\" \"${image%.*}.$2\"; done fi }","title":"imagemagick"},{"location":"js_notes/","text":"Refresh every 5 seconds: https://stackoverflow.com/questions/7188145/call-a-javascript-function-every-5-seconds-continuously","title":"JS Notes"},{"location":"keybase/","text":"Running Keybase Keybase Help run_keybase keybase chat read keybase chat send Error message: /keybase: Transport endpoint is not connected. I was able to get the keybase directory working after using this command from this link: - cannot access 'keybase': Transport endpoint is not connected (linux) #20331 : sudo fusermount -u /keybase Attachment Download: keybase chat download <team_name> <message_id> -o output_filename Example: keybase chat download rld,sdd 123456 -o xyz.png - Keybase commands I copied from https://book.keybase.io/guides/command-line Generally: -m means a message (as opposed to stdin or an input file) -i means an input file -o means an output file -b means binary output, as opposed to ASCII given keybase user \"max\" keybase encrypt max -m \"this is a secret\" echo \"this is a secret\" | keybase encrypt max keybase encrypt max -i secret.txt keybase encrypt max -i secret.mp3 -b -o secret.mp3.encrypted Encrypting for Keybase users keybase encrypt max -m \"this is a secret for max\" echo \"secret\" | keybase encrypt max echo \"secret\" | keybase encrypt maxtaco@twitter keybase encrypt max -i ~/movie.avi -o ~/movie.avi.encrypted Encrypting for Keybase teams keybase encrypt --team The_Team_Name -m \"This is an encryption test from the commandline to the The_Team_Name team\" | keybase chat send The_Team_Name Decrypting keybase decrypt -i movie.avi.encrypted -o movie.avi keybase decrypt -i some_secret.txt cat some_secret.txt.encrypted | keybase decrypt Signing keybase sign -m \"I hereby abdicate the throne\" keybase sign -i foo.exe -b -o foo.exe.signed Verifying cat some_signed_statement.txt | keybase verify keybase verify -i foo.exe.signed -o foo.exe Encrypting a PGP message If a Keybase user only has a PGP key, or you'd rather encrypt for that: keybase pgp encrypt chris -m \"secret\" # encrypt keybase pgp encrypt maxtaco@twitter -m \"secret\" # using a twitter name keybase pgp encrypt maxtaco@reddit -m \"secret\" # using a Reddit name keybase pgp encrypt chris -s -m \"secret\" # also sign with -s keybase pgp encrypt chris -i foo.txt # foo.txt -> foo.txt.asc keybase pgp encrypt chris -i foo.txt -o bar.asc # foo.txt -> bar.asc echo 'secret' | keybase pgp encrypt chris # stream Decrypting a PGP message keybase pgp decrypt -i foo.txt.asc # foo.txt.asc -> stdout keybase pgp decrypt -i foo.txt.asc -o foo.txt # foo.txt.asc -> foo.txt cat foo.txt.asc | keybase pgp decrypt # decrypt a stream Send attachment from the commandline keybase chat upload user1,user2 filename.txt Signing a PGP message keybase pgp sign -m \"Hello\" # sign a message keybase pgp sign --clearsign -m \"Hello\" # sign, but don't encode contents keybase pgp sign -i foo.txt --detached # generate foo.txt.asc, just a signature keybase pgp sign -i foo.txt # generate foo.txt.asc, containing signed foo.txt echo \"I rock.\" | keybase pgp sign # stream Verifying a PGP message keybase pgp verify -i foo.txt.asc # verify a self-signed file keybase pgp verify -d foo.txt.asc -i foo.txt # verify a file + detached signature cat foo.txt.asc | keybase pgp verify # stream a self-signed file Publishing a bitcoin address keybase btc 1p90X3byTONYhortonETC # sign and set the bitcoin # address on your profile","title":"Keybase"},{"location":"keybase/#running-keybase","text":"Keybase Help run_keybase keybase chat read keybase chat send","title":"Running Keybase"},{"location":"keybase/#error-message-keybase-transport-endpoint-is-not-connected","text":"I was able to get the keybase directory working after using this command from this link: - cannot access 'keybase': Transport endpoint is not connected (linux) #20331 : sudo fusermount -u /keybase","title":"Error message: /keybase: Transport endpoint is not connected."},{"location":"keybase/#attachment-download","text":"keybase chat download <team_name> <message_id> -o output_filename Example: keybase chat download rld,sdd 123456 -o xyz.png","title":"Attachment Download:"},{"location":"keybase/#-keybase-commands-i-copied-from-httpsbookkeybaseioguidescommand-line","text":"","title":"- Keybase commands I copied from https://book.keybase.io/guides/command-line"},{"location":"keybase/#generally","text":"-m means a message (as opposed to stdin or an input file) -i means an input file -o means an output file -b means binary output, as opposed to ASCII","title":"Generally:"},{"location":"keybase/#given-keybase-user-max","text":"keybase encrypt max -m \"this is a secret\" echo \"this is a secret\" | keybase encrypt max keybase encrypt max -i secret.txt keybase encrypt max -i secret.mp3 -b -o secret.mp3.encrypted","title":"given keybase user \"max\""},{"location":"keybase/#encrypting-for-keybase-users","text":"keybase encrypt max -m \"this is a secret for max\" echo \"secret\" | keybase encrypt max echo \"secret\" | keybase encrypt maxtaco@twitter keybase encrypt max -i ~/movie.avi -o ~/movie.avi.encrypted","title":"Encrypting for Keybase users"},{"location":"keybase/#encrypting-for-keybase-teams","text":"keybase encrypt --team The_Team_Name -m \"This is an encryption test from the commandline to the The_Team_Name team\" | keybase chat send The_Team_Name","title":"Encrypting for Keybase teams"},{"location":"keybase/#decrypting","text":"keybase decrypt -i movie.avi.encrypted -o movie.avi keybase decrypt -i some_secret.txt cat some_secret.txt.encrypted | keybase decrypt","title":"Decrypting"},{"location":"keybase/#signing","text":"keybase sign -m \"I hereby abdicate the throne\" keybase sign -i foo.exe -b -o foo.exe.signed","title":"Signing"},{"location":"keybase/#verifying","text":"cat some_signed_statement.txt | keybase verify keybase verify -i foo.exe.signed -o foo.exe","title":"Verifying"},{"location":"keybase/#encrypting-a-pgp-message","text":"If a Keybase user only has a PGP key, or you'd rather encrypt for that: keybase pgp encrypt chris -m \"secret\" # encrypt keybase pgp encrypt maxtaco@twitter -m \"secret\" # using a twitter name keybase pgp encrypt maxtaco@reddit -m \"secret\" # using a Reddit name keybase pgp encrypt chris -s -m \"secret\" # also sign with -s keybase pgp encrypt chris -i foo.txt # foo.txt -> foo.txt.asc keybase pgp encrypt chris -i foo.txt -o bar.asc # foo.txt -> bar.asc echo 'secret' | keybase pgp encrypt chris # stream","title":"Encrypting a PGP message"},{"location":"keybase/#decrypting-a-pgp-message","text":"keybase pgp decrypt -i foo.txt.asc # foo.txt.asc -> stdout keybase pgp decrypt -i foo.txt.asc -o foo.txt # foo.txt.asc -> foo.txt cat foo.txt.asc | keybase pgp decrypt # decrypt a stream","title":"Decrypting a PGP message"},{"location":"keybase/#send-attachment-from-the-commandline","text":"keybase chat upload user1,user2 filename.txt","title":"Send attachment from the commandline"},{"location":"keybase/#signing-a-pgp-message","text":"keybase pgp sign -m \"Hello\" # sign a message keybase pgp sign --clearsign -m \"Hello\" # sign, but don't encode contents keybase pgp sign -i foo.txt --detached # generate foo.txt.asc, just a signature keybase pgp sign -i foo.txt # generate foo.txt.asc, containing signed foo.txt echo \"I rock.\" | keybase pgp sign # stream","title":"Signing a PGP message"},{"location":"keybase/#verifying-a-pgp-message","text":"keybase pgp verify -i foo.txt.asc # verify a self-signed file keybase pgp verify -d foo.txt.asc -i foo.txt # verify a file + detached signature cat foo.txt.asc | keybase pgp verify # stream a self-signed file","title":"Verifying a PGP message"},{"location":"keybase/#publishing-a-bitcoin-address","text":"keybase btc 1p90X3byTONYhortonETC # sign and set the bitcoin # address on your profile","title":"Publishing a bitcoin address"},{"location":"linuxtapedrives/","text":"Managing a tape device Source: Managing tape devices mt -f /dev/st0 status I started using bacula but I am going to keep the \"mt\" tape commands below for future reference. To run bacula from the command line type: bconsole You can also run it from Webmin once you get it installed. The main configuration files for bacula are located in /etc/bacula and /usr/libexec/bacula. There is a bacula log file located here /var/log/bacula/bacula.log. If you download the bacula tar.gz package, it contains an example folder that has some pretty good examles that can be modified. Types of tape devices The following is a list of the different types of tape devices: /dev/st0 is a rewinding tape device. /dev/nst0 is a non-rewinding tape device. Use non-rewinding devices for daily backups. Install the mt-st tool (Tape drive management tool) Install the mt-st package: dnf -y install mt-st Tape commands: Erases the entire tape. mt -f /dev/st0 erase Rewinds the tape device. mt -f /dev/st0 rewind Switches the tape head to the forward record. Here, n is an optional file count. If a file count is specified, tape head skips n records. mt -f /dev/st0 fsf n <--(n is the count (see man mt)) Switches the tape head to the previous record. mt -f /dev/st0 bsfm n Switches the tape head to the end of the data. mt -f /dev/st0 eod Ejects the tape. mt -f /dev/st0 eject https://unix.stackexchange.com/questions/564146/simple-tools-to-read-write-tapes-on-linux We used to store multiple tar archives on a single tape, on Solaris with QIC tapes. To manage the physical tape, there is the mt(1) command. Specifically, this lets you space forward and back using tape marks, using either absolute or relative numbering. Confusingly, the terminology uses \"files\" in the sense of multiple sub-files separated by tape marks. A complete tar archive would correspond to a \"file\". The mt command has a binary and a man page on my Linux Mint 18.1. Tapes are pretty non-standard -- some types of deck won't have all the commands, but tapemarks are pretty fundamental. Standard tape devices usually rewind by default before and after each use, thereby destroying any pre-positioning you do. Typically, each deck has a designator like /dev/rmt0, and an additional device for the same physical unit like /dev/nrmt0 where the n says \"no rewind\". So you embed your append tar command in a script that does something like: mt -f /dev/nrmt0 rewind mt -f /dev/nrmt0 eod tar -f /dev/nrmt0 ... mt -f /dev/rmt0 offline You would need to keep a catalogue of which archives are on which tape and which subfile, and your retrieval would be like: mt -f /dev/nrmt0 rewind mt -f /dev/nrmt0 fsf 17 tar -f /dev/nrmt0 ... Breaking your archives into many smaller sections, and skipping between them, would be a significant optimisation for retrieving small numbers of files.","title":"Linux Tape Drives"},{"location":"linuxtapedrives/#managing-a-tape-device","text":"Source: Managing tape devices","title":"Managing a tape device"},{"location":"linuxtapedrives/#mt-f-devst0-status","text":"","title":"mt -f /dev/st0 status"},{"location":"linuxtapedrives/#i-started-using-bacula-but-i-am-going-to-keep-the-mt-tape-commands-below-for-future-reference","text":"To run bacula from the command line type: bconsole You can also run it from Webmin once you get it installed. The main configuration files for bacula are located in /etc/bacula and /usr/libexec/bacula. There is a bacula log file located here /var/log/bacula/bacula.log. If you download the bacula tar.gz package, it contains an example folder that has some pretty good examles that can be modified.","title":"I started using bacula but I am going to keep the \"mt\" tape commands below for future reference."},{"location":"linuxtapedrives/#types-of-tape-devices","text":"The following is a list of the different types of tape devices: /dev/st0 is a rewinding tape device. /dev/nst0 is a non-rewinding tape device. Use non-rewinding devices for daily backups.","title":"Types of tape devices"},{"location":"linuxtapedrives/#install-the-mt-st-tool-tape-drive-management-tool","text":"Install the mt-st package: dnf -y install mt-st","title":"Install the mt-st tool (Tape drive management tool)"},{"location":"linuxtapedrives/#tape-commands","text":"Erases the entire tape. mt -f /dev/st0 erase Rewinds the tape device. mt -f /dev/st0 rewind Switches the tape head to the forward record. Here, n is an optional file count. If a file count is specified, tape head skips n records. mt -f /dev/st0 fsf n <--(n is the count (see man mt)) Switches the tape head to the previous record. mt -f /dev/st0 bsfm n Switches the tape head to the end of the data. mt -f /dev/st0 eod Ejects the tape. mt -f /dev/st0 eject https://unix.stackexchange.com/questions/564146/simple-tools-to-read-write-tapes-on-linux We used to store multiple tar archives on a single tape, on Solaris with QIC tapes. To manage the physical tape, there is the mt(1) command. Specifically, this lets you space forward and back using tape marks, using either absolute or relative numbering. Confusingly, the terminology uses \"files\" in the sense of multiple sub-files separated by tape marks. A complete tar archive would correspond to a \"file\". The mt command has a binary and a man page on my Linux Mint 18.1. Tapes are pretty non-standard -- some types of deck won't have all the commands, but tapemarks are pretty fundamental. Standard tape devices usually rewind by default before and after each use, thereby destroying any pre-positioning you do. Typically, each deck has a designator like /dev/rmt0, and an additional device for the same physical unit like /dev/nrmt0 where the n says \"no rewind\". So you embed your append tar command in a script that does something like: mt -f /dev/nrmt0 rewind mt -f /dev/nrmt0 eod tar -f /dev/nrmt0 ... mt -f /dev/rmt0 offline You would need to keep a catalogue of which archives are on which tape and which subfile, and your retrieval would be like: mt -f /dev/nrmt0 rewind mt -f /dev/nrmt0 fsf 17 tar -f /dev/nrmt0 ... Breaking your archives into many smaller sections, and skipping between them, would be a significant optimisation for retrieving small numbers of files.","title":"Tape commands:"},{"location":"linuxuser/","text":"If you want to find the system ID of the user type: id username You can check what groups a user belongs to by using the \"groups\" command. groups <username> To create a user with the default groups type: sudo adduser --add_extra_groups username Fedora: sudo adduser -m username To delete a user and its primary group type: sudo deluser username To add an existing user to an existing group type: sudo usermod -a -G thegroupname theusername sudo usermod -a -G thegroupname theusername sudo useradd -G thegroupname theusername Use gpasswd: sudo gpasswd -a theusername thegroupname To remove user billybob from the group hillbilly. gpasswd -d billybob hillbilly To give user billybob administrative rights to the group hillbilly. gpasswd -A billybob hillbilly To Change a users primary group type: useradd -g www joebob To show users that are in a group named joebob type: getent group joebob To temporarily lock or unlock a user account, use the following syntax, respectively: sudo passwd -l username sudo passwd -u username If you want to use the GUI you will have to install the gnome-system-tools sudo apt-get install gnome-system-tools Here are a few ways to run it once it is installed type: sudo users-admin Press Alt+F2 Type sudo users-admin Press Enter. Press Ctrl+Alt+T . Type sudo users-admin Press Enter. If you want to add a group type: sudo groupadd foo sudo addgroup groupname If you want to delete a group type: sudo delgroup groupname User Profile Security when a new user is created, the adduser utility creates a brand new home directory named /home/username , respectively. The default profile is modeled after the contents found in the directory of /etc/skel , which includes all profile basics. If your server will be home to multiple users, you should pay close attention to the user home directory permissions to ensure confidentiality. By default, user home directories in Ubuntu are created with world read/execute permissions. This means that all users can browse and access the contents of other users home directories. This may not be suitable for your environment. To verify your current users home directory permissions, use the following syntax: ls -ld /home/username The following output shows that the directory /home/username has world readable permissions: drwxr-xr-x 2 username username 4096 2007-10-02 20:03 username You can remove the world readable permissions using the following syntax: sudo chmod 0750 /home/username Some people tend to use the recursive option ( -R ) indiscriminately which modifies all child folders and files, but this is not necessary, and may yield other undesirable results. The parent directory alone is sufficient for preventing unauthorized access to anything below the parent. A much more efficient approach to the matter would be to modify the adduser global default permissions when creating user home folders. Simply edit the file /etc/adduser.conf and modify the DIR_MODE variable to something appropriate, so that all new home directories will receive the correct permissions. DIR_MODE=0750 After correcting the directory permissions using any of the previously mentioned techniques, verify the results using the following syntax: ls -ld /home/username The results below show that world readable permissions have been removed: drwxr-x--- 2 username username 4096 2007-10-02 20:03 username Password Policy A strong password policy is one of the most important aspects of your security posture. Many successful security breaches involve simple brute force and dictionary attacks against weak passwords. If you intend to offer any form of remote access involving your local password system, make sure you adequately address minimum password complexity requirements, maximum password lifetimes, and frequent audits of your authentication systems. Minimum Password Length By default, Ubuntu requires a minimum password length of 6 characters , as well as some basic entropy checks (Fedora has a minimum of 8 characters) . These values are controlled in the file /etc/pam.d/common-password , which is outlined below. password required pam_unix.so nullok obscure min=4 max=8 md5 If you would like to adjust the minimum length to 6 characters, change the appropriate variable to min=6. The modification is outlined below. password required pam_unix.so nullok obscure min=6 max=8 md5 The max=8 variable does not represent the maximum length of a password. It only means that complexity requirements will not be checked on passwords over 8 characters. You may want to look at the libpam-cracklib package for additional password entropy assistance. Password Expiration When creating user accounts, you should make it a policy to have a minimum and maximum password age forcing users to change their passwords when they expire. To easily view the current status of a user account, use the following syntax: sudo chage -l username The output below shows interesting facts about the user account, namely that there are no policies applied: Last password change : Jan 20, 2008 Password expires : never Password inactive : never Account expires : never Minimum number of days between password change : 0 Maximum number of days between password change : 99999 Number of days of warning before password expires : 7 To set any of these values, simply use the following syntax, and follow the interactive prompts: sudo chage username The following is also an example of how you can manually change the explicit expiration date (-E) to 01/31/2008, minimum password age (-m) of 5 days, maximum password age (-M) of 90 days, inactivity period (-I) of 5 days after password expiration, and a warning time period (-W) of 14 days before password expiration. sudo chage -E 01/31/2008 -m 5 -M 90 -I 30 -W 14 username To verify changes, use the same syntax as mentioned previously: sudo chage -l username The output below shows the new policies that have been established for the account: Last password change : Jan 20, 2008 Password expires : Apr 19, 2008 Password inactive : May 19, 2008 Account expires : Jan 31, 2008 Minimum number of days between password change : 5 Maximum number of days between password change : 90 Number of days of warning before password expires : 14 Other Security Considerations Many applications use alternate authentication mechanisms that can be easily overlooked by even experienced system administrators. Therefore, it is important to understand and control how users authenticate and gain access to services and applications on your server. SSH Access by Disabled Users Simply disabling/locking a user account will not prevent a user from logging into your server remotely if they have previously set up RSA public key authentication. They will still be able to gain shell access to the server, without the need for any password. Remember to check the users home directory for files that will allow for this type of authenticated SSH access. e.g. /home/username/.ssh/authorized_keys . Remove or rename the directory .ssh/ in the user's home folder to prevent further SSH authentication capabilities. Be sure to check for any established SSH connections by the disabled user, as it is possible they may have existing inbound or outbound connections. Kill any that are found. Restrict SSH access to only user accounts that should have it. For example, you may create a group called \"sshlogin\" and add the group name as the value associated with the AllowGroups variable located in the file /etc/ssh/sshd_config . AllowGroups sshlogin Then add your permitted SSH users to the group \"sshlogin\", and restart the SSH service. sudo adduser username sshlogin sudo /etc/init.d/ssh restart MakeUser Function for .bashrc file: makeuser () { if [ $# -eq 0 ] then echo \"Usage: makeuser username.\" else sudo adduser --add_extra_groups $1 fi } Source for most of this document: | Ubuntu Server User and Group Administration","title":"Linux User Admin"},{"location":"luks/","text":"Mounting and Unmounting a LUKS Encrypted USB Volume Mounting and Unmounting a LUKS Encrypted USB Volume This process also works for hard drives. Basic commands to view the disks/USB devices: blkid duf lsblk lsblk -a lsblk -o +UUID,PARTUUID lsblk -o +UUID,FSTYPE,PARTUUID ls -lF /dev/disk/by-id sudo lshw -short -C disk sudo udisksctl info -b /dev/?? 01. USB drive has not been inserted (plugged in) yet. To see volumes type: lsblk 02. GUI password prompt when encrypted drive is plugged in (I clicked cancel to demonstrate mounting from commandline). 03. USB drive inserted (plugged in) and showing as /dev/sdm1. To see volumes type: lsblk 04. Check the volume information type: sudo udisksctl info -b /dev/sdm1 or sudo cryptsetup isLuks -v /dev/sdm1 The volume /dev/sdm1 shows as \"crypto_LUKS\". 05. If you try to mount the locked LUKS encrypted volume it will fail. (Screenshot shows mount failed. This is because the volume is locked. Run cryptsetup first to unlock.). 06. Running cryptsetup to unlock the encrypted volume (Assigning alias of \"2T_SSD\" to reference the unlocked volume. The alias can be whatever you want.). To open the encrypted filesystem type: sudo cryptsetup luksOpen /dev/sdm1 2T_SSD 07. Decrypted volume showing as 2T_SSD, but not yet mounted. To see the unlocked volume type: lsblk 08. Decrypted volume alias \"2T_SSD\" showing under /dev/mapper. Check /dev/mapper to see if your alias is there: ls -al /dev/mapper 09. Password prompt when using sudo to mount decrypted 2T_SSD volume to /dev/m. To mount your alias to a mount point type: sudo mount /dev/mapper/2T_SSD /mnt/m 10. Decrypted volume showing unlocked and mounted at /mnt/m. To see volumes type: lsblk 11. Unmounting /mnt/m. To unmount the volume type: sudo umount /mnt/m 12. Closing cryptsetup session (Locking it). To close the volume type: sudo cryptsetup close 2T_SSD 13. USB drive unmounted and unplugged from system. To see volumes type: lsblk Mount a USB volume and use umask to allow \"other\" full access. sudo mount /dev/sdi1 /mnt/i -o umask=000,utf8 Automatically mount using fstab. You can automatically mount by UUID if you want the mount points to consistently mount to the same device. Each partition on a drive will have its own UUID. Use this to find the UUID: lsblk -o +UUID,PARTUUID In fstab; UUID=FC3E-233D /mnt/i auto user,umask=000,utf8 0 0 UUID=B06E-CC89 /mnt/c auto user,umask=000,utf8 0 0 UUID=02608207608201A1 /mnt/h auto user,umask=000,utf8 0 0 After editing the fstab file, run 'systemctl daemon-reload' to update systemd Luks Header Backup and Restore https://www.cyberciti.biz/security/how-to-backup-and-restore-luks-header-on-linux/ Creating LUKS Header Backup: Syntax: sudo cryptsetup luksHeaderBackup /dev/XXX --header-backup-file myfile.bin Example: sudo cryptsetup luksHeaderBackup /dev/sda3 --header-backup-file my_luks_header.bin sudo cryptsetup luksHeaderBackup /dev/sdb --header-backup-file my_luks_header.bin Side note: The permission on the bin files that are created are 400 and the owner is root. Check the file type: sudo file my_luks_header.bin my_luks_header.bin: LUKS encrypted file, ver 2 [, , sha256] UUID: 9e5f5c4b-a4bb-464a-80c6-118c22e35e8f Use luksDump to view information about the file: sudo cryptsetup luksDump my_luks_header.bin Restoring LUKS header when needed: cryptsetup luksHeaderRestore /dev/XXX --header-backup-file /path/to/my_luks_header.bin Assuming that your header file is on /dev/external/volume cryptsetup luksHeaderRestore /dev/md1 --header-backup-file /dev/external/volume/my_luks_header.bin WARNING! ======== Device /dev/XXX already contains LUKS2 header. Replacing header will destroy existing keyslots. Are you sure? (Type uppercase yes): YES","title":"LUKS"},{"location":"luks/#mounting-and-unmounting-a-luks-encrypted-usb-volume","text":"","title":"Mounting and Unmounting a LUKS Encrypted USB Volume"},{"location":"luks/#mounting-and-unmounting-a-luks-encrypted-usb-volume_1","text":"This process also works for hard drives.","title":"Mounting and Unmounting a LUKS Encrypted USB Volume"},{"location":"luks/#basic-commands-to-view-the-disksusb-devices","text":"blkid duf lsblk lsblk -a lsblk -o +UUID,PARTUUID lsblk -o +UUID,FSTYPE,PARTUUID ls -lF /dev/disk/by-id sudo lshw -short -C disk sudo udisksctl info -b /dev/??","title":"Basic commands to view the disks/USB devices:"},{"location":"luks/#01-usb-drive-has-not-been-inserted-plugged-in-yet","text":"To see volumes type: lsblk","title":"01. USB drive has not been inserted (plugged in) yet."},{"location":"luks/#02-gui-password-prompt-when-encrypted-drive-is-plugged-in-i-clicked-cancel-to-demonstrate-mounting-from-commandline","text":"","title":"02. GUI password prompt when encrypted drive is plugged in (I clicked cancel to demonstrate mounting from commandline)."},{"location":"luks/#03-usb-drive-inserted-plugged-in-and-showing-as-devsdm1","text":"To see volumes type: lsblk","title":"03. USB drive inserted (plugged in) and showing as /dev/sdm1."},{"location":"luks/#04-check-the-volume-information-type","text":"sudo udisksctl info -b /dev/sdm1 or sudo cryptsetup isLuks -v /dev/sdm1 The volume /dev/sdm1 shows as \"crypto_LUKS\".","title":"04. Check the volume information type:"},{"location":"luks/#05-if-you-try-to-mount-the-locked-luks-encrypted-volume-it-will-fail-screenshot-shows-mount-failed-this-is-because-the-volume-is-locked-run-cryptsetup-first-to-unlock","text":"","title":"05. If you try to mount the locked LUKS encrypted volume it will fail. (Screenshot shows mount failed. This is because the volume is locked. Run cryptsetup first to unlock.)."},{"location":"luks/#06-running-cryptsetup-to-unlock-the-encrypted-volume-assigning-alias-of-2t_ssd-to-reference-the-unlocked-volume-the-alias-can-be-whatever-you-want","text":"To open the encrypted filesystem type: sudo cryptsetup luksOpen /dev/sdm1 2T_SSD","title":"06. Running cryptsetup to unlock the encrypted volume (Assigning alias of \"2T_SSD\" to reference the unlocked volume. The alias can be whatever you want.)."},{"location":"luks/#07-decrypted-volume-showing-as-2t_ssd-but-not-yet-mounted","text":"To see the unlocked volume type: lsblk","title":"07. Decrypted volume showing as 2T_SSD, but not yet mounted."},{"location":"luks/#08-decrypted-volume-alias-2t_ssd-showing-under-devmapper","text":"Check /dev/mapper to see if your alias is there: ls -al /dev/mapper","title":"08. Decrypted volume alias \"2T_SSD\" showing under /dev/mapper."},{"location":"luks/#09-password-prompt-when-using-sudo-to-mount-decrypted-2t_ssd-volume-to-devm","text":"To mount your alias to a mount point type: sudo mount /dev/mapper/2T_SSD /mnt/m","title":"09. Password prompt when using sudo to mount decrypted 2T_SSD volume to /dev/m."},{"location":"luks/#10-decrypted-volume-showing-unlocked-and-mounted-at-mntm","text":"To see volumes type: lsblk","title":"10. Decrypted volume showing unlocked and mounted at /mnt/m."},{"location":"luks/#11-unmounting-mntm","text":"To unmount the volume type: sudo umount /mnt/m","title":"11. Unmounting /mnt/m."},{"location":"luks/#12-closing-cryptsetup-session-locking-it","text":"To close the volume type: sudo cryptsetup close 2T_SSD","title":"12. Closing cryptsetup session (Locking it)."},{"location":"luks/#13-usb-drive-unmounted-and-unplugged-from-system","text":"To see volumes type: lsblk","title":"13. USB drive unmounted and unplugged from system."},{"location":"luks/#mount-a-usb-volume-and-use-umask-to-allow-other-full-access","text":"","title":"Mount a USB volume and use umask to allow \"other\" full access."},{"location":"luks/#_1","text":"sudo mount /dev/sdi1 /mnt/i -o umask=000,utf8","title":""},{"location":"luks/#automatically-mount-using-fstab","text":"","title":"Automatically mount using fstab."},{"location":"luks/#you-can-automatically-mount-by-uuid-if-you-want-the-mount-points-to-consistently-mount-to-the-same-device-each-partition-on-a-drive-will-have-its-own-uuid","text":"Use this to find the UUID: lsblk -o +UUID,PARTUUID In fstab; UUID=FC3E-233D /mnt/i auto user,umask=000,utf8 0 0 UUID=B06E-CC89 /mnt/c auto user,umask=000,utf8 0 0 UUID=02608207608201A1 /mnt/h auto user,umask=000,utf8 0 0 After editing the fstab file, run 'systemctl daemon-reload' to update systemd","title":"You can automatically mount by UUID if you want the mount points to consistently mount to the same device. Each partition on a drive will have its own UUID."},{"location":"luks/#luks-header-backup-and-restore","text":"","title":"Luks Header Backup and Restore"},{"location":"luks/#httpswwwcybercitibizsecurityhow-to-backup-and-restore-luks-header-on-linux","text":"","title":"https://www.cyberciti.biz/security/how-to-backup-and-restore-luks-header-on-linux/"},{"location":"luks/#creating-luks-header-backup","text":"Syntax: sudo cryptsetup luksHeaderBackup /dev/XXX --header-backup-file myfile.bin Example: sudo cryptsetup luksHeaderBackup /dev/sda3 --header-backup-file my_luks_header.bin sudo cryptsetup luksHeaderBackup /dev/sdb --header-backup-file my_luks_header.bin Side note: The permission on the bin files that are created are 400 and the owner is root. Check the file type: sudo file my_luks_header.bin my_luks_header.bin: LUKS encrypted file, ver 2 [, , sha256] UUID: 9e5f5c4b-a4bb-464a-80c6-118c22e35e8f Use luksDump to view information about the file: sudo cryptsetup luksDump my_luks_header.bin","title":"Creating LUKS Header Backup:"},{"location":"luks/#restoring-luks-header-when-needed","text":"cryptsetup luksHeaderRestore /dev/XXX --header-backup-file /path/to/my_luks_header.bin Assuming that your header file is on /dev/external/volume cryptsetup luksHeaderRestore /dev/md1 --header-backup-file /dev/external/volume/my_luks_header.bin WARNING! ======== Device /dev/XXX already contains LUKS2 header. Replacing header will destroy existing keyslots. Are you sure? (Type uppercase yes): YES","title":"Restoring LUKS header when needed:"},{"location":"lvm/","text":"Volume Group Quick Info: Volumegroup commands sudo vgs - Show volume groups and information about them. sudo vgscan - Show any volume group that is found. Encrypted volume groups will not show unless open by luks. sudo vgscan --mknodes (checks the LVM special files in /dev that are needed for active LVs and creates any missing ones and removes unused ones.) sudo vgdisplay - Show more detailed information about each volume group. (-v will show more verbose, -vv even more). sudo vgchange -ay (VG change active yes) sudo pvs - Show information about the physical volumes. sudo pvscan - Show information about the physical volumes. sudo pvdisplay - Show more detailed information about each physical volume. (-v will show more verbose, -vv even more). sudo lvs - Show information about logical volumes. sudo lvscan - Show active/inactive logical volumes. sudo lvdisplay - Show detailed information about the logical volumes. (-v will show more verbose, -vv even more). sudo lvdisplay|grep \"LV Path\" sudo lsblk -a Show volumes and where they are mounted. sudo udisksctl status - Shows high-level information about disk drives and block devices. gnome-disks --block-device=/dev/sdX - Opens the disk manager for the volume specified. sudo blkid |grep crypto - Show the encrypted volume IDs. sudo cryptsetup isLuks -v /dev/sdb - Show the encrypted volume ID. sudo cryptsetup luksOpen /dev/sdX TheUUIDofTheDevice - Open the encrypted volume. sudo cryptsetup luksUUID /dev/sd? #Show the Luks UUID of the device. sudo udisksctl info -b /dev/sd? #Show the Luks UUID of the device. sudo udisksctl dump - Show an insane amount of information about the volumes. Examples: sudo mount /dev/volumegroupname/logicalvolumename /mnt/mountpoint sudo mount /dev/vg_data/lv_data2 /mnt/data2 sudo mount -a #Mount everything in /etc/fstab. https://github.com/rlholland/miscellaneous/blob/master/Linux/Logical_Volume_Manager.txt. https://evilshit.wordpress.com/2012/10/29/how-to-mount-luks-encrypted-partitions-manually.. Check information about storage devices: Run fdisk -l to see information about storage devices. The ones that show \"Linux LVM\" are logical volumes that haven't been created into physical volumes using (pvcreate). Type: pvcreate /dev/sda2 (Use -v to see verbose information. The more -v's the more information you will see.) Type: pvs to see the volume that was just created. Type: pvremove /dev/sda2 Any time you can see all block devices that may be used as a PV, use the command: Type: lvmdiskscan This will show you the devices that \"pvcreate\" has been used on (LVM physical volume) and can be used as a physical volume. It also shows devices that pvcreate has not been used on (do not show up as LVM physical volume). Once the physical volume is created you need to add it to a Volume Group: Create the volume group and add the PV to it in one command: Type: vgcreate vgVolume_Group_Name /dev/sda2 EX: vgcreate onevg /dev/sda2 If you want more than one PV in your VG: EX: vgcreate onevg /dev/sda2 /dev/sda3 Type: vgremove to delete it. Make sure there are no LV and no data before removing VG. EX: vgremove onevg To see information about the volume group: Type: pvs (Physical Volume Show) This will show you the physical volume(s), the volume group, format, physical size, and physical free You can also use another command to see information about the volume group: Type: vgs (Volume Group Show) EX: vgs -vv This will show you the attributes, extent size, physical volumes, logical volumes, serial number, volume size, volume free Display information about the physical volumes: Type: pvdisplay If you add another physical device you can add it to a volume group: Type: vgextend TheVolumeGroupName /dev/sda2 EX: vgextend onevg /dev/sda2 Type: vgreduce TheVolumeGroupName /dev/sda2 to remove it from the VG. EX: vgreduce onevg /dev/sda2 Check for volume groups: Type: vgscan This command is run automatically when the system starts up. Split Volume Group: Type: vgsplit OriginalNamed_VG NewNamed_VG /dev/sda2 EX: vgsplit onevg newvg /dev/sda2 This command removes the physical volume named /dev/sda2 from the volume group onevg and adds it to a new volume group called newvg. Merge/Add a volume back to a Volume Group: Type: vgmerge -v VolumeGroupYouWantToKeep VolumeGroupYouWantToMerge This command merges VolumeGroupYouWantToMerge into VolumeGroupYouWantToKeep Rename a Volume Group: Type: vgrename OldVGName NewVGName EX: vgrename onevg newvg Create a logical volume inside of a Volume group: Type: lvcreate -L 500M -n TheNameOfLV TheNameOfVGTheLVWillBeCreatedIn EX: lvcreate -L 500M -n lvone onevg This command creates a physical volume named TheNameOfLV inside the volume group named TheNameOfVGTheLVWillBeCreatedIn Method 2 (example 1): Type: lvcreate -l 50%VG -n TheNameOfLV TheNameOfVGTheLVWillBeCreatedIn EX: lvcreate -l 50%VG -n lvtwo VGOne This command will use up 50% of the volume group to create a new logical volume named lvtwo Method 2 (example 2): Type: lvcreate -l 100%FREE -n TheNameOfLV TheNameOfVGTheLVWillBeCreatedIn EX: lvcreate -l 100%FREE -n lvthree onevg (This worked on Ubuntu) Remove the physical volume: Type: lvremove /dev/TheNameOfVG/TheNameOfPVlv EX: lvremove /dev/onevg/lvthree Method 3 (Create LV using Extents): Type: lvcreate -l 444 TheNameOfVG -n TheNameOfPV EX: lvcreate -l 444 onevg -n lvfour This command creates a physical volume of 444 extents named lvfour. Volume Groups are linear, meaning that if you have multiple PV's inside of your VG and you create an LV of any size, the first PV will be used by default then the second, third, etc. To change this behavior, you can create an LV on a PV that you specify. Type: lvcreate -L 500M -n NewNameOfLV TheNameOfVG /Name/of/PV EX: lvcreate -L 500M -n lvnew onevg /dev/sda9 Method 4 (Create LV using Extents from two different PV's) Create a logical volume of 50 extents using 25 extents from two separate PV's: Type: lvcreate -l 50 -n lvone onevg /dev/sda6:0-25 /dev/sda7:0-25 Method 5 (Create LV using non-contiguous Extents from one PV). Skipping using some Extents, skipping a few, and using the rest. Type: lvcreate -l 50 -n lvone onvg /dev/sda6:0-20:40- To remove two extents from the 50: Type: lvreduce -l -2 /dev/onevg/lvone This command creates the logical volume of 50 extents using the first 20 Extents then skipping to 40 and using everything after. Make the LV read only: Type: lvchange -pr /dev/onevg/lvone <--(The p means \"permissions\" and the r means \"Read Only\") Type: lvdisplay Grow an LV. Type: lvextend -L1g <--(Grow the logical volume by to 1G) Type: lvs to see the change. Type: lvextend -L+20M <--(grow the logical volume by 20 MB) Type: lvextend -l +100%FREE /dev/onevg/lvone <--(Use up all the free space) Adjust LVS (Logical Volume Show) output: lvs -v --segments <--(will show linear, stripe, mirror, etc) Adjust the PVS (Physical Volume Show) output: pvs --separator = <--(Use an = sign as the delimiter) pvs --separator = --aligned <--(Make it neater looking) pvs -a <--(Shows all devices so you can see what PV's are attached to VG's) pvs -o pv_name,pv_size,pv_free <--(Shows the PV name, PV size, and PV free) pvs -o pv_name,pv_size,pv_free +O -pv_size <--(sort by pv_size. Uppercase Letter +O) pvs -o pv_name,pv_size,pv_free -O -pv_size <--(sort by pv_size. Uppercase Letter -O) pvs --units m <--(Megabytes) pvs --units G <--(Gigabytes) Adjust the VGS (Volume Groups Show) output: vgs -o +pv_name <--(Shows the PV and the VG) After I created the logical volume on Ubuntu I formatted them using ext4: I found the format path by typing \"sudo lvdisplay\" which showed me the LV path below: sudo mkfs.ext4 /dev/vg_data/lv_data1 sudo mkfs.ext4 /dev/vg_data/lv_data2 Show the filesystem type and other df information: df -Th http://superuser.com/questions/116617/how-to-mount-an-lvm-volume Find the logical volume that has your Fedora root filesystem (mine proved to be LogVol00): $ sudo lvs Create a mount point for that volume: $ sudo mkdir /mnt/fcroot Mount it: $ sudo mount /dev/VolGroup00/LogVol00 /mnt/fcroot -o ro,user You're done, navigate to /mnt/fcroot and copy the files and paste somewhere else. I changed the permissions on the new volume so that anyone in the sambashare group could read/write to it. sudo chown -R root:sambashare /mnt/data1 sudo chmod o-rwx /mnt/data1 (remove access to anyone else). Make sure the group has access to the repository: sudo chgrp -R sambashare /mnt/data1 (-R set the group ownership recursively). sudo chmod g+rws /mnt/data1 (set the sticky bit so changes are owned by the group). sudo chmod o-rwx /mnt/data1 (remove access for \"other\" so only group members can clone). https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/High_Availability_Add-On_Administration/s1-LVMsetupnfs-HAAA.html Create the physical volume: sudo pvcreate /dev/sdb1 Create the volume group and add the physical volume to it: sudo vgcreate my_vg /dev/sdb1 Create 450MB logical volume in my_lv inside volume group my_vg: sudo lvcreate -L450 -n my_lv my_vg Show the logical volumes: sudo lvs Format the logical volume \"my_lv\" inside volume group \"my_vg\" with ext4 filesystem: sudo mkfs.ext4 /dev/my_vg/my_lv I have extended the root filesystem from 15GB to 500GB using lvextend, however I cannot use the extra space because the file system is still formatted for 15GB. I have to use: resize2fs /dev/fedora/root to increase the size but the file system has to be unmounted for me to run resize2fs. Ubuntu Link: https://help.ubuntu.com/community/UbuntuDesktopLVM Helpful HTTP Links: What mount points exist on a typical Linux system Increase the size of the logical volume UMount Resizing partitions using FDISK Logical Volume Manager - Deep Inside How to mount an LVM volume How to partition hard drive on CentOS Linux using fdisk Managing Storage with the Linux Logical Volume Manager (LVM) Increase the size of an EXT2, EXT3, EXT4 filesystem link link","title":"LVM - Linux Volume Manager"},{"location":"lvm/#volume-group-quick-info","text":"","title":"Volume Group Quick Info:"},{"location":"lvm/#volumegroup-commands","text":"sudo vgs - Show volume groups and information about them. sudo vgscan - Show any volume group that is found. Encrypted volume groups will not show unless open by luks. sudo vgscan --mknodes (checks the LVM special files in /dev that are needed for active LVs and creates any missing ones and removes unused ones.) sudo vgdisplay - Show more detailed information about each volume group. (-v will show more verbose, -vv even more). sudo vgchange -ay (VG change active yes) sudo pvs - Show information about the physical volumes. sudo pvscan - Show information about the physical volumes. sudo pvdisplay - Show more detailed information about each physical volume. (-v will show more verbose, -vv even more). sudo lvs - Show information about logical volumes. sudo lvscan - Show active/inactive logical volumes. sudo lvdisplay - Show detailed information about the logical volumes. (-v will show more verbose, -vv even more). sudo lvdisplay|grep \"LV Path\" sudo lsblk -a Show volumes and where they are mounted. sudo udisksctl status - Shows high-level information about disk drives and block devices. gnome-disks --block-device=/dev/sdX - Opens the disk manager for the volume specified. sudo blkid |grep crypto - Show the encrypted volume IDs. sudo cryptsetup isLuks -v /dev/sdb - Show the encrypted volume ID. sudo cryptsetup luksOpen /dev/sdX TheUUIDofTheDevice - Open the encrypted volume. sudo cryptsetup luksUUID /dev/sd? #Show the Luks UUID of the device. sudo udisksctl info -b /dev/sd? #Show the Luks UUID of the device. sudo udisksctl dump - Show an insane amount of information about the volumes. Examples: sudo mount /dev/volumegroupname/logicalvolumename /mnt/mountpoint sudo mount /dev/vg_data/lv_data2 /mnt/data2 sudo mount -a #Mount everything in /etc/fstab. https://github.com/rlholland/miscellaneous/blob/master/Linux/Logical_Volume_Manager.txt. https://evilshit.wordpress.com/2012/10/29/how-to-mount-luks-encrypted-partitions-manually..","title":"Volumegroup commands"},{"location":"lvm/#check-information-about-storage-devices","text":"Run fdisk -l to see information about storage devices. The ones that show \"Linux LVM\" are logical volumes that haven't been created into physical volumes using (pvcreate). Type: pvcreate /dev/sda2 (Use -v to see verbose information. The more -v's the more information you will see.) Type: pvs to see the volume that was just created. Type: pvremove /dev/sda2","title":"Check information about storage devices:"},{"location":"lvm/#any-time-you-can-see-all-block-devices-that-may-be-used-as-a-pv-use-the-command","text":"Type: lvmdiskscan This will show you the devices that \"pvcreate\" has been used on (LVM physical volume) and can be used as a physical volume. It also shows devices that pvcreate has not been used on (do not show up as LVM physical volume).","title":"Any time you can see all block devices that may be used as a PV, use the command:"},{"location":"lvm/#once-the-physical-volume-is-created-you-need-to-add-it-to-a-volume-group","text":"Create the volume group and add the PV to it in one command: Type: vgcreate vgVolume_Group_Name /dev/sda2 EX: vgcreate onevg /dev/sda2 If you want more than one PV in your VG: EX: vgcreate onevg /dev/sda2 /dev/sda3 Type: vgremove to delete it. Make sure there are no LV and no data before removing VG. EX: vgremove onevg","title":"Once the physical volume is created you need to add it to a Volume Group:"},{"location":"lvm/#to-see-information-about-the-volume-group","text":"Type: pvs (Physical Volume Show) This will show you the physical volume(s), the volume group, format, physical size, and physical free You can also use another command to see information about the volume group: Type: vgs (Volume Group Show) EX: vgs -vv This will show you the attributes, extent size, physical volumes, logical volumes, serial number, volume size, volume free Display information about the physical volumes: Type: pvdisplay","title":"To see information about the volume group:"},{"location":"lvm/#if-you-add-another-physical-device-you-can-add-it-to-a-volume-group","text":"Type: vgextend TheVolumeGroupName /dev/sda2 EX: vgextend onevg /dev/sda2 Type: vgreduce TheVolumeGroupName /dev/sda2 to remove it from the VG. EX: vgreduce onevg /dev/sda2","title":"If you add another physical device you can add it to a volume group:"},{"location":"lvm/#check-for-volume-groups","text":"Type: vgscan This command is run automatically when the system starts up.","title":"Check for volume groups:"},{"location":"lvm/#split-volume-group","text":"Type: vgsplit OriginalNamed_VG NewNamed_VG /dev/sda2 EX: vgsplit onevg newvg /dev/sda2 This command removes the physical volume named /dev/sda2 from the volume group onevg and adds it to a new volume group called newvg.","title":"Split Volume Group:"},{"location":"lvm/#mergeadd-a-volume-back-to-a-volume-group","text":"Type: vgmerge -v VolumeGroupYouWantToKeep VolumeGroupYouWantToMerge This command merges VolumeGroupYouWantToMerge into VolumeGroupYouWantToKeep","title":"Merge/Add a volume back to a Volume Group:"},{"location":"lvm/#rename-a-volume-group","text":"Type: vgrename OldVGName NewVGName EX: vgrename onevg newvg","title":"Rename a Volume Group:"},{"location":"lvm/#create-a-logical-volume-inside-of-a-volume-group","text":"Type: lvcreate -L 500M -n TheNameOfLV TheNameOfVGTheLVWillBeCreatedIn EX: lvcreate -L 500M -n lvone onevg This command creates a physical volume named TheNameOfLV inside the volume group named TheNameOfVGTheLVWillBeCreatedIn Method 2 (example 1): Type: lvcreate -l 50%VG -n TheNameOfLV TheNameOfVGTheLVWillBeCreatedIn EX: lvcreate -l 50%VG -n lvtwo VGOne This command will use up 50% of the volume group to create a new logical volume named lvtwo Method 2 (example 2): Type: lvcreate -l 100%FREE -n TheNameOfLV TheNameOfVGTheLVWillBeCreatedIn EX: lvcreate -l 100%FREE -n lvthree onevg (This worked on Ubuntu) Remove the physical volume: Type: lvremove /dev/TheNameOfVG/TheNameOfPVlv EX: lvremove /dev/onevg/lvthree Method 3 (Create LV using Extents): Type: lvcreate -l 444 TheNameOfVG -n TheNameOfPV EX: lvcreate -l 444 onevg -n lvfour This command creates a physical volume of 444 extents named lvfour. Volume Groups are linear, meaning that if you have multiple PV's inside of your VG and you create an LV of any size, the first PV will be used by default then the second, third, etc. To change this behavior, you can create an LV on a PV that you specify. Type: lvcreate -L 500M -n NewNameOfLV TheNameOfVG /Name/of/PV EX: lvcreate -L 500M -n lvnew onevg /dev/sda9 Method 4 (Create LV using Extents from two different PV's) Create a logical volume of 50 extents using 25 extents from two separate PV's: Type: lvcreate -l 50 -n lvone onevg /dev/sda6:0-25 /dev/sda7:0-25 Method 5 (Create LV using non-contiguous Extents from one PV). Skipping using some Extents, skipping a few, and using the rest. Type: lvcreate -l 50 -n lvone onvg /dev/sda6:0-20:40- To remove two extents from the 50: Type: lvreduce -l -2 /dev/onevg/lvone This command creates the logical volume of 50 extents using the first 20 Extents then skipping to 40 and using everything after. Make the LV read only: Type: lvchange -pr /dev/onevg/lvone <--(The p means \"permissions\" and the r means \"Read Only\") Type: lvdisplay Grow an LV. Type: lvextend -L1g <--(Grow the logical volume by to 1G) Type: lvs to see the change. Type: lvextend -L+20M <--(grow the logical volume by 20 MB) Type: lvextend -l +100%FREE /dev/onevg/lvone <--(Use up all the free space)","title":"Create a logical volume inside of a Volume group:"},{"location":"lvm/#adjust-lvs-logical-volume-show-output","text":"lvs -v --segments <--(will show linear, stripe, mirror, etc)","title":"Adjust LVS (Logical Volume Show) output:"},{"location":"lvm/#adjust-the-pvs-physical-volume-show-output","text":"pvs --separator = <--(Use an = sign as the delimiter) pvs --separator = --aligned <--(Make it neater looking) pvs -a <--(Shows all devices so you can see what PV's are attached to VG's) pvs -o pv_name,pv_size,pv_free <--(Shows the PV name, PV size, and PV free) pvs -o pv_name,pv_size,pv_free +O -pv_size <--(sort by pv_size. Uppercase Letter +O) pvs -o pv_name,pv_size,pv_free -O -pv_size <--(sort by pv_size. Uppercase Letter -O) pvs --units m <--(Megabytes) pvs --units G <--(Gigabytes)","title":"Adjust the PVS (Physical Volume Show) output:"},{"location":"lvm/#adjust-the-vgs-volume-groups-show-output","text":"vgs -o +pv_name <--(Shows the PV and the VG)","title":"Adjust the VGS (Volume Groups Show) output:"},{"location":"lvm/#after-i-created-the-logical-volume-on-ubuntu-i-formatted-them-using-ext4","text":"","title":"After I created the logical volume on Ubuntu I formatted them using ext4:"},{"location":"lvm/#i-found-the-format-path-by-typing-sudo-lvdisplay-which-showed-me-the-lv-path-below","text":"sudo mkfs.ext4 /dev/vg_data/lv_data1 sudo mkfs.ext4 /dev/vg_data/lv_data2","title":"I found the format path by typing \"sudo lvdisplay\" which showed me the LV path below:"},{"location":"lvm/#show-the-filesystem-type-and-other-df-information","text":"df -Th http://superuser.com/questions/116617/how-to-mount-an-lvm-volume Find the logical volume that has your Fedora root filesystem (mine proved to be LogVol00): $ sudo lvs Create a mount point for that volume: $ sudo mkdir /mnt/fcroot Mount it: $ sudo mount /dev/VolGroup00/LogVol00 /mnt/fcroot -o ro,user You're done, navigate to /mnt/fcroot and copy the files and paste somewhere else. I changed the permissions on the new volume so that anyone in the sambashare group could read/write to it. sudo chown -R root:sambashare /mnt/data1 sudo chmod o-rwx /mnt/data1 (remove access to anyone else). Make sure the group has access to the repository: sudo chgrp -R sambashare /mnt/data1 (-R set the group ownership recursively). sudo chmod g+rws /mnt/data1 (set the sticky bit so changes are owned by the group). sudo chmod o-rwx /mnt/data1 (remove access for \"other\" so only group members can clone). https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/High_Availability_Add-On_Administration/s1-LVMsetupnfs-HAAA.html Create the physical volume: sudo pvcreate /dev/sdb1 Create the volume group and add the physical volume to it: sudo vgcreate my_vg /dev/sdb1 Create 450MB logical volume in my_lv inside volume group my_vg: sudo lvcreate -L450 -n my_lv my_vg Show the logical volumes: sudo lvs Format the logical volume \"my_lv\" inside volume group \"my_vg\" with ext4 filesystem: sudo mkfs.ext4 /dev/my_vg/my_lv I have extended the root filesystem from 15GB to 500GB using lvextend, however I cannot use the extra space because the file system is still formatted for 15GB. I have to use: resize2fs /dev/fedora/root to increase the size but the file system has to be unmounted for me to run resize2fs. Ubuntu Link: https://help.ubuntu.com/community/UbuntuDesktopLVM Helpful HTTP Links: What mount points exist on a typical Linux system Increase the size of the logical volume UMount Resizing partitions using FDISK Logical Volume Manager - Deep Inside How to mount an LVM volume How to partition hard drive on CentOS Linux using fdisk Managing Storage with the Linux Logical Volume Manager (LVM) Increase the size of an EXT2, EXT3, EXT4 filesystem link link","title":"Show the filesystem type and other df information:"},{"location":"mac_apple/","text":"How do you disable a user account on a Mac? You can disable a user account by setting their shell to /usr/bin/false. Either run: chsh -s /usr/bin/false or change it in Users & Groups \u2192 Advanced Options. To change it back, run chsh -s /bin/bash . It doesn't apply to GUI logins? Another link: Link The answer is given here: With details on hiding given here: pwpolicy can both disable and enable users, without losing their password To disable the user pwpolicy -u username disableuser To enable the user pwpolicy -u username enableuser Use dscl to hide the user so they don't show on login: sudo dscl . create /Users/username IsHidden 1 To show a hidden user sudo dscl . create /Users/username IsHidden 0 More stuff to read here: Where to put custom executables on a Mac so they are globally visible: /usr/local/bin/","title":"MAC - Apple"},{"location":"mac_apple/#pwpolicy-can-both-disable-and-enable-users-without-losing-their-password","text":"To disable the user pwpolicy -u username disableuser To enable the user pwpolicy -u username enableuser Use dscl to hide the user so they don't show on login: sudo dscl . create /Users/username IsHidden 1 To show a hidden user sudo dscl . create /Users/username IsHidden 0 More stuff to read here: Where to put custom executables on a Mac so they are globally visible: /usr/local/bin/","title":"pwpolicy can both disable and enable users, without losing their password"},{"location":"markdown/","text":"Features Support Standard Markdown / CommonMark and GFM(GitHub Flavored Markdown); Full-featured: Real-time Preview, Image (cross-domain) upload, Preformatted text/Code blocks/Tables insert, Code fold, Search replace, Read only, Themes, Multi-languages, L18n, HTML entities, Code syntax highlighting...; Markdown Extras : Support ToC (Table of Contents), Emoji, Task lists, @Links...; Compatible with all major browsers (IE8+), compatible Zepto.js and iPad; Support identification, interpretation, fliter of the HTML tags; Support TeX (LaTeX expressions, Based on KaTeX), Flowchart and Sequence Diagram of Markdown extended syntax; Support AMD/CMD (Require.js & Sea.js) Module Loader, and Custom/define editor plugins; Editor.md Table of Contents [TOCM] Features Editor.md H1 header H2 header H3 header H4 header H5 header H6 header Heading 1 link Heading link Heading 2 link Heading link Heading 3 link Heading link Heading 4 link Heading link Heading link Heading link Heading 5 link Heading link Heading 6 link Heading link Headers (Underline) H1 Header (Underline) H2 Header (Underline) Characters Blockquotes Links Code Blocks (multi-language) & highlighting Inline code Code Blocks (Indented style) Javascript HTML code Images Lists Unordered list (-) Unordered list (*) Unordered list (plus sign and nested) Ordered list Tables HTML entities Escaping for Special Characters Markdown extras GFM task list Emoji mixed :smiley: GFM task lists & Emoji & fontAwesome icon emoji & editormd logo emoji :editormd-logo-5x: TeX(LaTeX) FlowChart Sequence Diagram H1 header H2 header H3 header H4 header H5 header H6 header Heading 1 link Heading link Heading 2 link Heading link Heading 3 link Heading link Heading 4 link Heading link Heading link Heading link Heading 5 link Heading link Heading 6 link Heading link Headers (Underline) H1 Header (Underline) H2 Header (Underline) Characters ~~Strikethrough~~ Strikethrough (when enable html tag decode.) Italic Italic Emphasis Emphasis Emphasis Italic Emphasis Italic Superscript: X 2 \uff0cSubscript: O 2 Abbreviation(link HTML abbr tag) The HTML specification is maintained by the W3C . Blockquotes Blockquotes Paragraphs and Line Breaks \"Blockquotes Blockquotes\", Link \u3002 Links Links Links with title <link> : https://github.com Reference link GFM a-tail link @pandao Code Blocks (multi-language) & highlighting Inline code $ npm install marked Code Blocks (Indented style) Indented 4 spaces, like <pre> (Preformatted Text). <?php echo \"Hello world!\"; ?> Code Blocks (Preformatted text): | First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell | Javascript function test(){ console.log(\"Hello world!\"); } (function(){ var box = function(){ return box.fn.init(); }; box.prototype = box.fn = { init : function(){ console.log('box.init()'); return this; }, add : function(str){ alert(\"add\", str); return this; }, remove : function(str){ alert(\"remove\", str); return this; } }; box.fn.init.prototype = box.fn; window.box =box; })(); var testBox = box(); testBox.add(\"jQuery\").remove(\"jQuery\"); HTML code <!DOCTYPE html> <html> <head> <mate charest=\"utf-8\" /> <title>Hello world!</title> </head> <body> <h1>Hello world!</h1> </body> </html> Images Image: Follow your heart. \u56fe\u4e3a\uff1a\u53a6\u95e8\u767d\u57ce\u6c99\u6ee9 Xiamen \u56fe\u7247\u52a0\u94fe\u63a5 (Image + Link)\uff1a \u56fe\u4e3a\uff1a\u674e\u5065\u9996\u5f20\u4e13\u8f91\u300a\u4f3c\u6c34\u6d41\u5e74\u300b\u5c01\u9762 Lists Unordered list (-) Item A Item B Item C Unordered list (*) Item A Item B Item C Unordered list (plus sign and nested) Item A Item B Item B 1 Item B 2 Item B 3 Item C Item C 1 Item C 2 Item C 3 Ordered list Item A Item B Item C Tables First Header Second Header Content Cell Content Cell Content Cell Content Cell First Header Second Header Content Cell Content Cell Content Cell Content Cell Function name Description help() Display the help window. destroy() Destroy your computer! Item Value Computer $1600 Phone $12 Pipe $1 Left-Aligned Center Aligned Right Aligned col 3 is some wordy text $1600 col 2 is centered $12 zebra stripes are neat $1 HTML entities \u00a9 & \u00a8 \u2122 \u00a1 \u00a3 & < > \u00a5 \u20ac \u00ae \u00b1 \u00b6 \u00a7 \u00a6 \u00af \u00ab \u00b7 X\u00b2 Y\u00b3 \u00be \u00bc \u00d7 \u00f7 \u00bb 18\u00baC \" ' Escaping for Special Characters *literal asterisks* Markdown extras GFM task list [x] GFM task list 1 [x] GFM task list 2 [ ] GFM task list 3 [ ] GFM task list 3-1 [ ] GFM task list 3-2 [ ] GFM task list 3-3 [ ] GFM task list 4 [ ] GFM task list 4-1 [ ] GFM task list 4-2 Emoji mixed :smiley: Blockquotes :star: GFM task lists & Emoji & fontAwesome icon emoji & editormd logo emoji :editormd-logo-5x: [x] :smiley: @mentions, :smiley: #refs, links , formatting , and tags supported :editormd-logo:; [x] list syntax required (any unordered or ordered list supported) :editormd-logo-3x:; [x] [ ] :smiley: this is a complete item :smiley:; [ ] []this is an incomplete item test link :fa-star: @pandao; [ ] [ ]this is an incomplete item :fa-star: :fa-gear:; [ ] :smiley: this is an incomplete item test link :fa-star: :fa-gear:; [ ] :smiley: this is :fa-star: :fa-gear: an incomplete item test link ; TeX(LaTeX) $$E=mc^2$$ Inline $$E=mc^2$$ Inline\uff0cInline $$E=mc^2$$ Inline\u3002 $$(\\sqrt{3x-1}+(1+x)^2)$$ $$\\sin(\\alpha)^{\\theta}=\\sum_{i=0}^{n}(x^i + \\cos(f))$$ FlowChart st=>start: Login op=>operation: Login operation cond=>condition: Successful Yes or No? e=>end: To admin st->op->cond cond(yes)->e cond(no)->op Sequence Diagram Andrew->China: Says Hello Note right of China: China thinks\\nabout it China-->Andrew: How are you? Andrew->>China: I am good thanks!","title":"Markdown"},{"location":"markdown/#features","text":"Support Standard Markdown / CommonMark and GFM(GitHub Flavored Markdown); Full-featured: Real-time Preview, Image (cross-domain) upload, Preformatted text/Code blocks/Tables insert, Code fold, Search replace, Read only, Themes, Multi-languages, L18n, HTML entities, Code syntax highlighting...; Markdown Extras : Support ToC (Table of Contents), Emoji, Task lists, @Links...; Compatible with all major browsers (IE8+), compatible Zepto.js and iPad; Support identification, interpretation, fliter of the HTML tags; Support TeX (LaTeX expressions, Based on KaTeX), Flowchart and Sequence Diagram of Markdown extended syntax; Support AMD/CMD (Require.js & Sea.js) Module Loader, and Custom/define editor plugins;","title":"Features"},{"location":"markdown/#editormd","text":"Table of Contents [TOCM] Features Editor.md H1 header H2 header H3 header H4 header H5 header H6 header Heading 1 link Heading link Heading 2 link Heading link Heading 3 link Heading link Heading 4 link Heading link Heading link Heading link Heading 5 link Heading link Heading 6 link Heading link Headers (Underline) H1 Header (Underline) H2 Header (Underline) Characters Blockquotes Links Code Blocks (multi-language) & highlighting Inline code Code Blocks (Indented style) Javascript HTML code Images Lists Unordered list (-) Unordered list (*) Unordered list (plus sign and nested) Ordered list Tables HTML entities Escaping for Special Characters Markdown extras GFM task list Emoji mixed :smiley: GFM task lists & Emoji & fontAwesome icon emoji & editormd logo emoji :editormd-logo-5x: TeX(LaTeX) FlowChart Sequence Diagram","title":"Editor.md"},{"location":"markdown/#h1-header","text":"","title":"H1 header"},{"location":"markdown/#h2-header","text":"","title":"H2 header"},{"location":"markdown/#h3-header","text":"","title":"H3 header"},{"location":"markdown/#h4-header","text":"","title":"H4 header"},{"location":"markdown/#h5-header","text":"","title":"H5 header"},{"location":"markdown/#h6-header","text":"","title":"H6 header"},{"location":"markdown/#heading-1-link-heading-link","text":"","title":"Heading 1 link Heading link"},{"location":"markdown/#heading-2-link-heading-link","text":"","title":"Heading 2 link Heading link"},{"location":"markdown/#heading-3-link-heading-link","text":"","title":"Heading 3 link Heading link"},{"location":"markdown/#heading-4-link-heading-link-heading-link-heading-link","text":"","title":"Heading 4 link Heading link Heading link Heading link"},{"location":"markdown/#heading-5-link-heading-link","text":"","title":"Heading 5 link Heading link"},{"location":"markdown/#heading-6-link-heading-link","text":"","title":"Heading 6 link Heading link"},{"location":"markdown/#headers-underline","text":"","title":"Headers (Underline)"},{"location":"markdown/#h1-header-underline","text":"","title":"H1 Header (Underline)"},{"location":"markdown/#h2-header-underline","text":"","title":"H2 Header (Underline)"},{"location":"markdown/#characters","text":"~~Strikethrough~~ Strikethrough (when enable html tag decode.) Italic Italic Emphasis Emphasis Emphasis Italic Emphasis Italic Superscript: X 2 \uff0cSubscript: O 2 Abbreviation(link HTML abbr tag) The HTML specification is maintained by the W3C .","title":"Characters"},{"location":"markdown/#blockquotes","text":"Blockquotes Paragraphs and Line Breaks \"Blockquotes Blockquotes\", Link \u3002","title":"Blockquotes"},{"location":"markdown/#links","text":"Links Links with title <link> : https://github.com Reference link GFM a-tail link @pandao","title":"Links"},{"location":"markdown/#code-blocks-multi-language-highlighting","text":"","title":"Code Blocks (multi-language) &amp; highlighting"},{"location":"markdown/#inline-code","text":"$ npm install marked","title":"Inline code"},{"location":"markdown/#code-blocks-indented-style","text":"Indented 4 spaces, like <pre> (Preformatted Text). <?php echo \"Hello world!\"; ?> Code Blocks (Preformatted text): | First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell |","title":"Code Blocks (Indented style)"},{"location":"markdown/#javascript","text":"function test(){ console.log(\"Hello world!\"); } (function(){ var box = function(){ return box.fn.init(); }; box.prototype = box.fn = { init : function(){ console.log('box.init()'); return this; }, add : function(str){ alert(\"add\", str); return this; }, remove : function(str){ alert(\"remove\", str); return this; } }; box.fn.init.prototype = box.fn; window.box =box; })(); var testBox = box(); testBox.add(\"jQuery\").remove(\"jQuery\");","title":"Javascript"},{"location":"markdown/#html-code","text":"<!DOCTYPE html> <html> <head> <mate charest=\"utf-8\" /> <title>Hello world!</title> </head> <body> <h1>Hello world!</h1> </body> </html>","title":"HTML code"},{"location":"markdown/#images","text":"Image: Follow your heart. \u56fe\u4e3a\uff1a\u53a6\u95e8\u767d\u57ce\u6c99\u6ee9 Xiamen \u56fe\u7247\u52a0\u94fe\u63a5 (Image + Link)\uff1a \u56fe\u4e3a\uff1a\u674e\u5065\u9996\u5f20\u4e13\u8f91\u300a\u4f3c\u6c34\u6d41\u5e74\u300b\u5c01\u9762","title":"Images"},{"location":"markdown/#lists","text":"","title":"Lists"},{"location":"markdown/#unordered-list-","text":"Item A Item B Item C","title":"Unordered list (-)"},{"location":"markdown/#unordered-list","text":"Item A Item B Item C","title":"Unordered list (*)"},{"location":"markdown/#unordered-list-plus-sign-and-nested","text":"Item A Item B Item B 1 Item B 2 Item B 3 Item C Item C 1 Item C 2 Item C 3","title":"Unordered list (plus sign and nested)"},{"location":"markdown/#ordered-list","text":"Item A Item B Item C","title":"Ordered list"},{"location":"markdown/#tables","text":"First Header Second Header Content Cell Content Cell Content Cell Content Cell First Header Second Header Content Cell Content Cell Content Cell Content Cell Function name Description help() Display the help window. destroy() Destroy your computer! Item Value Computer $1600 Phone $12 Pipe $1 Left-Aligned Center Aligned Right Aligned col 3 is some wordy text $1600 col 2 is centered $12 zebra stripes are neat $1","title":"Tables"},{"location":"markdown/#html-entities","text":"\u00a9 & \u00a8 \u2122 \u00a1 \u00a3 & < > \u00a5 \u20ac \u00ae \u00b1 \u00b6 \u00a7 \u00a6 \u00af \u00ab \u00b7 X\u00b2 Y\u00b3 \u00be \u00bc \u00d7 \u00f7 \u00bb 18\u00baC \" '","title":"HTML entities"},{"location":"markdown/#escaping-for-special-characters","text":"*literal asterisks*","title":"Escaping for Special Characters"},{"location":"markdown/#markdown-extras","text":"","title":"Markdown extras"},{"location":"markdown/#gfm-task-list","text":"[x] GFM task list 1 [x] GFM task list 2 [ ] GFM task list 3 [ ] GFM task list 3-1 [ ] GFM task list 3-2 [ ] GFM task list 3-3 [ ] GFM task list 4 [ ] GFM task list 4-1 [ ] GFM task list 4-2","title":"GFM task list"},{"location":"markdown/#emoji-mixed-smiley","text":"Blockquotes :star:","title":"Emoji mixed :smiley:"},{"location":"markdown/#gfm-task-lists-emoji-fontawesome-icon-emoji-editormd-logo-emoji-editormd-logo-5x","text":"[x] :smiley: @mentions, :smiley: #refs, links , formatting , and tags supported :editormd-logo:; [x] list syntax required (any unordered or ordered list supported) :editormd-logo-3x:; [x] [ ] :smiley: this is a complete item :smiley:; [ ] []this is an incomplete item test link :fa-star: @pandao; [ ] [ ]this is an incomplete item :fa-star: :fa-gear:; [ ] :smiley: this is an incomplete item test link :fa-star: :fa-gear:; [ ] :smiley: this is :fa-star: :fa-gear: an incomplete item test link ;","title":"GFM task lists &amp; Emoji &amp; fontAwesome icon emoji &amp; editormd logo emoji :editormd-logo-5x:"},{"location":"markdown/#texlatex","text":"$$E=mc^2$$ Inline $$E=mc^2$$ Inline\uff0cInline $$E=mc^2$$ Inline\u3002 $$(\\sqrt{3x-1}+(1+x)^2)$$ $$\\sin(\\alpha)^{\\theta}=\\sum_{i=0}^{n}(x^i + \\cos(f))$$","title":"TeX(LaTeX)"},{"location":"markdown/#flowchart","text":"st=>start: Login op=>operation: Login operation cond=>condition: Successful Yes or No? e=>end: To admin st->op->cond cond(yes)->e cond(no)->op","title":"FlowChart"},{"location":"markdown/#sequence-diagram","text":"Andrew->China: Says Hello Note right of China: China thinks\\nabout it China-->Andrew: How are you? Andrew->>China: I am good thanks!","title":"Sequence Diagram"},{"location":"ms_teams/","text":"Map the letter \"H:\" to your OneDrive: Create a script named \"MapH.cmd\" with the following content and place in the Startup Folder @echo off REM ---------------------------------------------------------------------------- REM Author: Robert Holland REM Name: MapH.cmd REM Creation Date: Thu Oct 14 2021 08:53:25 GMT-0700 (US Mountain Standard Time) REM Last Modified: REM Purpose: Locally Map H: drive to OneDrive REM ---------------------------------------------------------------------------- Change the \"OneDrive - Location\" part to your specific settings. subst H: \"C:\\Users\\%username%\\OneDrive - Location\\\"","title":"MS Teams"},{"location":"mysql/","text":"Terminology: Data Definition Language (DDL): DDL statements are used to define the database structure or schema. DDL (Data Definition Language) refers to the CREATE, ALTER and DROP statements DDL allows to add / modify / delete the logical structures which contain the data or which allow users to access / maintain the data (databases, tables, keys, views...). DDL is about \"metadata\". Some examples: CREATE - to create objects in the database ALTER - alters the structure of the database DROP - delete objects from the database TRUNCATE - remove all records from a table, including all spaces allocated for the records are removed. The operation cannot be rolled back. COMMENT - add comments to the data dictionary RENAME - rename an object Data Manipulation Language (DML): DML (Data Manipulation Language) refers to the INSERT, UPDATE and DELETE statements. DML statements are used for managing data within schema objects. DML allows to add / modify / delete data itself. Some examples: INSERT - insert data into a table UPDATE - updates existing data within a table DELETE - deletes all records from a table, the space for the records remain. Can be rolled back. Must me committed to make changes permanent. MERGE - UPSERT operation (insert or update) CALL - call a PL/SQL or Java subprogram EXPLAIN PLAN - explain access path to data LOCK TABLE - control concurrency DQL (Data Query Language): DQL refers to the SELECT, SHOW and HELP statements (queries) SELECT is the main DQL instruction. It retrieves data you need. SHOW retrieves information about the metadata. HELP ... is for people who need help. Some examples: SELECT - retrieve data from the a database Data Control Language (DCL): DCL (Data Control Language) refers to the GRANT and REVOKE statements DCL is used to grant / revoke permissions on databases and their contents. DCL is simple, but MySQL's permissions are rather complex. DCL is about security. Some examples: GRANT - gives user's access privileges to database REVOKE - withdraw access privileges given with the GRANT command Transaction Control (TCL): TCL statements are used to manage the changes made by DML statements. It allows statements to be grouped together into logical transactions. COMMIT - save work done SAVEPOINT - identify a point in a transaction to which you can later roll back ROLLBACK - restore database to original since the last COMMIT SET TRANSACTION - Change transaction options like isolation level and what rollback segment to use DTL (Data Transaction Language): DTL refers to the START TRANSACTION, SAVEPOINT, COMMIT and ROLLBACK [TO SAVEPOINT] statements. DTL is used to manage transactions (operations which include more instructions none of which can be executed if one of them fails). Note about DROP, TRUNCATE, and DELETE: DROP and TRUNCATE are DDL commands, whereas DELETE* is a DML command. Therefore DELETE operations can be rolled back (undone), while DROP** and TRUNCATE operations cannot be rolled back. MySQL Data Types: Properly defining the fields in a table is important to the overall optimization of your database. You should use only the type and size of field you really need to use; don't define a field as 10 characters wide if you know you're only going to use 2 characters. These types of fields (or columns) are also referred to as data types, after the type of data you will be storing in those fields. MySQL uses many different data types broken into three categories: numeric, date and time, and string types. - Numeric Data Types: MySQL uses all the standard ANSI SQL numeric data types, so if you're coming to MySQL from a different database system, these definitions will look familiar to you. The following list shows the common numeric data types and their descriptions: - INT - A normal-sized integer that can be signed or unsigned. If signed, the allowable range is from -2147483648 to 2147483647. If unsigned, the allowable range is from 0 to 4294967295. You can specify a width of up to 11 digits. - TINYINT - A very small integer that can be signed or unsigned. If signed, the allowable range is from -128 to 127. If unsigned, the allowable range is from 0 to 255. You can specify a width of up to 4 digits. - SMALLINT - A small integer that can be signed or unsigned. If signed, the allowable range is from -32768 to 32767. If unsigned, the allowable range is from 0 to 65535. You can specify a width of up to 5 digits. - MEDIUMINT - A medium-sized integer that can be signed or unsigned. If signed, the allowable range is from -8388608 to 8388607. If unsigned, the allowable range is from 0 to 16777215. You can specify a width of up to 9 digits. - BIGINT - A large integer that can be signed or unsigned. If signed, the allowable range is from -9223372036854775808 to 9223372036854775807. If unsigned, the allowable range is from 0 to 18446744073709551615. You can specify a width of up to 20 digits. - FLOAT(M,D) - A floating-point number that cannot be unsigned. You can define the display length (M) and the number of decimals (D). This is not required and will default to 10,2, where 2 is the number of decimals and 10 is the total number of digits (including decimals). Decimal precision can go to 24 places for a FLOAT. - DOUBLE(M,D) - A double precision floating-point number that cannot be unsigned. You can define the display length (M) and the number of decimals (D). This is not required and will default to 16,4, where 4 is the number of decimals. Decimal precision can go to 53 places for a DOUBLE. REAL is a synonym for DOUBLE. - DECIMAL(M,D) - An unpacked floating-point number that cannot be unsigned. In unpacked decimals, each decimal corresponds to one byte. Defining the display length (M) and the number of decimals (D) is required. NUMERIC is a synonym for DECIMAL. - Date and Time Types: The MySQL date and time datatypes are: - DATE - A date in YYYY-MM-DD format, between 1000-01-01 and 9999-12-31. For example, December 30th, 1973 would be stored as 1973-12-30. - DATETIME - A date and time combination in YYYY-MM-DD HH:MM:SS format, between 1000-01-01 00:00:00 and 9999-12-31 23:59:59. For example, 3:30 in the afternoon on December 30th, 1973 would be stored as 1973-12-30 15:30:00. - TIMESTAMP - A timestamp between midnight, January 1, 1970 and sometime in 2037. This looks like the previous DATETIME format, only without the hyphens between numbers; 3:30 in the afternoon on December 30th, 1973 would be stored as 19731230153000 ( YYYYMMDDHHMMSS ). - TIME - Stores the time in HH:MM:SS format. - YEAR(M) - Stores a year in 2-digit or 4-digit format. If the length is specified as 2 (for example YEAR(2)), YEAR can be 1970 to 2069 (70 to 69). If the length is specified as 4, YEAR can be 1901 to 2155. The default length is 4. - String Types: Although numeric and date types are fun, most data you'll store will be in string format. This list describes the common string datatypes in MySQL. - CHAR(M) - A fixed-length string between 1 and 255 characters in length (for example CHAR(5)), right-padded with spaces to the specified length when stored. Defining a length is not required, but the default is 1. - VARCHAR(M) - A variable-length string between 1 and 255 characters in length; for example VARCHAR(25). You must define a length when creating a VARCHAR field. - BLOB or TEXT - A field with a maximum length of 65535 characters. BLOBs are \"Binary Large Objects\" and are used to store large amounts of binary data, such as images or other types of files. Fields defined as TEXT also hold large amounts of data; the difference between the two is that sorts and comparisons on stored data are case sensitive on BLOBs and are not case sensitive in TEXT fields. You do not specify a length with BLOB or TEXT. - TINYBLOB or TINYTEXT - A BLOB or TEXT column with a maximum length of 255 characters. You do not specify a length with TINYBLOB or TINYTEXT. - MEDIUMBLOB or MEDIUMTEXT - A BLOB or TEXT column with a maximum length of 16777215 characters. You do not specify a length with MEDIUMBLOB or MEDIUMTEXT. - LONGBLOB or LONGTEXT - A BLOB or TEXT column with a maximum length of 4294967295 characters. You do not specify a length with LONGBLOB or LONGTEXT. - ENUM - An enumeration, which is a fancy term for list. When defining an ENUM, you are creating a list of items from which the value must be selected (or it can be NULL). For example, if you wanted your field to contain \"A\" or \"B\" or \"C\", you would define your ENUM as ENUM ('A', 'B', 'C') and only those values (or NULL) could ever populate that field. Source: http://www.tutorialspoint.com/mysql/mysql-data-types.htm Alter Table: Alter Table Column (CHANGE and MODIFY): CHANGE allows you to rename a column and change the definition. MODIFY allows you to change the definition (cannot rename). Rename a table column named tasklist to entry: ALTER TABLE tablename CHANGE tasklist entry MEDIUMTEXT NOT NULL; Alter the column definition: alter table tablename modify column1 timestamp not null default current_timestamp on update current_timestamp; Alter the table field type and comment: ALTER TABLE `weapons` CHANGE `active_ind` `active_ind` TINYINT( 1 ) UNSIGNED NOT NULL DEFAULT '0' COMMENT '1 Disposed, 0 Not Disposed'; Alter Table (Add): Adding columns to a table. Adding a single colum to a table: ALTER TABLE tablename add column columnname varchar(100) not null after id; Making a column unique: ALTER TABLE tablename add unique (column1); Giving the unique index a name: ALTER TABLE tablename add unique idx_uniquename (column1); Multi-column unique index with a name: Source: https://stackoverflow.com/questions/635937/how-do-i-specify-unique-constraint-for-multiple-columns-in-mysql ALTER TABLE `tablename` add unique `idx_unique_index_name`(`column1`, `column2`, `column3`); Alter Table (Move a column): ``` ALTER TABLE `tablename` CHANGE `columnname` `columname` INT(11) NOT NULL AFTER `someothercolumnname`; ``` - Example: Move the lastname column after the firstname column in the customers table. ``` ALTER TABLE `customers` CHANGE `lastname` `lastname` INT(11) NOT NULL AFTER `firstname`; ``` Create a unique index with a name and a comment (MySQL v8): Try to use idx for beginning of index name. Syntax: Create unique index: CREATE UNIQUE INDEX `idx_videos_videoname` ON `videos`.`videos` (videoname) COMMENT 'Unique videoname' ALGORITHM DEFAULT LOCK DEFAULT ** You might get ERROR 1062 Duplicate entry '' for key ??? if the column you are trying to make unique, already has duplicate data. This includes NULL and spaces. ** Removing the unique index. Syntax: Notice the missing parenthesis: ALTER TABLE tablename drop index column1; Remove the primary key: Without an index, maintaining an autoincrement column becomes too expensive, that's why MySQL requires an autoincrement column to be a leftmost part of an index. Syntax: You should remove the autoincrement property before dropping the key: ALTER TABLE tablename MODIFY id INT NOT NULL; -- Removing autoincrement. ALTER TABLE tablename DROP PRIMARY KEY; Set field value to default to nothing instead of NULL: alter table customers modify address2 varchar(100) null default \"\"; Rename a MySQL table: The \"to\" keyword is part of the command. Syntax: rename table oldtable to newtable; Rename a Database: For InnoDB, the following seems to work: create the new empty database, then rename each table and turn into the new database: Syntax: RENAME TABLE old_db.table TO new_db.table; You will need to adjust the permissions after that. For scripting in a shell, you can use either of the following: This: mysql -u username -ppassword old_db -sNe 'show tables' | while read table; \\ do mysql -u username -ppassword -sNe \"rename table old_db.$table to new_db.$table\"; done Or: for table in `mysql -u root -s -N -e \"show tables from old_db\"\\`; do mysql -u root -s -N -e \"rename table old_db.$table to new_db.$table\"; done;` Note: there is no space between the option -p and the password. If your database user has no password, remove the -u username -ppassword part. If you have stored procedures, you can copy them afterward: Alter User: Change Password / Lock and Unlock Accounts: use mysql; -- Method 1 (Deprecated): update mysql.user set password(\"thepassword123\") where user = 'hillc'; FLUSH PRIVILEGES; -- Method 2 (MySQL 5.7+): update mysql.user set authentication_string=PASSWORD(\"thepassword123\") where user='hillc'; FLUSH PRIVILEGES; -- Method 3 (Preferred method for current user.): alter user set password = \"thepassword123\"; FLUSH PRIVILEGES; -- MySQL 5.7: alter user 'hillc'@'localhost' identified by \"thepassword123\"; alter user 'hillc'@'%' identified by \"thepassword123\"; -- Method 4 (Preferred method for another user.): alter user set password for 'hillc'@'localhost' = \"thepassword123\"; FLUSH PRIVILEGES; -- Remote user password change: alter user set password for 'hillc'@'%' = \"thepassword123\"; FLUSH PRIVILEGES; -- ALTER USER == ERROR 1820 (HY000): You must reset your password using ALTER USER statement before executing this statement. --If you started MySQL using \"mysql -u root -p\" use this method to reset your password: ALTER USER 'root'@'localhost' IDENTIFIED BY 'Your New Password'; -- This worked for me from the MySQL DB prompt: SET PASSWORD = PASSWORD(\"your_new_password\"); -- Source: http://stackoverflow.com/questions/33467337/reset-mysql-root-password-using-alter-user-statement-after-install-on-mac -- This syntax enables changing your own password without naming your account literally. ALTER USER USER() IDENTIFIED BY \"auth_string\"; -- This statement changes the password for jeffrey but leaves that for jeanne unchanged. For both accounts, connections are required to use SSL and -- each account can be used for a maximum of two simultaneous connections: ALTER USER 'jeffrey'@'localhost' IDENTIFIED BY \"new_password\", 'jeanne'@'localhost' REQUIRE SSL WITH MAX_USER_CONNECTIONS 2; -- Example 1: Change an account's password and expire it. As a result, the user must connect with the named password and choose a new one at the next connection: ALTER USER 'jeffrey'@'localhost' IDENTIFIED BY \"new_password\" PASSWORD EXPIRE; -- Example 2: Modify an account to use the sha256_password authentication plugin and the given password. Require that a new password be chosen every 180 days: ALTER USER 'jeffrey'@'localhost' IDENTIFIED WITH sha256_password BY \"new_password\" (SHA256 may require an SSL connection on some systems) PASSWORD EXPIRE INTERVAL 180 DAY; -- Example 3: Lock or unlock an account: ALTER USER 'jeffrey'@'localhost' ACCOUNT LOCK; ALTER USER 'jeffrey'@'localhost' ACCOUNT UNLOCK; -- Example 4: Require an account to connect using SSL and establish a limit of 20 connections per hour: ALTER USER 'jeffrey'@'localhost' REQUIRE SSL WITH MAX_CONNECTIONS_PER_HOUR 20; -- http://dev.mysql.com/doc/refman/5.7/en/alter-user.html -- Lock User Account on MySQL 8.0.x.x.: UPDATE `user` SET `account_locked` = 'Y' WHERE `user`.`Host` = 'localhost' AND `user`.`User` = 'robdba5'; -- Solution for - Connect Error: SQLSTATE[HY000] [2054] The server requested authentication method unknown to the client. -- Change the authentication method from auth_socket to mysql_native_password: ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY \"password\"; -- Switch to caching_sha2_password authentication for MySQL 8 upgrades: ALTER USER 'umptyfratz'@'%' IDENTIFIED WITH caching_sha2_password BY \"password\"; ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY \"password\"; Show create user: show create user billybob@localhost; Blob (text) data display using convert(FIELD using utf8mb4): -- I used this in my bacula database to find jobs that contained the file groupmems. SELECT DISTINCT Job.JobId as JobId, convert(Client.Name using utf8mb4) as Client, convert(Path.Path using utf8mb4),convert(File.FileName using utf8mb4),StartTime,Level,JobFiles,JobBytes FROM Client,Job,File,Path WHERE Client.ClientId=Job.ClientId AND JobStatus IN ('T','W') AND Job.JobId=File.JobId AND Path.PathId=File.PathId AND convert(File.FileName using utf8mb4) = 'groupmems' AND File.FileIndex > 0 -- AND Job.JobId = 16 ORDER BY Job.StartTime; CHAR_LENGTH: Needed to find out the maximum length of each column so that I could dynamically adjust the column width in PDF output. This shows the maximum length of the manufacturer_importer column. select inventory_number, manufacturer_importer, max(char_length(`manufacturer_importer`)) Number_of_Characters from vw_ffl_book2 group by manufacturer_importer, inventory_number order by Number_of_Characters desc; This shows me the maximum length of the model column from highest to lowest. select model, max(char_length(`model`)) Number_of_Characters from vw_ffl_book2 group by model order by Number_of_Characters desc; Concatinate: This is a query that I used to sequentially rename some video files so they would be in the correct order. I accidentally numbered them 1 to 32 and they were in alphabetical order instead of chronological order. I had to renumber them so they would be in chronolocial order: I used the concat and substring_index functions: select concat('mv ',oldname,' ',newnum,'.',substring_index(oldname,'.',-2)) as Rename_Script from v_rename; Concatenate multiple MySQL rows into one field? You can use GROUP_CONCAT: SELECT person_id, GROUP_CONCAT(hobbies SEPARATOR ', ') FROM peoples_hobbies GROUP BY person_id; As Ludwig stated in his comment, you can add the DISTINCT operator to avoid duplicates: SELECT person_id, GROUP_CONCAT(DISTINCT hobbies SEPARATOR ', ') FROM peoples_hobbies GROUP BY person_id; As Jan stated in their comment, you can also sort the values before imploding it using ORDER BY: SELECT person_id, GROUP_CONCAT(hobbies ORDER BY hobbies ASC SEPARATOR ', ') FROM peoples_hobbies GROUP BY person_id; As Dag stated in his comment, there is a 1024 byte limit on the result. To solve this, run this query before your query: SET group_concat_max_len = 2048; Of course, you can change 2048 according to your needs. To calculate and assign the value: SET group_concat_max_len = CAST( (SELECT SUM(LENGTH(hobbies)) + COUNT(*) * LENGTH(', ') FROM peoples_hobbies GROUP BY person_id) AS UNSIGNED ); Source: https://stackoverflow.com/questions/276927/can-i-concatenate-multiple-mysql-rows-into-one-field?rq=1 Conditional Update: create table test ( id int not null auto_increment primary key, name varchar(50), age tinyint ) engine = myisam; insert into test (name) values (\"jim\"),(\"john\"),(\"paul\"),(\"mike\"); - The age field is now NULL. select * from test; update test set age = case when name = \"jim\" then 10 when name = \"paul\" then 20 else 30 end; - The age field now has data. select * from test; Create a Stored Procedure: Create a stored procedure that inserts 10 rows DELIMITER $$ DROP PROCEDURE IF EXISTS insert_ten_rows $$ CREATE PROCEDURE insert_ten_rows () BEGIN DECLARE crs INT DEFAULT 0; WHILE crs < 10 DO INSERT INTO `continent`(`name`) VALUES ('count_'+crs); SET crs = crs + 1; END WHILE; END $$ DELIMITER ;Invoke the procedure: CALL insert_ten_rows(); Create Users: Syntax definitions: % = remote user localhost = local user on server/computer This is my MySQL Create User Statement: CREATE USER 'monty'@'localhost' IDENTIFIED BY 'some_pass'; -- ALTER USER 'theusername'@'localhost' IDENTIFIED BY 'some_pass'; GRANT ALL PRIVILEGES ON *.* TO 'monty'@'localhost' WITH GRANT OPTION; CREATE USER 'monty'@'%' IDENTIFIED BY 'some_pass'; GRANT ALL PRIVILEGES ON *.* TO 'monty'@'%' WITH GRANT OPTION; This is my MariaDB Create User and MySQL Create User Statement. CREATE USER 'SomeUser'@'%'; CREATE USER 'SomeUser'@'localhost'; SET PASSWORD FOR 'SomeUser'@'%' = PASSWORD('SomePassword!'); SET PASSWORD FOR 'SomeUser'@'localhost' = PASSWORD('SomePassword!'); GRANT USAGE ON SomeDatabase.* TO 'SomeUser'@'localhost' GRANT USAGE ON SomeDatabase.* TO 'SomeUser'@'%' REQUIRE NONE WITH MAX_QUERIES_PER_HOUR 0 MAX_CONNECTIONS_PER_HOUR 0 MAX_UPDATES_PER_HOUR 0 MAX_USER_CONNECTIONS 0; GRANT ALL PRIVILEGES ON `SomeDatabase`.* TO 'SomeUser'@'localhost'; GRANT ALL PRIVILEGES ON `SomeDatabase\\_%`.* TO 'SomeUser'@'%'; FLUSH PRIVILEGES; On MariaDB: I got an access denied error when I tried to run the following statement as root. UPDATE mysql.user SET Grant_priv='Y', Super_priv='Y' WHERE User='rob'; FLUSH PRIVILEGES; I had to run the following as root to give myself the \"GRANT\" privilege. (https://stackoverflow.com/questions/8484722/access-denied-for-user-rootlocalhost-while-attempting-to-grant-privileges) Note that we use `%`.* instead of *.* <-- The backticks are needed. Website example: GRANT ALL PRIVILEGES ON `%`.* TO '[user]'@'[hostname]' IDENTIFIED BY '[password]' WITH GRANT OPTION; I ran it without the password section because I already have an established password: GRANT ALL PRIVILEGES ON `%`.* TO 'rob'@'localhost' WITH GRANT OPTION; GRANT ALL PRIVILEGES ON *.* TO 'rob'@'%' WITH GRANT OPTION; MySQL 8.0.X.X. Create user with mysql_native_password authentication; CREATE USER username@localhost identified with mysql_native_password by 'password'; VPS on Godaddy; CREATE USER 'theusername'@'localhost'; ALTER USER 'theusername'@'localhost' IDENTIFIED BY 'thePa55word!' -- MySQL GRANT USAGE ON thedatabase.* TO 'theusername'@'localhost'; GRANT ALL PRIVILEGES ON `thedatabase`.* TO 'theusername'@'localhost'; GRANT ALL PRIVILEGES ON `thedatabase\\_%`.* TO 'theusername'@'localhost'; Datatypes Example: --Create a table with all of the MySQL datatypes. CREATE TABLE`all_data_types` ( `bigint` BIGINT, `binary` BINARY( 20 ), `blob` BLOB, `bool` BOOL, `char` CHAR( 10 ), `date` DATE, `datetime` DATETIME, `decimal` DECIMAL( 10, 2 ), `double` DOUBLE, `enum` ENUM( '1', '2', '3' ), `float` FLOAT( 10, 2 ), `int` INT, `longblob` LONGBLOB, `longtext` LONGTEXT, `mediumblob` MEDIUMBLOB, `mediumint` MEDIUMINT, `mediumtext` MEDIUMTEXT, `set` SET( '1', '2', '3' ), `smallint` SMALLINT, `text` TEXT, `timestamp` TIMESTAMP, `time` TIME, `tinyblob` TINYBLOB, `tinyint` TINYINT, `tinytext` TINYTEXT, `varbinary` VARBINARY( 20 ), `varchar` VARCHAR( 20 ), `year` YEAR ) ENGINE= innodb ; Date fields: MySQL Reference Manual - Date Time Functions Date Add: mysql> SELECT DATE_ADD('2018-05-01',INTERVAL 1 DAY); -> '2018-05-02' mysql> SELECT DATE_SUB('2018-05-01',INTERVAL 1 YEAR); -> '2017-05-01' mysql> SELECT DATE_ADD('2020-12-31 23:59:59', -> INTERVAL 1 SECOND); -> '2021-01-01 00:00:00' mysql> SELECT DATE_ADD('2018-12-31 23:59:59', -> INTERVAL 1 DAY); -> '2019-01-01 23:59:59' mysql> SELECT DATE_ADD('2100-12-31 23:59:59', -> INTERVAL '1:1' MINUTE_SECOND); -> '2101-01-01 00:01:00' mysql> SELECT DATE_SUB('2025-01-01 00:00:00', -> INTERVAL '1 1:1:1' DAY_SECOND); -> '2024-12-30 22:58:59' mysql> SELECT DATE_ADD('1900-01-01 00:00:00', -> INTERVAL '-1 10' DAY_HOUR); -> '1899-12-30 14:00:00' mysql> SELECT DATE_SUB('1998-01-02', INTERVAL 31 DAY); -> '1997-12-02' mysql> SELECT DATE_ADD('1992-12-31 23:59:59.000002', -> INTERVAL '1.999999' SECOND_MICROSECOND); -> '1993-01-01 00:00:01.000001' Date Difference: mysql> SELECT DATEDIFF('2007-12-31 23:59:59','2007-12-30'); -> 1 mysql> SELECT DATEDIFF('2010-11-30 23:59:59','2010-12-31'); -> -31 select year(date_field) as year from table; Difference between DATETIME and TIMESTAMP: --The timestamp data type has a limitation between the years 1970 and 2038. --Use datetime instead. If you need a timestamp you can set the default to current_timestamp. --See the updt_dt_tm and cr_date fields in the table below. CREATE TABLE `test1` ( `id` int(11) NOT NULL AUTO_INCREMENT, `firstname` varchar(100) NOT NULL, `lastname` varchar(100) NOT NULL, `updt_dt_tm` datetime DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP, `cr_date` datetime DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=latin1; --Date Format: http://www.mysqltutorial.org/mysql-date/ -- Alter table and add a datetime column that defaults to the current timestamp. alter table code_value add column updt_dt_tm datetime not null default current_timestamp on update current_timestamp; DEFINER Change: Change/Update DEFINER: 1. Change the DEFINER This is possibly easiest to do when initially importing your database objects, by removing any DEFINER statements from the dump. Changing the definer later is a little more tricky: How to change the definer for views Run this SQL to generate the necessary ALTER statements SELECT CONCAT(\"ALTER DEFINER=`youruser`@`host` VIEW \", table_name, \" AS \", view_definition, \";\") FROM information_schema.views WHERE table_schema='your-database-name'; Copy and run the ALTER statements How to change the definer for stored procedures Example: UPDATE `mysql`.`proc` p SET definer = 'user@%' WHERE definer='root@%' Be careful, because this will change all the definers for all databases. 2. Create the missing user If you've found following error while using MySQL database: The user specified as a definer ('someuser'@'%') does not exist` Then you can solve it by using following : GRANT ALL ON *.* TO 'someuser'@'%' IDENTIFIED BY 'complex-password'; FLUSH PRIVILEGES; From http://www.lynnnayko.com/2010/07/mysql-user-specified-as-definer-root.html This worked like a charm - you only have to change someuser to the name of the missing user. On a local dev server, you might typically just use root. Also consider whether you actually need to grant the user ALL permissions or whether they could do with less. ******************** select concat(\"ALTER DEFINER=`rlholland1`@`localhost` VIEW \", weapons, \" AS \" , view_definition, \";\") FROM information_schema.views where table_schema=\"hillc1\"; DROP Drop a database: drop database `TheDataBaseName`; Drop a table; drop table `TheTablename`; Drop an index: alter TheTableName drop `TheIndexName`; ** In MySQL, there\u001as no DROP CONSTRAINT, you have to use DROP FOREIGN KEY instead: ALTER TABLE `table_name` DROP FOREIGN KEY `id_name_fk`; You might have to drop the index too because simply removing the foreign key does not remove the index. ALTER TABLE `table_name` DROP INDEX `id_name_fk`; An alternative to temporarily disable all the foreign keys: SET FOREIGN_KEY_CHECKS=0; When you need to turn it on: SET FOREIGN_KEY_CHECKS=1; Dump a Database: Dump and rename: mysqldump -R old_db | mysql new_db or just dump the database and import the file into a new database name: mysqldump -p -c -e TheNameOfTheDatabase > The_Name_of_the_Dump.sql To import from the MySQL command prompt type: source The_Name_of_the_Dump.sql or \\. The_Name_of_the_Dump.sql Dump a Table: mysqldump -p -c -e TheNameOfTheDatabase TheNameOfTheTable > The_Name_of_the_Dump.sql Dump a single Database: mysqldump -p -c -e TheNameOfTheDatabase > The_Name_of_the_Dump.sql Dump All Databases on the Server to a file: mysqldump -p -c -e --all-databases > The_Name_of_the_Dump.sql Backup shell script to create a timestamped database dump: Script Name: dbdump.sh DBuser=SomeUser DBname=SomeDatabase TimeStamp=`date +\"%Y%m%d%H%M%S%Z\"` mysqldump -u$SomeUser -p -c -e $DBname > $TimeStamp.DBDump.$DBname.`hostname`.sql echo \"Compressing Database Dump. Please wait...\" tar -zcvf $TimeStamp.DBDump.$DBname.`hostname`.sql.gz $TimeStamp.DBDump.$DBname.`hostname`.sql Duplicate Data: Find duplicate data in a column. SELECT column1, COUNT(*) c FROM tablename GROUP BY column1 HAVING c > 1; Enable remote connections for a specific IP address: Create a database, create database user, and enable remote connections for that user from a specific IP address. -- Example: /* DB_NAME = webdb USER_NAME = webdb_user REMOTE_IP = 10.0.15.25 PASSWORD = password123 PERMISSIONS = ALL */ -- CREATE DATABASE ## -- MariaDB [(none)]> CREATE DATABASE webdb; -- CREATE USER ## -- MariaDB [(none)]> CREATE USER 'webdb_user'@'10.0.15.25' IDENTIFIED BY 'password123'; -- GRANT PERMISSIONS ## -- MariaDB [(none)]> GRANT ALL ON webdb.* TO 'webdb_user'@'10.0.15.25'; -- FLUSH PRIVILEGES, Tell the server to reload the grant tables ## -- MariaDB [(none)]> FLUSH PRIVILEGES; ENUM: Definition: ENUM is a good choice for boolean type of fields except that it is treated as a string and not an integer. In this case I just want to set a column in the table to indicate whether the row is active (1) or not (0). I do not want someone to accidentally enter a 2, 3, etc. in the field. Source: http://komlenic.com/244/8-reasons-why-mysqls-enum-data-type-is-evil/ alter table healthtemperature1 add column active_ind enum('0','1') not null; Event: Creating Events: http://stackoverflow.com/questions/10314806/mysql-triggers-deleting-a-row-after-inactivity First, do not put this update/delete in a trigger, you are going to see a huge performance hit if there are millions of rows. Instead, you can create a cron job or if you want to keep it all in MySQL use the MySQL Event scheduler. Go to this page to read more about scheduling events in MySQL: http://dev.mysql.com/doc/refman/5.1/en/events.html MySQL Event allows you to schedule things on MySQL on a regular basis. The code would look something like: CREATE EVENT myevent ON SCHEDULE AT CURRENT_TIMESTAMP + INTERVAL 1 HOUR DO DELETE FROM MyTable Where Expired< NOW(); Example updates the state column to 1 if it is older than 24 hours. Check a table every hour and update a column that is 24 hours old: CREATE EVENT reset ON SCHEDULE EVERY 1 HOUR DO update T1 set state=1 where time < date_sub(now(),interval 24 hour) and (state=0 or state=2) ; CREATE EVENT reset ON SCHEDULE EVERY 1 HOUR DO update test set state=1 where time < date_sub(now(),interval 24 hour) and (state=0 or state=2); Create Event Source: https://dba.stackexchange.com/questions/56424/column-auto-updated-after-24-hours-in-mysql Foreign Keys: Add foreign key constraint: alter table TableName add constraint TheConstraintName foreign key (CurrentTableColumnName) references ForeignTable(ColumnName) on update cascade on delete restrict; *If you do not give the constraint a name, then one will be automatically generated. *Sometimes you will see a message \"Check DataType\" if the two columns are not exactly the same or there is a duplicate constraint name. Casecade only works if foreign_key_checks is ON. To see this information type: show variables like 'foreign_key_checks'; If you want to see all variables type: show variables; Display Foreign Key References: -- To run from the command prompt type: -- mysql -u rob -p < display_foreign_key_references.sql > current_fk_refs.txt # Show constraints for all databases on the server: use INFORMATION_SCHEMA; select concat(`kcu`.`TABLE_SCHEMA`,'.',`kcu`.`TABLE_NAME`,'.',`kcu`.`COLUMN_NAME`) AS `This_DB_Table_and_Column` ,concat(`kcu`.`TABLE_SCHEMA`,'.',`kcu`.`REFERENCED_TABLE_NAME`,'.',`kcu`.`REFERENCED_COLUMN_NAME`) AS `References_This_DB_Table_and_Column` ,`kcu`.`CONSTRAINT_NAME` AS `CONSTRAINT_NAME` ,`rc`.`UPDATE_RULE` AS `update_rule` ,`rc`.`DELETE_RULE` AS `delete_rule` from (`information_schema`.`KEY_COLUMN_USAGE` `kcu` join `information_schema`.`referential_constraints` `rc` on(`kcu`.`TABLE_NAME` = `rc`.`TABLE_NAME`)) where `kcu`.`REFERENCED_TABLE_NAME` is not null order by concat(`kcu`.`TABLE_SCHEMA`,'.',`kcu`.`TABLE_NAME`,'.',`kcu`.`COLUMN_NAME`); # Show constraints for specific database: use INFORMATION_SCHEMA; select distinct concat(`kcu`.`TABLE_SCHEMA`,'.',`kcu`.`TABLE_NAME`,'.',`kcu`.`COLUMN_NAME`) AS `This_DB_Table_and_column` ,concat(`kcu`.`TABLE_SCHEMA`,'.',`kcu`.`REFERENCED_TABLE_NAME`,'.',`kcu`.`REFERENCED_COLUMN_NAME`) AS `References_This_DB_Table_and_Column` ,`kcu`.`CONSTRAINT_NAME` AS `constraint_name` ,`rc`.`UPDATE_RULE` AS `update_rule` ,`rc`.`DELETE_RULE` AS `delete_rule` from (`information_schema`.`KEY_COLUMN_USAGE` `kcu` join `information_schema`.`REFERENTIAL_CONSTRAINTS` `rc` on(`kcu`.`TABLE_NAME` = `rc`.`TABLE_NAME`)) where `kcu`.`REFERENCED_TABLE_NAME` is not null and `kcu`.`TABLE_SCHEMA` = 'YOURDATABASENAME' order by This_DB_Table_and_column; # Show constraints for all databases: create VIEW `vw_fk_global_constraints` AS select distinct concat(`kcu`.`TABLE_SCHEMA`,'.',`kcu`.`TABLE_NAME`,'.',`kcu`.`COLUMN_NAME`) AS `This_DB_Table_and_Column` ,concat(`kcu`.`TABLE_SCHEMA`,'.',`kcu`.`REFERENCED_TABLE_NAME`,'.',`kcu`.`REFERENCED_COLUMN_NAME`) AS `References_This_DB_Table_and_Column` ,`kcu`.`CONSTRAINT_NAME` AS `CONSTRAINT_NAME` ,`rc`.`UPDATE_RULE` AS `update_rule` ,`rc`.`DELETE_RULE` AS `delete_rule` from ( `information_schema`.`KEY_COLUMN_USAGE` `kcu` join `information_schema`.`referential_constraints` `rc` on(`kcu`.`TABLE_NAME` = `rc`.`TABLE_NAME`)) where `kcu`.`REFERENCED_TABLE_NAME` is not null order by concat(`kcu`.`TABLE_SCHEMA`,'.',`kcu`.`TABLE_NAME`,'.',`kcu`.`COLUMN_NAME` ); -- This is a quick way to view all of the constraints: SELECT * FROM information_schema.REFERENTIAL_CONSTRAINTS; -- This is a quick way to view constraints from a specific database: select * from information_schema.referential_constraints where constraint_schema = 'thedatabasename'; Source: https://www.youtube.com/watch?v=UQK9_gKQHZg Generated Columns The syntax for defining a generated column is as follows: column_name data_type [GENERATED ALWAYS] AS (expression) [VIRTUAL | STORED] [UNIQUE [KEY]] First, specify the column name and its data type. Next, add the GENERATED ALWAYS clause to indicate that the column is a generated column. Then, indicate whether the type of the generated column by using the corresponding option: VIRTUAL or STORED. By default, MySQL uses VIRTUAL if you don\u001at specify explicitly the type of the generated column. After that, specify the expression within the braces after the AS keyword. The expression can contain literals, built-in functions with no parameters, operators, or references to any column within the same table. If you use a function, it must be scalar and deterministic. Finally, if the generated column is stored, you can define a unique constraint for it. Generated column: Columns are generated because the data in these columns are computed based on predefined expressions. Basically, the columns are generated on the fly based on the data that already exists in the table. Virtual Column: The \"fullname\" column is Virtual by default because the generated column type was not specified. DROP TABLE IF EXISTS contacts; CREATE TABLE contacts ( id INT AUTO_INCREMENT PRIMARY KEY, first_name VARCHAR(50) NOT NULL, last_name VARCHAR(50) NOT NULL, fullname varchar(101) GENERATED ALWAYS AS (CONCAT(first_name,' ',last_name)), email VARCHAR(100) NOT NULL ); MySQL provides two types of generated columns: stored and virtual. The virtual columns are calculated on the fly each time data is read whereas the stored column are calculated and stored physically when the data is updated. Based on this definition, the fullname column in the example above is a virtual column. Stored Column: (If the generated column is stored, you can define a unique constraint for it.) ALTER TABLE products ADD COLUMN stockValue DOUBLE GENERATED ALWAYS AS (buyprice*quantityinstock) STORED; Grant: Grant privileges. grant all on *.* to 'rob'@'localhost'; show grants for 'root'@'localhost'; show grants for 'rob'@'localhost'; MySQL 8.0.X.X. Grant superuser privileges: use mysql; UPDATE `user` SET `Select_priv` = 'Y', `Insert_priv` = 'Y', `Update_priv` = 'Y', `Delete_priv` = 'Y', `Create_priv` = 'Y', `Drop_priv` = 'Y', `Reload_priv` = 'Y', `Shutdown_priv` = 'Y', `Process_priv` = 'Y', `File_priv` = 'Y', `Grant_priv` = 'Y', `References_priv` = 'Y', `Index_priv` = 'Y', `Alter_priv` = 'Y', `Show_db_priv` = 'Y', `Super_priv` = 'Y', `Create_tmp_table_priv` = 'Y', `Lock_tables_priv` = 'Y', `Execute_priv` = 'Y', `Repl_slave_priv` = 'Y', `Repl_client_priv` = 'Y', `Create_view_priv` = 'Y', `Show_view_priv` = 'Y', `Create_routine_priv` = 'Y', `Alter_routine_priv` = 'Y', `Create_user_priv` = 'Y', `Event_priv` = 'Y', `Trigger_priv` = 'Y', `Create_tablespace_priv` = 'Y', `Create_role_priv` = 'Y', `Drop_role_priv` = 'Y' WHERE `user`.`Host` = '%' AND `user`.`User` = 'rob'; https://lefred.be/content/how-to-grant-privileges-to-users-in-mysql-8-0/ Grant Privileges for a user to a database; grant alter,create,delete,drop,index,insert,select,update,trigger,alter routine, create routine, execute, create temporary tables on user1.* to 'user1'; grant alter,create,delete,drop,index,insert,select,update,trigger,alter routine, create routine, execute, create temporary tables on hillc1.* to 'theusername'; grant all privileges on thedatabasename.* to 'theusername'@'localhost' with grant option; flush privileges; grant all privileges on thedatabasename.* to 'theusername'@'%' with grant option; flush privileges; grant SELECT, INSERT, UPDATE, DELETE ON SomeDatabase TO 'theusername'@'localhost'; Group By: (Uses \"Having\" instead of \"Where\" clause.) Find duplicate data in a column. SELECT column1, COUNT(*) c FROM tablename GROUP BY column1 HAVING c > 1; Show number of presidents from each state. select state_born State, count(*) Number_of_Presidents from uspresidents group by state having Number_of_Presidents > 0 order by Number_of_Presidents, state; IF and CASE Statements: Select If: There are times where running IF statements inside a query can be useful. MySQL provides a simple way to do this through the use of IF and CASE statements. The IF statement takes three arguments; the conditional, the true value, and the false value. False and true values may be static values or column values. For example: SELECT IF(score >= 100, \"Good Job\", score) AS score FROM exam_results; this will check if the value in the score column is 100 then print \"Good Job\" otherwise print the value of score. IF statements can also be nested: SELECT IF(score >= 100, \"Good Job\", IF(score < 100, \"You Failed!\", score)) score FROM exam_results; CASE statements (switch statements for those C programmers) are much like if statements. For example: CREATE TABLE `headcount` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `num_heads` int(11) NOT NULL, `active_ind` int(1) NOT NULL DEFAULT '1', PRIMARY KEY (`id`) ) ENGINE=InnoDB; SELECT CASE num_heads WHEN 0 THEN 'Zombie' WHEN 1 THEN 'Human' ELSE 'Alien' END AS race FROM headcount; This code checks the value in the num_heads column and deduces race from the values presented. CASE statements may also be nested in the same way as IF statements. I used this to prepend a zero in front of values that were less than 10. select concat(\"update yt_video_rename set day = \",if(day<10, concat(\"0\",day),day),\" where id = \", id,\";\") xyz from yt_video_rename order by day; Count the number of presidents from each party: select sum(if(party = 1, 1,0)) as Federalist, sum(if(party = 2, 1,0)) as \"Democratic-Republican\", sum(if(party = 3,1,0)) as Democrat, sum(if(party = 4,1,0)) as Whig, sum(if(party = 5,1,0)) Republican, sum(if(party = 6,1,0)) \"Democratic-Union\", sum(if(party = 7,1,0)) Republican1 from us_presidents; -- Start at 0 and increment by 1 for each party member found. Increment results numerically (count results). Good for displaying first, second, third place: SELECT @n := @n + 1 \"Item#:\", firstname, lastname FROM test, (SELECT @n := 0) m ORDER BY firstname, lastname; My working example: select @n := @n + 1 place, person, medication, dose_unit, admin_dttm, temp_f, temp_c, symptom from vw_healthsummary, (select @n := 0) m order by temp_f desc limit 0, 50; Online Example for SQLServer: SELECT row_number() OVER (ORDER BY first_name, last_name) n, first_name, last_name FROM table1 Source: https://stackoverflow.com/questions/16555454/how-to-generate-auto-increment-field-in-select-query InnoDB vs MyISAM: The main differences between InnoDB and MyISAM (\"with respect to designing a table or database\" you asked about) are support for \"referential integrity\" and \"transactions\". If you need the database to enforce foreign key constraints, or you need the database to support transactions (i.e. changes made by two or more DML operations handled as single unit of work, with all of the changes either applied, or all the changes reverted) then you would choose the InnoDB engine, since these features are absent from the MyISAM engine. Those are the two biggest differences. Another big difference is concurrency. With MyISAM, a DML statement will obtain an exclusive lock on the table, and while that lock is held, no other session can perform a SELECT or a DML operation on the table. Those two specific engines you asked about (InnoDB and MyISAM) have different design goals. MySQL also has other storage engines, with their own design goals. So, in choosing between InnoDB and MyISAM, the first step is in determining if you need the features provided by InnoDB. If not, then MyISAM is up for consideration. A more detailed discussion of differences is rather impractical (in this forum) absent a more detailed discussion of the problem space... how the application will use the database, how many tables, size of the tables, the transaction load, volumes of select, insert, updates, concurrency requirements, replication features, etc. The logical design of the database should be centered around data analysis and user requirements; the choice to use a relational database would come later, and even later would the the choice of MySQL as a relational database management system, and then the selection of a storage engine for each table. MYISAM: MYISAM supports Table-level Locking MyISAM designed for need of speed MyISAM does not support foreign keys hence we call MySQL with MYISAM is DBMS MyISAM stores its tables, data and indexes in diskspace using separate three different files. (tablename.FRM, tablename.MYD, tablename.MYI) MYISAM not supports transaction. You cannot commit and rollback with MYISAM. Once you issue a command it\u001as done. MYISAM supports fulltext search You can use MyISAM, if the table is more static with lots of select and less update and delete. INNODB: InnoDB supports Row-level Locking InnoDB designed for maximum performance when processing high volume of data InnoDB support foreign keys hence we call MySQL with InnoDB is RDBMS InnoDB stores its tables and indexes in a tablespace InnoDB supports transaction. You can commit and rollback with InnoDB Source: http://stackoverflow.com/questions/12614541/whats-the-difference-between-myisam-and-innodb Insert Into: INSERT INTO ANOTHER TABLE FROM CURRENT TABLE First, make an empty version (copy) of a table by using CREATE TABLE. Example: CREATE TABLE secondtable LIKE firsttable; -- This example inserts two columns into the secondtable table from the firsttable table. insert into secondtable (column1, column2) select column1, column2 from firsttable; -- Another method: CREATE TABLE secondtable AS SELECT columns FROM firsttable WHERE conditions; INT vs BIGINT: -- http://stackoverflow.com/questions/3135804/types-in-mysql-bigint20-vs-int20-etcc INT is a four-byte signed integer. BIGINT is an eight-byte signed integer. The 20 in INT(20) and BIGINT(20) means almost nothing. It's a hint for display width, it has nothing to do with storage. Practically, it affects only the ZEROFILL option: CREATE TABLE foo ( bar INT(20) ZEROFILL ); INSERT INTO foo (bar) VALUES (1234); SELECT bar from foo; +----------------------+ | bar | +----------------------+ | 00000000000000001234 | +----------------------+ It's a common source of confusion for MySQL users to see INT(20) and assume it's a size limit, something analogous to CHAR(20). Joins: Left Inner Join Left Join Inner Join Right Inner Join Right Join Full Outer Join Full Inner Join Join with no where clause: I have two tables I want to join. I want all of the categories in the categories table and also all of the categories subscribed to by a user in the category_subscriptions table. essentially this is my query so far: SELECT * FROM categories LEFT JOIN user_category_subscriptions ON user_category_subscriptions.category_id = categories.category_id; This works fine however I want to add a where clause on the end of the query which then essentially makes it an inner/equi join. SELECT * FROM categories LEFT JOIN user_category_subscriptions ON user_category_subscriptions.category_id = categories.category_id WHERE user_category_subscriptions.user_id = 1; How do I get all the categories as well as all the categories subscribed to by a particular user using only one query? category_id being a key in both categories table and user_category_subscriptions. user_id residing in the user_category_subscriptions table. thanks Join with no where clause ANSWER: You need to put it in the join clause, not the where: SELECT * FROM categories LEFT JOIN user_category_subscriptions ON user_category_subscriptions.category_id = categories.category_id and user_category_subscriptions.user_id =1; See, with an inner join, putting a clause in the join or the where is equivalent. However, with an outer join, they are vastly different. As a join condition, you specify the rowset that you will be joining to the table. This means that it evaluates user_id = 1 first, and takes the subset of user_category_subscriptions with a user_id of 1 to join to all of the rows in categories. This will give you all of the rows in categories, while only the categories that this particular user has subscribed to will have any information in the user_category_subscriptions columns. Of course, all other categories will be populated with null in the user_category_subscriptions columns. Conversely, a where clause does the join, and then reduces the rowset. So, this does all of the joins and then eliminates all rows where user_id doesn't equal 1. You're left with an inefficient way to get an inner join. Last Insert ID: Getting Last Insert ID: drop database lastinsert_id; create database lastinsert_id; use lastinsert_id; create table foo (id int(11) auto_increment primary key , text varchar(50) not null)engine=innodb; create table foo2 (id int(11) auto_increment primary key , foo_id int(11) not null, text varchar(50) not null)engine=innodb; -- https://dev.mysql.com/doc/c-api/5.6/en/getting-unique-id.html INSERT INTO foo (id,text) VALUES(NULL,'filename'); # generate ID by inserting NULL INSERT INTO foo2 (id,foo_id,text) VALUES(NULL,LAST_INSERT_ID(),'last_insert_id.sql'); # use ID in second table Last Insert ID Using PDO: -- https://stackoverflow.com/questions/10680943/pdo-get-the-last-id-inserted $stmt = $db->prepare(\"...\"); $stmt->execute(); $id = $db->lastInsertId(); If you want to do it with SQL instead of the PDO API, you would do it like a normal select query: $stmt = $db->query(\"SELECT LAST_INSERT_ID()\"); $lastId = $stmt->fetchColumn(); Load input (local_infile): insert into cv (id,content) values (\"1\",LOAD_FILE('cv.doc')); MySQL 8.0 has the load data local_infile option off by default. You can enable it by logging into the MySQL server and running: mysql> show global variables like 'local_infile'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | local_infile | OFF | +---------------+-------+ 1 row in set (0.01 sec) mysql> set global local_infile = true; Query OK, 0 rows affected (0.00 sec) mysql> show global variables like 'local_infile'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | local_infile | ON | +---------------+-------+ 1 row in set (0.00 sec) Afterward, you will have to start the MySQL client with: /usr/local/mysql/bin/mysql -u USERNAME -p --local-infile DATABASENAME mysql -u USERNAME -p --local-infile DATABASENAME Source: https://stackoverflow.com/questions/10762239/mysql-enable-load-data-local-infile -- From the MySQL command prompt. -- It is easier to have the file you want to import located in the same directory where you start mysql. Then run load data local infile once you log in. -- I loaded the exported Bedrock .csv files into a database using the following: /* The database and table. create database bedrock; use bedrock; if exist drop table bedrock_csv; create table bedrock_csv (id int(11) unsigned auto_increment primary key, audit_type varchar(500) null, topic_name varchar(500) null, filter_sequence varchar(500) null, filter_meaning varchar(500) null, filter_type_meaning varchar(500) null, filter_name varchar(500) null, flex_display varchar(500) null, saved_value varchar(500) null, description varchar(500) null, event_set_name varchar(500) null, code_value_id varchar(500) null, value_type varchar(500) null, value_sequence varchar(500) null, value_group_sequence varchar(500) null, qualifier varchar(500) null, map_type varchar(500) null, mapped_to_code_1 varchar(500) null, mapped_to_description_1 varchar(500) null, mapped_to_code_2 varchar(500) null, mapped_to_description_2 varchar(500) null, last_update_date_time varchar(500) null, last_update_by varchar(500) null ) engine=innodb; */ -- I combined all of the exported Bedrock .csv files into one large file called allfiles.dat by using sed to remove the first header row. -- Example: sed '1d' Exported_CSV_FILE.csv >> allfiles.dat -- http://unix.stackexchange.com/questions/96226/delete-first-line-of-a-file load data local infile 'allfiles.dat' into table bedrock_csv fields terminated by ',' enclosed by '\"' lines terminated by '\\n' (audit_type, topic_name, filter_sequence, filter_meaning, filter_type_meaning, filter_name, flex_display, saved_value, description, event_set_name, code_value_id, value_type, value_sequence, value_group_sequence, qualifier, map_type, mapped_to_code_1, mapped_to_description_1, mapped_to_code_2, mapped_to_description_2, last_update_date_time, last_update_by); load data infile 'allfiles.dat' replace into table bedrock_csv; -- Using the \"local\" keyword helped me get past the error message: \"The MySQL server is running with the --secure-file-priv option so it cannot execute this statement\". -- https://stackoverflow.com/questions/32737478/how-should-i-tackle-secure-file-priv-in-mysql load data local infile 'US_States.csv' into table us_states fields terminated by '|' lines terminated by '\\n' (state,abbreviation,capital,largest_city,established,population,sq_mi,sq_km,land_area_mi,land_area_km,water_area_mi,water_area_km,representatives); /*Another example: I was stuck on a problem where the ImportXML3.xml file would not get imported into the database because the XML tag names were in different case on some of the lines. Once I made them the same case it was imported. -- This online link was helpful. http://dev.mysql.com/doc/refman/5.5/en/load-xml.html This statement supports three different XML formats: Column names as attributes and column values as attribute values: <row column1=\"value1\" column2=\"value2\" .../> Column names as tags and column values as the content of these tags: <row> <column1>value1</column1> <column2>value2</column2> </row> Column names are the name attributes of <field> tags, and values are the contents of these tags: <row> <field name='column1'>value1</field> <field name='column2'>value2</field> </row> This is the format used by other MySQL tools, such as mysqldump. All three formats can be used in the same XML file; the import routine automatically detects the format for each row and interprets it correctly. Tags are matched based on the tag or attribute name and the column name. */ LOAD XML LOCAL INFILE 'ImportXML3.xml' INTO TABLE xmlimport3 ROWS IDENTIFIED BY '<myfields>'; /*The ImportXML3.xml file looks like this: <rlh> <myfields><lastname>firstname01</lastname><firstname>lastname01</firstname></myfields> <myfields><lastname>firstname02</lastname><firstname>lastname02</firstname></myfields> <myfields><lastname>firstname03</lastname><firstname>lastname03</firstname></myfields> <myfields><lastname>firstname04</lastname><firstname>lastname04</firstname></myfields> <myfields><lastname>firstname05</lastname><firstname>lastname05</firstname></myfields> <myfields><lastname>firstname06</lastname><firstname>lastname06</firstname></myfields> <myfields><lastname>firstname07</lastname><firstname>lastname07</firstname></myfields> <myfields><lastname>firstname08</lastname><firstname>lastname08</firstname></myfields> <myfields><lastname>firstname09</lastname><firstname>lastname09</firstname></myfields> <myfields><lastname>firstname10</lastname><firstname>lastname10</firstname></myfields> <myfields><lastname>firstname11</lastname><firstname>lastname11</firstname></myfields> <myfields><lastname>firstname12</lastname><firstname>lastname12</firstname></myfields> <myfields><lastname>firstname13</lastname><firstname>lastname13</firstname></myfields> <myfields><lastname>firstname14</lastname><firstname>lastname14</firstname></myfields> <myfields><lastname>firstname15</lastname><firstname>lastname15</firstname></myfields> <myfields><lastname>firstname16</lastname><firstname>lastname16</firstname></myfields> <myfields><lastname>firstname17</lastname><firstname>lastname17</firstname></myfields> </rlh> */ I got an error when I tried to load some data exported from an Excel spreadsheet in .csv format. The error message was \"ERROR 1300 (HY000): Invalid utf8mb4 character string:\" I wasn't able to manually correct all of the invalid characters in the .csv file because there were too many. There is a command on Linux called \"file\" that will tell you the file type. When I ran it \"file -i filename.csv\" it displayed a message telling me unknown. file -i mpages1.csv I found a website that suggested that the file might be latin so I used another Linux command called \"iconv\" to convert it from latin to UTF8 and I was able to import the .csv into MySQL. iconv -f latin1 -t utf8 < mpages1.csv > mpages2.csv This worked: (Source: https://unix.stackexchange.com/questions/141539/iconv-illegal-input-sequence-why). Change database and table collation and char set to utf8mb4 and utf8mb4_unicode_ci.: ALTER DATABASE <db_name> CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; ALTER TABLE <table_name> CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; (Source: https://stackoverflow.com/questions/48270374/invalid-datetime-format-1366-incorrect-string-value) Locate MySQL Database Files: Typically the MySQL database files are located in /usr/local/mysql/data/databasename/ select @@datadir, @@innodb_data_home_dir; File locations: SELECT TABLESPACE_NAME, FILE_NAME FROM INFORMATION_SCHEMA.FILES \\G Natural Sorting of Numbers: https://stackoverflow.com/questions/8557172/mysql-order-by-sorting-alphanumeric-correctly https://www.copterlabs.com/natural-sorting-in-mysql/ select lastname, firstname, salary, jobtitle, hiredate from payback order by cast(salary as unsigned), salary; Output to a file: From the mysql command prompt: You can create an output file formatted with comma delimiters and fields enclosed by quotes. The mysql user must have privileges to the output file location. select * into outfile 'outputfilename.txt' fields terminated by ',' optionally enclosed by '\"' lines terminated by '\\n' from yourtablename where columnname = 'whatever'; If no path is specified, the file will be located in the default database folder. In my case (Fedora 12) it was located in /var/lib/mysql/thedatabasename/outputfilename.txt. -- You can specify where the output file will go: SELECT id, client, project, task, description, time, date INTO OUTFILE '/path/to/file.csv' --mysql user must have privileges to the location. FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '\"' LINES TERMINATED BY '\\n' FROM ts From outside of the mysql command prompt (ie. the command line) you can also run a query and create an output file with the results of that query. Create a query that you want to run and save it as an .sql file. Example: test.sql The content of the test.sql file looks like this: select * from tablename; To run test.sql type one of the following: -- If you want tab delimited output format (default): mysql databasename -u username -p < test.sql > output.tab Convert the tabs to comma delimited surrounded by quotes: mysql -u username -p -h computername.lan < test.sql |sed 's/\\t/\\\",\\\"/g'|sed 's/^/\\\"/g'|sed 's/$/\\\"/g' > output.csv -- XML output format: mysql databasename -u username -p --xml < test.sql > output.xml -- If you don't want to create the test.sql file and just want to run everything from one commandline statement and get XML output: mysql -u username -p --xml -e 'use databasename; select * from tablename' > output.xml -- You can also put the db_name in your script to avoid typing it on the command line (see below). mysql -u username -p --xml < test.sql > output.xml -- You can create a bash script named getdata and put the following in it. mysql -u username -p < test.sql > test.tab -- Then chmod +x getdata. then run it from the commandline: sh getdata. -- You will be prompted for your database password and the data will get dumped to test.tab. -- The contents of test.sql without the database name. select * from tablename order by columnName; -- The contents of test.sql with the database name. use thedatabase; select * from tablename order by columnName; -- Connect to a remote database server and directly to a database on that server. mysql -h hostname -u databaseuser -p -D databasename -- To Dump a database to a file and generate full insert statements: mysqldump -p -c -e databasename > DatabaseName.sql -- To Dump the database data without the database structure: mysqldump -u root -p thedatabasename --no-create-info > 20240609.sql -- To dump a table from a database and generate full insert statements: mysqldump -p -c -e databasename tablename > TableName.sql -- To dump multiple tables from a database: mysqldump -u theusername -p thedatabasename tablename1 tablename1 tablename2 tablename3 tablename4 tablename5 > thedate_thedatabasename_tables_on_`hostname`.sql -- To dump all databases on the database server: mysqldump -p -c -e --all-databases > AllDatabases.sql -- To dump all databases on the database server without the data (just a skeleton). mysqldump -p -c -e --no-data --all-databases > AllDatabases_Skeleton.sql -- To dump a database from a remote server: mysqldump -h hostname -u username -p -c -e databasename > NameOfDatabaseDumpFile.sql -- To dump a table from a database on a remote server: mysqldump -h hostname -u username -p -c -e databasename tablename > NameOfTableDumpFile.sql -- To dump all databases on a remote server: mysqldump -h hostname -u username -p -c -e --all-databases > NameOfEntireDatabaseDumpFile.sql -- Restore database from a file: mysql -u root -p thedatabasename < 20200424_thedatabasename.sql Padding numbers with zeros: Number padding -- Prepend zeros to numbers. There are some links that I saw that said you will need to convert the column to non-numerical to get this to work but I did it on an integer field and it worked. -- The 8 means to pad up to 8 characters, the zero is the character you want to pad with. SELECT LPAD('1234567', 8, '0'); Password Change: use mysql; -- Method 1 (Deprecated): update mysql.user set password('thepassword') where user = 'root'; FLUSH PRIVILEGES; -- Method 2 (MySQL 5.7+): update mysql.user set authentication_string=PASSWORD('thepassword') where user='root'; FLUSH PRIVILEGES; -- Method 3 (Preferred method for current user.): alter user set password = 'thepassword'; FLUSH PRIVILEGES; -- MySQL 5.7: alter user 'root'@'localhost' identified by 'thepassword'; alter user 'root'@'%' identified by 'thepassword'; -- Method 4 (Preferred method for another user.): alter user set password for 'root'@'localhost' = 'thepassword'; FLUSH PRIVILEGES; -- Remote user password change: alter user set password for 'root'@'%' = 'thepassword'; FLUSH PRIVILEGES; Path to MySQL files: On my MAC: MySQL program: /usr/local/mysql/bin/mysql Databases: /usr/local/mysql/data/ On Ubuntu: MySQL program: /usr/bin/mysql Databases (need to be root): /var/lib/mysql/ Prompt (MySQL): Change the default mysql> prompt to something functional and useful. 1. Display username, hostname and current database name in the mysql prompt The MYSQL_PS1 in this example displays the following three information in the prompt: \\u - Username \\h - Hostname \\d - Current mysql database $ export MYSQL_PS1=\"\\u@\\h [\\d]> \" $ mysql -u root -pyour-password -D sugarcrm root@dev-db [sugarcrm]> 2. Change the mysql> prompt interactively You can also change the mysql> prompt interactively from inside the mysql as shown below. $ mysql -u root -pyour-password -D sugarcrm mysql> prompt \\u@\\h [\\d]> PROMPT set to '\\u@\\h [\\d]> ' root@dev-db [sugarcrm]> 3. Change the mysql> prompt from mysql command line Instead of using the MYSQL_PS1 variable, you can also pass the prompt as an argument to the mysql command line as shown below. $ mysql --prompt=\"\\u@\\h [\\d]> \" -u root -pyour-password -D sugarcrm root@dev-db [sugarcrm]> 4. Display Current Time in the mysql> prompt Use \\D to display full date in the mysql prompt as shown below. $ export MYSQL_PS1=\"\\u@\\h [\\D]> \" $ mysql -u root -pyour-password -D sugarcrm root@dev-db [Sat Dec 26 19:56:33 2009]> 5. Change the mysql> prompt using /etc/my.cnf or .my.cnf file You can also use either the global /etc/my.cnf (or) your local ~/.my.cnf file to set the prompt as shown below. $ vi ~/.my.cnf [mysql] prompt=\\\\u@\\\\h [\\\\d]>\\\\_ $ mysql -u root -pyour-password -D sugarcrm root@dev-db [sugarcrm]> 6. Customize mysql> prompt any way you want it Use the following variables and customize the mysql prompt as you see fit. These variables are somewhat similar to the Unix PS1 variables (but not exactly the same). Generic variables: \\S displays semicolon \\' displays single quote \\\" displays double quote \\v displays server version \\p displays port \\\\ displays backslash \\n displays newline \\t displays tab \\ displays space (there is a space after \\ ) \\d displays default database \\h displays default host \\_ displays space (there is a underscore after \\ ) \\c displays a mysql statement counter. keeps increasing as you type commands. \\u displays username \\U displays username@hostname accountname Date related variables: \\D displays full current date (as shown in the above example) \\w displays 3 letter day of the week (e.g. Mon) \\y displays the two digit year \\Y displays the four digit year \\o displays month in number \\O displays 3 letter month (e.g. Jan) \\R displays current time in 24 HR format \\r displays current time in 12 hour format \\m displays the minutes \\s displays the seconds \\P displays AM or PM Note: You can go back to the regular boring mysql> prompt at anytime by simply typing prompt in the mysql> prompt as shown below. root@dev-db [sugarcrm]> prompt Returning to default PROMPT of mysql> mysql> <a href='http://www.thegeekstuff.com/2010/02/mysql_ps1-6-examples-to-make-your-mysql-prompt-like-angelina-jolie/'>Source</a> mysql -h localhost -u rob_com1 -p -D robcom1 Remote connection from commandline: You should only use this command on a secure SSH connection. Syntax: mysql -h RemoteServerName -u myusername -p Connect to a remote database server and directly to a database on that server. mysql -h hostname -u databaseuser -p -D databasename Rename a Database The normal way to rename a database is to dump it then import the data to a new database name. Make sure you check the definer for any views that were created in the database. To rename a table type: RENAME TABLE tb1 TO tb2; Another way to rename a table; ALTER TABLE exampletable RENAME TO new_table_name; The commands below are what I copied from a Stack Exchange article but they did not work for me. I am only leaving them here so that I can study them at some other time. /* mysql -e \"CREATE DATABASE \\`new_database\\`;\" for table in `mysql -B -N -e \"SHOW TABLES;\" old_database` do mysql -e \"RENAME TABLE \\`old_database\\`.\\`$table\\` to \\`new_database\\`.\\`$table\\`\" done mysql -e \"DROP DATABASE \\`old_database\\`;\" */ mysql -u robertme -p mysql -e \"CREATE DATABASE \\`united_states\\`;\" for table in `mysql -B -N -e \"SHOW TABLES;\" test` do mysql -e \"RENAME TABLE \\`test\\`.\\`$table\\` to \\`united_states\\`.\\`$table\\`\" done mysql -e \"DROP DATABASE \\`test\\`;\" Revoke: https://mariadb.com/kb/en/revoke/ https://www.techonthenet.com/mariadb/grant_revoke.php revoke all privileges, grant option from 'SomeUser'@'%'; revoke all privileges, grant option from 'SomeUser'@'localhost'; revoke SELECT, INSERT, UPDATE, DELETE ON SomeDatabase TO 'SomeUser'@'localhost'; Select: Select across databases; select mysql.user.user from mysql.user; -- Example on https://stackoverflow.com/questions/674115/select-columns-across-different-databases SELECT mydatabase1.tblUsers.UserID, mydatabse2.tblUsers.UserID FROM mydatabase1.tblUsers INNER JOIN mydatabase2.tblUsers ON mydatabase1.tblUsers.UserID = mydatabase2.tblUsers.UserID Select Blobdata: SELECT SUBSTRING(<BLOB COLUMN_NAME>,1,2500) FROM <Table_name>; Null and Not NULL: Show what IS NOT NULL: SELECT * FROM table WHERE YourColumn IS NOT NULL; This seems to show what IS NULL: SELECT * FROM table WHERE NOT (YourColumn <=> NULL); http://stackoverflow.com/questions/5285448/mysql-select-only-not-null-values Shell Commands: If you want to run shell commands from within the MySQL command prompt use a backslash and exclaimation mark: Example: \\! ls -al Show columns/tables/databases: To show columns: show columns from <table> from <database>; or (if you are already in the database) desc <table>; To show tables: show tables from <database>; or (if you are already in the database) show tables; To show databases: show databases; or (if you are already in the database) show schemas; To show database file location: show variables where Variable_name like '%datadir%'; Service (MySQL): Linux and/or MAC: Restart, Start, Stop MySQL from the Command Line macOS, OSX, Linux November 19, 2015 24 Comments To restart, start or stop MySQL server from the command line, type the following at the shell prompt\u001a On Linux start/stop/restart from the command line: /etc/init.d/mysqld start /etc/init.d/mysqld stop /etc/init.d/mysqld restart Some Linux flavors offer the service command too service mysqld start service mysqld stop service mysqld restart or service mysql start service mysql stop service mysql restart On macOS Sierra & OS to start/stop/restart MySQL post 5.7 from the command line: Start: sudo launchctl load -F /Library/LaunchDaemons/com.oracle.oss.mysql.mysqld.plist Stop: sudo launchctl unload -F /Library/LaunchDaemons/com.oracle.oss.mysql.mysqld.plist On OS X to start/stop/restart MySQL pre 5.7 from the command line: sudo /usr/local/mysql/support-files/mysql.server start sudo /usr/local/mysql/support-files/mysql.server stop sudo /usr/local/mysql/support-files/mysql.server restart Source: Use \"source\" to run a query from outside the database command prompt window. Example: if you have a query file named \"bigdata.sql\" that contains valid MySQL statements that you want to run. Example: source bigdata.sql; or \\. bigdata.sql Flush Privileges Error: ERROR 1227 (42000): Access denied; you need (at least one of) the RELOAD privilege(s) for this operation Solution: GRANT RELOAD ON *.* TO 'your_user'@'localhost'; GRANT RELOAD ON *.* TO 'rob'@'localhost'; GRANT RELOAD ON *.* TO 'rob'@'%'; Statements and Clauses (MySQL): MYSQL Statements and clauses ALTER DATABASE ALTER TABLE ALTER VIEW ANALYZE TABLE BACKUP TABLE CACHE INDEX CHANGE MASTER TO CHECK TABLE CHECKSUM TABLE COMMIT CREATE DATABASE CREATE INDEX CREATE TABLE CREATE VIEW DELETE DESCRIBE DO DROP DATABASE DROP INDEX DROP TABLE DROP USER DROP VIEW EXPLAIN FLUSH GRANT HANDLER INSERT JOIN KILL LOAD DATA FROM MASTER LOAD DATA INFILE LOAD INDEX INTO CACHE LOAD TABLE...FROM MASTER LOCK TABLES OPTIMIZE TABLE PURGE MASTER LOGS RENAME TABLE REPAIR TABLE REPLACE RESET RESET MASTER RESET SLAVE RESTORE TABLE REVOKE ROLLBACK ROLLBACK TO SAVEPOINT SAVEPOINT SELECT SET SET PASSWORD SET SQL_LOG_BIN SET TRANSACTION SHOW BINLOG EVENTS SHOW CHARACTER SET SHOW COLLATION SHOW COLUMNS SHOW CREATE DATABASE SHOW CREATE TABLE SHOW CREATE VIEW SHOW DATABASES SHOW ENGINES SHOW ERRORS SHOW GRANTS SHOW INDEX SHOW INNODB STATUS SHOW LOGS SHOW MASTER LOGS SHOW MASTER STATUS SHOW PRIVILEGES SHOW PROCESSLIST SHOW SLAVE HOSTS SHOW SLAVE STATUS SHOW STATUS SHOW TABLE STATUS SHOW TABLES show tables like 'abc%'; SHOW VARIABLES SHOW WARNINGS START SLAVE START TRANSACTION STOP SLAVE TRUNCATE TABLE UNION UNLOCK TABLES USE String Functions AES_DECRYPT AES_ENCRYPT ASCII BIN BINARY BIT_LENGTH CHAR CHAR_LENGTH CHARACTER_LENGTH COMPRESS CONCAT CONCAT_WS CONV DECODE DES_DECRYPT DES_ENCRYPT ELT ENCODE ENCRYPT EXPORT_SET FIELD FIND_IN_SET HEX INET_ATON INET_NTOA INSERT INSTR LCASE LEFT LENGTH LOAD_FILE LOCATE LOWER LPAD LTRIM MAKE_SET MATCH AGAINST MD5 MID OCT OCTET_LENGTH OLD_PASSWORD ORD PASSWORD POSITION QUOTE REPEAT REPLACE REVERSE RIGHT RPAD RTRIM SHA SHA1 SOUNDEX SPACE STRCMP SUBSTRING SUBSTRING_INDEX TRIM UCASE UNCOMPRESS UNCOMPRESSED_LENGTH UNHEX UPPER Date and Time Functions ADDDATE ADDTIME CONVERT_TZ CURDATE CURRENT_DATE CURRENT_TIME CURRENT_TIMESTAMP CURTIME DATE DATE_ADD DATE_FORMAT DATE_SUB DATEDIFF DAY DAYNAME DAYOFMONTH DAYOFWEEK DAYOFYEAR EXTRACT FROM_DAYS FROM_UNIXTIME GET_FORMAT HOUR LAST_DAY LOCALTIME LOCALTIMESTAMP MAKEDATE MAKETIME MICROSECOND MINUTE MONTH MONTHNAME NOW PERIOD_ADD PERIOD_DIFF QUARTER SEC_TO_TIME SECOND STR_TO_DATE SUBDATE SUBTIME SYSDATE TIME TIMEDIFF TIMESTAMP TIMESTAMPDIFF TIMESTAMPADD TIME_FORMAT TIME_TO_SEC TO_DAYS UNIX_TIMESTAMP UTC_DATE UTC_TIME UTC_TIMESTAMP WEEK WEEKDAY WEEKOFYEAR YEAR YEARWEEK Mathematical and Aggregate Functions ABS ACOS ASIN ATAN ATAN2 AVG BIT_AND BIT_OR BIT_XOR CEIL CEILING COS COT COUNT CRC32 DEGREES EXP FLOOR FORMAT GREATEST GROUP_CONCAT LEAST LN LOG LOG2 LOG10 MAX MIN MOD PI POW POWER RADIANS RAND ROUND SIGN SIN SQRT STD STDDEV SUM TAN TRUNCATE VARIANCE Flow Control Functions CASE IF IFNULL NULLIF Command-Line Utilities comp_err isamchk make_binary_distribution msql2mysql my_print_defaults myisamchk myisamlog myisampack mysqlaccess mysqladmin mysqlbinlog mysqlbug mysqlcheck mysqldump mysqldumpslow mysqlhotcopy mysqlimport mysqlshow perror Perl API - using functions and methods built into the Perl DBI with MySQL available_drivers begin_work bind_col bind_columns bind_param bind_param_array bind_param_inout can clone column_info commit connect connect_cached data_sources disconnect do dump_results err errstr execute execute_array execute_for_fetch fetch fetchall_arrayref fetchall_hashref fetchrow_array fetchrow_arrayref fetchrow_hashref finish foreign_key_info func get_info installed_versions last_insert_id looks_like_number neat neat_list parse_dsn parse_trace_flag parse_trace_flags ping prepare prepare_cached primary_key primary_key_info quote quote_identifier rollback rows selectall_arrayref selectall_hashref selectcol_arrayref selectrow_array selectrow_arrayref selectrow_hashref set_err state table_info table_info_all tables trace trace_msg type_info type_info_all Attributes for Handles PHP API - using functions built into PHP with MySQL mysql_affected_rows mysql_change_user mysql_client_encoding mysql_close mysql_connect mysql_create_db mysql_data_seek mysql_db_name mysql_db_query mysql_drop_db mysql_errno mysql_error mysql_escape_string mysql_fetch_array mysql_fetch_assoc mysql_fetch_field mysql_fetch_lengths mysql_fetch_object mysql_fetch_row mysql_field_flags mysql_field_len mysql_field_name mysql_field_seek mysql_field_table mysql_field_type mysql_free_result mysql_get_client_info mysql_get_host_info mysql_get_proto_info mysql_get_server_info mysql_info mysql_insert_id mysql_list_dbs mysql_list_fields mysql_list_processes mysql_list_tables mysql_num_fields mysql_num_rows mysql_pconnect mysql_ping mysql_query mysql_real_escape_string mysql_result mysql_select_db mysql_stat mysql_tablename mysql_thread_id mysql_unbuffered_query Time / Timezones: SELECT CONVERT_TZ(displaytime,'GMT','MET'); should work if your column type is timestamp, or date You need to have the timezones loaded. See below if you don't have the timezones loaded. ```","title":"MariaDB/MySQL"},{"location":"mysql/#terminology","text":"","title":"Terminology:"},{"location":"mysql/#data-definition-language-ddl","text":"DDL statements are used to define the database structure or schema. DDL (Data Definition Language) refers to the CREATE, ALTER and DROP statements DDL allows to add / modify / delete the logical structures which contain the data or which allow users to access / maintain the data (databases, tables, keys, views...). DDL is about \"metadata\". Some examples: CREATE - to create objects in the database ALTER - alters the structure of the database DROP - delete objects from the database TRUNCATE - remove all records from a table, including all spaces allocated for the records are removed. The operation cannot be rolled back. COMMENT - add comments to the data dictionary RENAME - rename an object","title":"Data Definition Language (DDL):"},{"location":"mysql/#data-manipulation-language-dml","text":"DML (Data Manipulation Language) refers to the INSERT, UPDATE and DELETE statements. DML statements are used for managing data within schema objects. DML allows to add / modify / delete data itself. Some examples: INSERT - insert data into a table UPDATE - updates existing data within a table DELETE - deletes all records from a table, the space for the records remain. Can be rolled back. Must me committed to make changes permanent. MERGE - UPSERT operation (insert or update) CALL - call a PL/SQL or Java subprogram EXPLAIN PLAN - explain access path to data LOCK TABLE - control concurrency","title":"Data Manipulation Language (DML):"},{"location":"mysql/#dql-data-query-language","text":"DQL refers to the SELECT, SHOW and HELP statements (queries) SELECT is the main DQL instruction. It retrieves data you need. SHOW retrieves information about the metadata. HELP ... is for people who need help. Some examples: SELECT - retrieve data from the a database","title":"DQL (Data Query Language):"},{"location":"mysql/#data-control-language-dcl","text":"DCL (Data Control Language) refers to the GRANT and REVOKE statements DCL is used to grant / revoke permissions on databases and their contents. DCL is simple, but MySQL's permissions are rather complex. DCL is about security. Some examples: GRANT - gives user's access privileges to database REVOKE - withdraw access privileges given with the GRANT command","title":"Data Control Language (DCL):"},{"location":"mysql/#transaction-control-tcl","text":"TCL statements are used to manage the changes made by DML statements. It allows statements to be grouped together into logical transactions. COMMIT - save work done SAVEPOINT - identify a point in a transaction to which you can later roll back ROLLBACK - restore database to original since the last COMMIT SET TRANSACTION - Change transaction options like isolation level and what rollback segment to use","title":"Transaction Control (TCL):"},{"location":"mysql/#dtl-data-transaction-language","text":"DTL refers to the START TRANSACTION, SAVEPOINT, COMMIT and ROLLBACK [TO SAVEPOINT] statements. DTL is used to manage transactions (operations which include more instructions none of which can be executed if one of them fails).","title":"DTL (Data Transaction Language):"},{"location":"mysql/#note-about-drop-truncate-and-delete","text":"DROP and TRUNCATE are DDL commands, whereas DELETE* is a DML command. Therefore DELETE operations can be rolled back (undone), while DROP** and TRUNCATE operations cannot be rolled back.","title":"Note about DROP, TRUNCATE, and DELETE:"},{"location":"mysql/#mysql-data-types","text":"Properly defining the fields in a table is important to the overall optimization of your database. You should use only the type and size of field you really need to use; don't define a field as 10 characters wide if you know you're only going to use 2 characters. These types of fields (or columns) are also referred to as data types, after the type of data you will be storing in those fields. MySQL uses many different data types broken into three categories: numeric, date and time, and string types. - Numeric Data Types: MySQL uses all the standard ANSI SQL numeric data types, so if you're coming to MySQL from a different database system, these definitions will look familiar to you. The following list shows the common numeric data types and their descriptions: - INT - A normal-sized integer that can be signed or unsigned. If signed, the allowable range is from -2147483648 to 2147483647. If unsigned, the allowable range is from 0 to 4294967295. You can specify a width of up to 11 digits. - TINYINT - A very small integer that can be signed or unsigned. If signed, the allowable range is from -128 to 127. If unsigned, the allowable range is from 0 to 255. You can specify a width of up to 4 digits. - SMALLINT - A small integer that can be signed or unsigned. If signed, the allowable range is from -32768 to 32767. If unsigned, the allowable range is from 0 to 65535. You can specify a width of up to 5 digits. - MEDIUMINT - A medium-sized integer that can be signed or unsigned. If signed, the allowable range is from -8388608 to 8388607. If unsigned, the allowable range is from 0 to 16777215. You can specify a width of up to 9 digits. - BIGINT - A large integer that can be signed or unsigned. If signed, the allowable range is from -9223372036854775808 to 9223372036854775807. If unsigned, the allowable range is from 0 to 18446744073709551615. You can specify a width of up to 20 digits. - FLOAT(M,D) - A floating-point number that cannot be unsigned. You can define the display length (M) and the number of decimals (D). This is not required and will default to 10,2, where 2 is the number of decimals and 10 is the total number of digits (including decimals). Decimal precision can go to 24 places for a FLOAT. - DOUBLE(M,D) - A double precision floating-point number that cannot be unsigned. You can define the display length (M) and the number of decimals (D). This is not required and will default to 16,4, where 4 is the number of decimals. Decimal precision can go to 53 places for a DOUBLE. REAL is a synonym for DOUBLE. - DECIMAL(M,D) - An unpacked floating-point number that cannot be unsigned. In unpacked decimals, each decimal corresponds to one byte. Defining the display length (M) and the number of decimals (D) is required. NUMERIC is a synonym for DECIMAL. - Date and Time Types: The MySQL date and time datatypes are: - DATE - A date in YYYY-MM-DD format, between 1000-01-01 and 9999-12-31. For example, December 30th, 1973 would be stored as 1973-12-30. - DATETIME - A date and time combination in YYYY-MM-DD HH:MM:SS format, between 1000-01-01 00:00:00 and 9999-12-31 23:59:59. For example, 3:30 in the afternoon on December 30th, 1973 would be stored as 1973-12-30 15:30:00. - TIMESTAMP - A timestamp between midnight, January 1, 1970 and sometime in 2037. This looks like the previous DATETIME format, only without the hyphens between numbers; 3:30 in the afternoon on December 30th, 1973 would be stored as 19731230153000 ( YYYYMMDDHHMMSS ). - TIME - Stores the time in HH:MM:SS format. - YEAR(M) - Stores a year in 2-digit or 4-digit format. If the length is specified as 2 (for example YEAR(2)), YEAR can be 1970 to 2069 (70 to 69). If the length is specified as 4, YEAR can be 1901 to 2155. The default length is 4. - String Types: Although numeric and date types are fun, most data you'll store will be in string format. This list describes the common string datatypes in MySQL. - CHAR(M) - A fixed-length string between 1 and 255 characters in length (for example CHAR(5)), right-padded with spaces to the specified length when stored. Defining a length is not required, but the default is 1. - VARCHAR(M) - A variable-length string between 1 and 255 characters in length; for example VARCHAR(25). You must define a length when creating a VARCHAR field. - BLOB or TEXT - A field with a maximum length of 65535 characters. BLOBs are \"Binary Large Objects\" and are used to store large amounts of binary data, such as images or other types of files. Fields defined as TEXT also hold large amounts of data; the difference between the two is that sorts and comparisons on stored data are case sensitive on BLOBs and are not case sensitive in TEXT fields. You do not specify a length with BLOB or TEXT. - TINYBLOB or TINYTEXT - A BLOB or TEXT column with a maximum length of 255 characters. You do not specify a length with TINYBLOB or TINYTEXT. - MEDIUMBLOB or MEDIUMTEXT - A BLOB or TEXT column with a maximum length of 16777215 characters. You do not specify a length with MEDIUMBLOB or MEDIUMTEXT. - LONGBLOB or LONGTEXT - A BLOB or TEXT column with a maximum length of 4294967295 characters. You do not specify a length with LONGBLOB or LONGTEXT. - ENUM - An enumeration, which is a fancy term for list. When defining an ENUM, you are creating a list of items from which the value must be selected (or it can be NULL). For example, if you wanted your field to contain \"A\" or \"B\" or \"C\", you would define your ENUM as ENUM ('A', 'B', 'C') and only those values (or NULL) could ever populate that field. Source: http://www.tutorialspoint.com/mysql/mysql-data-types.htm","title":"MySQL Data Types:"},{"location":"mysql/#alter-table","text":"","title":"Alter Table:"},{"location":"mysql/#alter-table-column-change-and-modify","text":"CHANGE allows you to rename a column and change the definition. MODIFY allows you to change the definition (cannot rename). Rename a table column named tasklist to entry: ALTER TABLE tablename CHANGE tasklist entry MEDIUMTEXT NOT NULL; Alter the column definition: alter table tablename modify column1 timestamp not null default current_timestamp on update current_timestamp; Alter the table field type and comment: ALTER TABLE `weapons` CHANGE `active_ind` `active_ind` TINYINT( 1 ) UNSIGNED NOT NULL DEFAULT '0' COMMENT '1 Disposed, 0 Not Disposed';","title":"Alter Table Column (CHANGE and MODIFY):"},{"location":"mysql/#alter-table-add","text":"Adding columns to a table. Adding a single colum to a table: ALTER TABLE tablename add column columnname varchar(100) not null after id; Making a column unique: ALTER TABLE tablename add unique (column1); Giving the unique index a name: ALTER TABLE tablename add unique idx_uniquename (column1); Multi-column unique index with a name: Source: https://stackoverflow.com/questions/635937/how-do-i-specify-unique-constraint-for-multiple-columns-in-mysql ALTER TABLE `tablename` add unique `idx_unique_index_name`(`column1`, `column2`, `column3`);","title":"Alter Table (Add):"},{"location":"mysql/#alter-table-move-a-column","text":"``` ALTER TABLE `tablename` CHANGE `columnname` `columname` INT(11) NOT NULL AFTER `someothercolumnname`; ``` - Example: Move the lastname column after the firstname column in the customers table. ``` ALTER TABLE `customers` CHANGE `lastname` `lastname` INT(11) NOT NULL AFTER `firstname`; ```","title":"Alter Table (Move a column):"},{"location":"mysql/#create-a-unique-index-with-a-name-and-a-comment-mysql-v8","text":"Try to use idx for beginning of index name. Syntax: Create unique index: CREATE UNIQUE INDEX `idx_videos_videoname` ON `videos`.`videos` (videoname) COMMENT 'Unique videoname' ALGORITHM DEFAULT LOCK DEFAULT ** You might get ERROR 1062 Duplicate entry '' for key ??? if the column you are trying to make unique, already has duplicate data. This includes NULL and spaces. ** Removing the unique index. Syntax: Notice the missing parenthesis: ALTER TABLE tablename drop index column1;","title":"Create a unique index with a name and a comment (MySQL v8):"},{"location":"mysql/#remove-the-primary-key","text":"Without an index, maintaining an autoincrement column becomes too expensive, that's why MySQL requires an autoincrement column to be a leftmost part of an index. Syntax: You should remove the autoincrement property before dropping the key: ALTER TABLE tablename MODIFY id INT NOT NULL; -- Removing autoincrement. ALTER TABLE tablename DROP PRIMARY KEY;","title":"Remove the primary key:"},{"location":"mysql/#set-field-value-to-default-to-nothing-instead-of-null","text":"alter table customers modify address2 varchar(100) null default \"\";","title":"Set field value to default to nothing instead of NULL:"},{"location":"mysql/#rename-a-mysql-table","text":"The \"to\" keyword is part of the command. Syntax: rename table oldtable to newtable;","title":"Rename a MySQL table:"},{"location":"mysql/#rename-a-database","text":"For InnoDB, the following seems to work: create the new empty database, then rename each table and turn into the new database: Syntax: RENAME TABLE old_db.table TO new_db.table; You will need to adjust the permissions after that. For scripting in a shell, you can use either of the following: This: mysql -u username -ppassword old_db -sNe 'show tables' | while read table; \\ do mysql -u username -ppassword -sNe \"rename table old_db.$table to new_db.$table\"; done Or: for table in `mysql -u root -s -N -e \"show tables from old_db\"\\`; do mysql -u root -s -N -e \"rename table old_db.$table to new_db.$table\"; done;` Note: there is no space between the option -p and the password. If your database user has no password, remove the -u username -ppassword part. If you have stored procedures, you can copy them afterward:","title":"Rename a Database:"},{"location":"mysql/#alter-user","text":"","title":"Alter User:"},{"location":"mysql/#change-password-lock-and-unlock-accounts","text":"use mysql; -- Method 1 (Deprecated): update mysql.user set password(\"thepassword123\") where user = 'hillc'; FLUSH PRIVILEGES; -- Method 2 (MySQL 5.7+): update mysql.user set authentication_string=PASSWORD(\"thepassword123\") where user='hillc'; FLUSH PRIVILEGES; -- Method 3 (Preferred method for current user.): alter user set password = \"thepassword123\"; FLUSH PRIVILEGES; -- MySQL 5.7: alter user 'hillc'@'localhost' identified by \"thepassword123\"; alter user 'hillc'@'%' identified by \"thepassword123\"; -- Method 4 (Preferred method for another user.): alter user set password for 'hillc'@'localhost' = \"thepassword123\"; FLUSH PRIVILEGES; -- Remote user password change: alter user set password for 'hillc'@'%' = \"thepassword123\"; FLUSH PRIVILEGES; -- ALTER USER == ERROR 1820 (HY000): You must reset your password using ALTER USER statement before executing this statement. --If you started MySQL using \"mysql -u root -p\" use this method to reset your password: ALTER USER 'root'@'localhost' IDENTIFIED BY 'Your New Password'; -- This worked for me from the MySQL DB prompt: SET PASSWORD = PASSWORD(\"your_new_password\"); -- Source: http://stackoverflow.com/questions/33467337/reset-mysql-root-password-using-alter-user-statement-after-install-on-mac -- This syntax enables changing your own password without naming your account literally. ALTER USER USER() IDENTIFIED BY \"auth_string\"; -- This statement changes the password for jeffrey but leaves that for jeanne unchanged. For both accounts, connections are required to use SSL and -- each account can be used for a maximum of two simultaneous connections: ALTER USER 'jeffrey'@'localhost' IDENTIFIED BY \"new_password\", 'jeanne'@'localhost' REQUIRE SSL WITH MAX_USER_CONNECTIONS 2; -- Example 1: Change an account's password and expire it. As a result, the user must connect with the named password and choose a new one at the next connection: ALTER USER 'jeffrey'@'localhost' IDENTIFIED BY \"new_password\" PASSWORD EXPIRE; -- Example 2: Modify an account to use the sha256_password authentication plugin and the given password. Require that a new password be chosen every 180 days: ALTER USER 'jeffrey'@'localhost' IDENTIFIED WITH sha256_password BY \"new_password\" (SHA256 may require an SSL connection on some systems) PASSWORD EXPIRE INTERVAL 180 DAY; -- Example 3: Lock or unlock an account: ALTER USER 'jeffrey'@'localhost' ACCOUNT LOCK; ALTER USER 'jeffrey'@'localhost' ACCOUNT UNLOCK; -- Example 4: Require an account to connect using SSL and establish a limit of 20 connections per hour: ALTER USER 'jeffrey'@'localhost' REQUIRE SSL WITH MAX_CONNECTIONS_PER_HOUR 20; -- http://dev.mysql.com/doc/refman/5.7/en/alter-user.html -- Lock User Account on MySQL 8.0.x.x.: UPDATE `user` SET `account_locked` = 'Y' WHERE `user`.`Host` = 'localhost' AND `user`.`User` = 'robdba5'; -- Solution for - Connect Error: SQLSTATE[HY000] [2054] The server requested authentication method unknown to the client. -- Change the authentication method from auth_socket to mysql_native_password: ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY \"password\"; -- Switch to caching_sha2_password authentication for MySQL 8 upgrades: ALTER USER 'umptyfratz'@'%' IDENTIFIED WITH caching_sha2_password BY \"password\"; ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY \"password\";","title":"Change Password / Lock and Unlock Accounts:"},{"location":"mysql/#show-create-user","text":"show create user billybob@localhost;","title":"Show create user:"},{"location":"mysql/#blob-text-data-display-using-convertfield-using-utf8mb4","text":"-- I used this in my bacula database to find jobs that contained the file groupmems. SELECT DISTINCT Job.JobId as JobId, convert(Client.Name using utf8mb4) as Client, convert(Path.Path using utf8mb4),convert(File.FileName using utf8mb4),StartTime,Level,JobFiles,JobBytes FROM Client,Job,File,Path WHERE Client.ClientId=Job.ClientId AND JobStatus IN ('T','W') AND Job.JobId=File.JobId AND Path.PathId=File.PathId AND convert(File.FileName using utf8mb4) = 'groupmems' AND File.FileIndex > 0 -- AND Job.JobId = 16 ORDER BY Job.StartTime;","title":"Blob (text) data display using convert(FIELD using utf8mb4):"},{"location":"mysql/#char_length","text":"","title":"CHAR_LENGTH:"},{"location":"mysql/#needed-to-find-out-the-maximum-length-of-each-column-so-that-i-could-dynamically-adjust-the-column-width-in-pdf-output-this-shows-the-maximum-length-of-the-manufacturer_importer-column","text":"select inventory_number, manufacturer_importer, max(char_length(`manufacturer_importer`)) Number_of_Characters from vw_ffl_book2 group by manufacturer_importer, inventory_number order by Number_of_Characters desc;","title":"Needed to find out the maximum length of each column so that I could dynamically adjust the column width in PDF output. This shows the maximum length of the manufacturer_importer column."},{"location":"mysql/#this-shows-me-the-maximum-length-of-the-model-column-from-highest-to-lowest","text":"select model, max(char_length(`model`)) Number_of_Characters from vw_ffl_book2 group by model order by Number_of_Characters desc;","title":"This shows me the maximum length of the model column from highest to lowest."},{"location":"mysql/#concatinate","text":"This is a query that I used to sequentially rename some video files so they would be in the correct order. I accidentally numbered them 1 to 32 and they were in alphabetical order instead of chronological order. I had to renumber them so they would be in chronolocial order: I used the concat and substring_index functions: select concat('mv ',oldname,' ',newnum,'.',substring_index(oldname,'.',-2)) as Rename_Script from v_rename; Concatenate multiple MySQL rows into one field? You can use GROUP_CONCAT: SELECT person_id, GROUP_CONCAT(hobbies SEPARATOR ', ') FROM peoples_hobbies GROUP BY person_id; As Ludwig stated in his comment, you can add the DISTINCT operator to avoid duplicates: SELECT person_id, GROUP_CONCAT(DISTINCT hobbies SEPARATOR ', ') FROM peoples_hobbies GROUP BY person_id; As Jan stated in their comment, you can also sort the values before imploding it using ORDER BY: SELECT person_id, GROUP_CONCAT(hobbies ORDER BY hobbies ASC SEPARATOR ', ') FROM peoples_hobbies GROUP BY person_id; As Dag stated in his comment, there is a 1024 byte limit on the result. To solve this, run this query before your query: SET group_concat_max_len = 2048; Of course, you can change 2048 according to your needs. To calculate and assign the value: SET group_concat_max_len = CAST( (SELECT SUM(LENGTH(hobbies)) + COUNT(*) * LENGTH(', ') FROM peoples_hobbies GROUP BY person_id) AS UNSIGNED ); Source: https://stackoverflow.com/questions/276927/can-i-concatenate-multiple-mysql-rows-into-one-field?rq=1","title":"Concatinate:"},{"location":"mysql/#conditional-update","text":"create table test ( id int not null auto_increment primary key, name varchar(50), age tinyint ) engine = myisam; insert into test (name) values (\"jim\"),(\"john\"),(\"paul\"),(\"mike\"); - The age field is now NULL. select * from test; update test set age = case when name = \"jim\" then 10 when name = \"paul\" then 20 else 30 end; - The age field now has data. select * from test;","title":"Conditional Update:"},{"location":"mysql/#create-a-stored-procedure","text":"","title":"Create a Stored Procedure:"},{"location":"mysql/#create-a-stored-procedure-that-inserts-10-rows","text":"DELIMITER $$ DROP PROCEDURE IF EXISTS insert_ten_rows $$ CREATE PROCEDURE insert_ten_rows () BEGIN DECLARE crs INT DEFAULT 0; WHILE crs < 10 DO INSERT INTO `continent`(`name`) VALUES ('count_'+crs); SET crs = crs + 1; END WHILE; END $$ DELIMITER ;Invoke the procedure: CALL insert_ten_rows();","title":"Create a stored procedure that inserts 10 rows"},{"location":"mysql/#create-users","text":"","title":"Create Users:"},{"location":"mysql/#syntax-definitions","text":"% = remote user localhost = local user on server/computer","title":"Syntax definitions:"},{"location":"mysql/#this-is-my-mysql-create-user-statement","text":"CREATE USER 'monty'@'localhost' IDENTIFIED BY 'some_pass'; -- ALTER USER 'theusername'@'localhost' IDENTIFIED BY 'some_pass'; GRANT ALL PRIVILEGES ON *.* TO 'monty'@'localhost' WITH GRANT OPTION; CREATE USER 'monty'@'%' IDENTIFIED BY 'some_pass'; GRANT ALL PRIVILEGES ON *.* TO 'monty'@'%' WITH GRANT OPTION;","title":"This is my MySQL Create User Statement:"},{"location":"mysql/#this-is-my-mariadb-create-user-and-mysql-create-user-statement","text":"CREATE USER 'SomeUser'@'%'; CREATE USER 'SomeUser'@'localhost'; SET PASSWORD FOR 'SomeUser'@'%' = PASSWORD('SomePassword!'); SET PASSWORD FOR 'SomeUser'@'localhost' = PASSWORD('SomePassword!'); GRANT USAGE ON SomeDatabase.* TO 'SomeUser'@'localhost' GRANT USAGE ON SomeDatabase.* TO 'SomeUser'@'%' REQUIRE NONE WITH MAX_QUERIES_PER_HOUR 0 MAX_CONNECTIONS_PER_HOUR 0 MAX_UPDATES_PER_HOUR 0 MAX_USER_CONNECTIONS 0; GRANT ALL PRIVILEGES ON `SomeDatabase`.* TO 'SomeUser'@'localhost'; GRANT ALL PRIVILEGES ON `SomeDatabase\\_%`.* TO 'SomeUser'@'%'; FLUSH PRIVILEGES; On MariaDB: I got an access denied error when I tried to run the following statement as root. UPDATE mysql.user SET Grant_priv='Y', Super_priv='Y' WHERE User='rob'; FLUSH PRIVILEGES; I had to run the following as root to give myself the \"GRANT\" privilege. (https://stackoverflow.com/questions/8484722/access-denied-for-user-rootlocalhost-while-attempting-to-grant-privileges) Note that we use `%`.* instead of *.* <-- The backticks are needed. Website example: GRANT ALL PRIVILEGES ON `%`.* TO '[user]'@'[hostname]' IDENTIFIED BY '[password]' WITH GRANT OPTION; I ran it without the password section because I already have an established password: GRANT ALL PRIVILEGES ON `%`.* TO 'rob'@'localhost' WITH GRANT OPTION; GRANT ALL PRIVILEGES ON *.* TO 'rob'@'%' WITH GRANT OPTION; MySQL 8.0.X.X. Create user with mysql_native_password authentication; CREATE USER username@localhost identified with mysql_native_password by 'password';","title":"This is my MariaDB Create User and MySQL Create User Statement."},{"location":"mysql/#vps-on-godaddy","text":"CREATE USER 'theusername'@'localhost'; ALTER USER 'theusername'@'localhost' IDENTIFIED BY 'thePa55word!' -- MySQL GRANT USAGE ON thedatabase.* TO 'theusername'@'localhost'; GRANT ALL PRIVILEGES ON `thedatabase`.* TO 'theusername'@'localhost'; GRANT ALL PRIVILEGES ON `thedatabase\\_%`.* TO 'theusername'@'localhost';","title":"VPS on Godaddy;"},{"location":"mysql/#datatypes-example","text":"--Create a table with all of the MySQL datatypes. CREATE TABLE`all_data_types` ( `bigint` BIGINT, `binary` BINARY( 20 ), `blob` BLOB, `bool` BOOL, `char` CHAR( 10 ), `date` DATE, `datetime` DATETIME, `decimal` DECIMAL( 10, 2 ), `double` DOUBLE, `enum` ENUM( '1', '2', '3' ), `float` FLOAT( 10, 2 ), `int` INT, `longblob` LONGBLOB, `longtext` LONGTEXT, `mediumblob` MEDIUMBLOB, `mediumint` MEDIUMINT, `mediumtext` MEDIUMTEXT, `set` SET( '1', '2', '3' ), `smallint` SMALLINT, `text` TEXT, `timestamp` TIMESTAMP, `time` TIME, `tinyblob` TINYBLOB, `tinyint` TINYINT, `tinytext` TINYTEXT, `varbinary` VARBINARY( 20 ), `varchar` VARCHAR( 20 ), `year` YEAR ) ENGINE= innodb ;","title":"Datatypes Example:"},{"location":"mysql/#date-fields","text":"MySQL Reference Manual - Date Time Functions Date Add: mysql> SELECT DATE_ADD('2018-05-01',INTERVAL 1 DAY); -> '2018-05-02' mysql> SELECT DATE_SUB('2018-05-01',INTERVAL 1 YEAR); -> '2017-05-01' mysql> SELECT DATE_ADD('2020-12-31 23:59:59', -> INTERVAL 1 SECOND); -> '2021-01-01 00:00:00' mysql> SELECT DATE_ADD('2018-12-31 23:59:59', -> INTERVAL 1 DAY); -> '2019-01-01 23:59:59' mysql> SELECT DATE_ADD('2100-12-31 23:59:59', -> INTERVAL '1:1' MINUTE_SECOND); -> '2101-01-01 00:01:00' mysql> SELECT DATE_SUB('2025-01-01 00:00:00', -> INTERVAL '1 1:1:1' DAY_SECOND); -> '2024-12-30 22:58:59' mysql> SELECT DATE_ADD('1900-01-01 00:00:00', -> INTERVAL '-1 10' DAY_HOUR); -> '1899-12-30 14:00:00' mysql> SELECT DATE_SUB('1998-01-02', INTERVAL 31 DAY); -> '1997-12-02' mysql> SELECT DATE_ADD('1992-12-31 23:59:59.000002', -> INTERVAL '1.999999' SECOND_MICROSECOND); -> '1993-01-01 00:00:01.000001' Date Difference: mysql> SELECT DATEDIFF('2007-12-31 23:59:59','2007-12-30'); -> 1 mysql> SELECT DATEDIFF('2010-11-30 23:59:59','2010-12-31'); -> -31 select year(date_field) as year from table;","title":"Date fields:"},{"location":"mysql/#difference-between-datetime-and-timestamp","text":"--The timestamp data type has a limitation between the years 1970 and 2038. --Use datetime instead. If you need a timestamp you can set the default to current_timestamp. --See the updt_dt_tm and cr_date fields in the table below. CREATE TABLE `test1` ( `id` int(11) NOT NULL AUTO_INCREMENT, `firstname` varchar(100) NOT NULL, `lastname` varchar(100) NOT NULL, `updt_dt_tm` datetime DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP, `cr_date` datetime DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=latin1; --Date Format: http://www.mysqltutorial.org/mysql-date/ -- Alter table and add a datetime column that defaults to the current timestamp. alter table code_value add column updt_dt_tm datetime not null default current_timestamp on update current_timestamp;","title":"Difference between DATETIME and TIMESTAMP:"},{"location":"mysql/#definer-change","text":"","title":"DEFINER Change:"},{"location":"mysql/#changeupdate-definer","text":"1. Change the DEFINER This is possibly easiest to do when initially importing your database objects, by removing any DEFINER statements from the dump. Changing the definer later is a little more tricky: How to change the definer for views Run this SQL to generate the necessary ALTER statements SELECT CONCAT(\"ALTER DEFINER=`youruser`@`host` VIEW \", table_name, \" AS \", view_definition, \";\") FROM information_schema.views WHERE table_schema='your-database-name'; Copy and run the ALTER statements How to change the definer for stored procedures Example: UPDATE `mysql`.`proc` p SET definer = 'user@%' WHERE definer='root@%' Be careful, because this will change all the definers for all databases. 2. Create the missing user If you've found following error while using MySQL database: The user specified as a definer ('someuser'@'%') does not exist` Then you can solve it by using following : GRANT ALL ON *.* TO 'someuser'@'%' IDENTIFIED BY 'complex-password'; FLUSH PRIVILEGES; From http://www.lynnnayko.com/2010/07/mysql-user-specified-as-definer-root.html This worked like a charm - you only have to change someuser to the name of the missing user. On a local dev server, you might typically just use root. Also consider whether you actually need to grant the user ALL permissions or whether they could do with less. ******************** select concat(\"ALTER DEFINER=`rlholland1`@`localhost` VIEW \", weapons, \" AS \" , view_definition, \";\") FROM information_schema.views where table_schema=\"hillc1\";","title":"Change/Update DEFINER:"},{"location":"mysql/#drop","text":"","title":"DROP"},{"location":"mysql/#drop-a-database","text":"drop database `TheDataBaseName`;","title":"Drop a database:"},{"location":"mysql/#drop-a-table","text":"drop table `TheTablename`;","title":"Drop a table;"},{"location":"mysql/#drop-an-index","text":"alter TheTableName drop `TheIndexName`;","title":"Drop an index:"},{"location":"mysql/#in-mysql-theres-no-drop-constraint-you-have-to-use-drop-foreign-key-instead","text":"ALTER TABLE `table_name` DROP FOREIGN KEY `id_name_fk`; You might have to drop the index too because simply removing the foreign key does not remove the index. ALTER TABLE `table_name` DROP INDEX `id_name_fk`; An alternative to temporarily disable all the foreign keys: SET FOREIGN_KEY_CHECKS=0; When you need to turn it on: SET FOREIGN_KEY_CHECKS=1;","title":"** In MySQL, there\u001as no DROP CONSTRAINT, you have to use DROP FOREIGN KEY instead:"},{"location":"mysql/#dump-a-database","text":"","title":"Dump a Database:"},{"location":"mysql/#dump-and-rename","text":"mysqldump -R old_db | mysql new_db or just dump the database and import the file into a new database name: mysqldump -p -c -e TheNameOfTheDatabase > The_Name_of_the_Dump.sql To import from the MySQL command prompt type: source The_Name_of_the_Dump.sql or \\. The_Name_of_the_Dump.sql","title":"Dump and rename:"},{"location":"mysql/#dump-a-table","text":"mysqldump -p -c -e TheNameOfTheDatabase TheNameOfTheTable > The_Name_of_the_Dump.sql","title":"Dump a Table:"},{"location":"mysql/#dump-a-single-database","text":"mysqldump -p -c -e TheNameOfTheDatabase > The_Name_of_the_Dump.sql","title":"Dump a single Database:"},{"location":"mysql/#dump-all-databases-on-the-server-to-a-file","text":"mysqldump -p -c -e --all-databases > The_Name_of_the_Dump.sql","title":"Dump All Databases on the Server to a file:"},{"location":"mysql/#backup-shell-script-to-create-a-timestamped-database-dump","text":"Script Name: dbdump.sh DBuser=SomeUser DBname=SomeDatabase TimeStamp=`date +\"%Y%m%d%H%M%S%Z\"` mysqldump -u$SomeUser -p -c -e $DBname > $TimeStamp.DBDump.$DBname.`hostname`.sql echo \"Compressing Database Dump. Please wait...\" tar -zcvf $TimeStamp.DBDump.$DBname.`hostname`.sql.gz $TimeStamp.DBDump.$DBname.`hostname`.sql","title":"Backup shell script to create a timestamped database dump:"},{"location":"mysql/#duplicate-data","text":"","title":"Duplicate Data:"},{"location":"mysql/#find-duplicate-data-in-a-column","text":"SELECT column1, COUNT(*) c FROM tablename GROUP BY column1 HAVING c > 1;","title":"Find duplicate data in a column."},{"location":"mysql/#enable-remote-connections-for-a-specific-ip-address","text":"","title":"Enable remote connections for a specific IP address:"},{"location":"mysql/#create-a-database-create-database-user-and-enable-remote-connections-for-that-user-from-a-specific-ip-address","text":"-- Example: /* DB_NAME = webdb USER_NAME = webdb_user REMOTE_IP = 10.0.15.25 PASSWORD = password123 PERMISSIONS = ALL */ -- CREATE DATABASE ## -- MariaDB [(none)]> CREATE DATABASE webdb; -- CREATE USER ## -- MariaDB [(none)]> CREATE USER 'webdb_user'@'10.0.15.25' IDENTIFIED BY 'password123'; -- GRANT PERMISSIONS ## -- MariaDB [(none)]> GRANT ALL ON webdb.* TO 'webdb_user'@'10.0.15.25'; -- FLUSH PRIVILEGES, Tell the server to reload the grant tables ## -- MariaDB [(none)]> FLUSH PRIVILEGES;","title":"Create a database, create database user, and enable remote connections for that user from a specific IP address."},{"location":"mysql/#enum","text":"","title":"ENUM:"},{"location":"mysql/#definition","text":"ENUM is a good choice for boolean type of fields except that it is treated as a string and not an integer. In this case I just want to set a column in the table to indicate whether the row is active (1) or not (0). I do not want someone to accidentally enter a 2, 3, etc. in the field. Source: http://komlenic.com/244/8-reasons-why-mysqls-enum-data-type-is-evil/ alter table healthtemperature1 add column active_ind enum('0','1') not null;","title":"Definition:"},{"location":"mysql/#event","text":"","title":"Event:"},{"location":"mysql/#creating-events","text":"http://stackoverflow.com/questions/10314806/mysql-triggers-deleting-a-row-after-inactivity First, do not put this update/delete in a trigger, you are going to see a huge performance hit if there are millions of rows. Instead, you can create a cron job or if you want to keep it all in MySQL use the MySQL Event scheduler. Go to this page to read more about scheduling events in MySQL: http://dev.mysql.com/doc/refman/5.1/en/events.html MySQL Event allows you to schedule things on MySQL on a regular basis. The code would look something like: CREATE EVENT myevent ON SCHEDULE AT CURRENT_TIMESTAMP + INTERVAL 1 HOUR DO DELETE FROM MyTable Where Expired< NOW(); Example updates the state column to 1 if it is older than 24 hours. Check a table every hour and update a column that is 24 hours old: CREATE EVENT reset ON SCHEDULE EVERY 1 HOUR DO update T1 set state=1 where time < date_sub(now(),interval 24 hour) and (state=0 or state=2) ; CREATE EVENT reset ON SCHEDULE EVERY 1 HOUR DO update test set state=1 where time < date_sub(now(),interval 24 hour) and (state=0 or state=2); Create Event Source: https://dba.stackexchange.com/questions/56424/column-auto-updated-after-24-hours-in-mysql","title":"Creating Events:"},{"location":"mysql/#foreign-keys","text":"","title":"Foreign Keys:"},{"location":"mysql/#add-foreign-key-constraint","text":"alter table TableName add constraint TheConstraintName foreign key (CurrentTableColumnName) references ForeignTable(ColumnName) on update cascade on delete restrict; *If you do not give the constraint a name, then one will be automatically generated. *Sometimes you will see a message \"Check DataType\" if the two columns are not exactly the same or there is a duplicate constraint name. Casecade only works if foreign_key_checks is ON. To see this information type: show variables like 'foreign_key_checks'; If you want to see all variables type: show variables;","title":"Add foreign key constraint:"},{"location":"mysql/#display-foreign-key-references","text":"-- To run from the command prompt type: -- mysql -u rob -p < display_foreign_key_references.sql > current_fk_refs.txt","title":"Display Foreign Key References:"},{"location":"mysql/#show-constraints-for-all-databases-on-the-server","text":"use INFORMATION_SCHEMA; select concat(`kcu`.`TABLE_SCHEMA`,'.',`kcu`.`TABLE_NAME`,'.',`kcu`.`COLUMN_NAME`) AS `This_DB_Table_and_Column` ,concat(`kcu`.`TABLE_SCHEMA`,'.',`kcu`.`REFERENCED_TABLE_NAME`,'.',`kcu`.`REFERENCED_COLUMN_NAME`) AS `References_This_DB_Table_and_Column` ,`kcu`.`CONSTRAINT_NAME` AS `CONSTRAINT_NAME` ,`rc`.`UPDATE_RULE` AS `update_rule` ,`rc`.`DELETE_RULE` AS `delete_rule` from (`information_schema`.`KEY_COLUMN_USAGE` `kcu` join `information_schema`.`referential_constraints` `rc` on(`kcu`.`TABLE_NAME` = `rc`.`TABLE_NAME`)) where `kcu`.`REFERENCED_TABLE_NAME` is not null order by concat(`kcu`.`TABLE_SCHEMA`,'.',`kcu`.`TABLE_NAME`,'.',`kcu`.`COLUMN_NAME`);","title":"# Show constraints for all databases on the server:"},{"location":"mysql/#show-constraints-for-specific-database","text":"use INFORMATION_SCHEMA; select distinct concat(`kcu`.`TABLE_SCHEMA`,'.',`kcu`.`TABLE_NAME`,'.',`kcu`.`COLUMN_NAME`) AS `This_DB_Table_and_column` ,concat(`kcu`.`TABLE_SCHEMA`,'.',`kcu`.`REFERENCED_TABLE_NAME`,'.',`kcu`.`REFERENCED_COLUMN_NAME`) AS `References_This_DB_Table_and_Column` ,`kcu`.`CONSTRAINT_NAME` AS `constraint_name` ,`rc`.`UPDATE_RULE` AS `update_rule` ,`rc`.`DELETE_RULE` AS `delete_rule` from (`information_schema`.`KEY_COLUMN_USAGE` `kcu` join `information_schema`.`REFERENTIAL_CONSTRAINTS` `rc` on(`kcu`.`TABLE_NAME` = `rc`.`TABLE_NAME`)) where `kcu`.`REFERENCED_TABLE_NAME` is not null and `kcu`.`TABLE_SCHEMA` = 'YOURDATABASENAME' order by This_DB_Table_and_column;","title":"# Show constraints for specific database:"},{"location":"mysql/#show-constraints-for-all-databases","text":"create VIEW `vw_fk_global_constraints` AS select distinct concat(`kcu`.`TABLE_SCHEMA`,'.',`kcu`.`TABLE_NAME`,'.',`kcu`.`COLUMN_NAME`) AS `This_DB_Table_and_Column` ,concat(`kcu`.`TABLE_SCHEMA`,'.',`kcu`.`REFERENCED_TABLE_NAME`,'.',`kcu`.`REFERENCED_COLUMN_NAME`) AS `References_This_DB_Table_and_Column` ,`kcu`.`CONSTRAINT_NAME` AS `CONSTRAINT_NAME` ,`rc`.`UPDATE_RULE` AS `update_rule` ,`rc`.`DELETE_RULE` AS `delete_rule` from ( `information_schema`.`KEY_COLUMN_USAGE` `kcu` join `information_schema`.`referential_constraints` `rc` on(`kcu`.`TABLE_NAME` = `rc`.`TABLE_NAME`)) where `kcu`.`REFERENCED_TABLE_NAME` is not null order by concat(`kcu`.`TABLE_SCHEMA`,'.',`kcu`.`TABLE_NAME`,'.',`kcu`.`COLUMN_NAME` ); -- This is a quick way to view all of the constraints: SELECT * FROM information_schema.REFERENTIAL_CONSTRAINTS; -- This is a quick way to view constraints from a specific database: select * from information_schema.referential_constraints where constraint_schema = 'thedatabasename'; Source: https://www.youtube.com/watch?v=UQK9_gKQHZg","title":"# Show constraints for all databases:"},{"location":"mysql/#generated-columns","text":"The syntax for defining a generated column is as follows: column_name data_type [GENERATED ALWAYS] AS (expression) [VIRTUAL | STORED] [UNIQUE [KEY]] First, specify the column name and its data type. Next, add the GENERATED ALWAYS clause to indicate that the column is a generated column. Then, indicate whether the type of the generated column by using the corresponding option: VIRTUAL or STORED. By default, MySQL uses VIRTUAL if you don\u001at specify explicitly the type of the generated column. After that, specify the expression within the braces after the AS keyword. The expression can contain literals, built-in functions with no parameters, operators, or references to any column within the same table. If you use a function, it must be scalar and deterministic. Finally, if the generated column is stored, you can define a unique constraint for it. Generated column: Columns are generated because the data in these columns are computed based on predefined expressions. Basically, the columns are generated on the fly based on the data that already exists in the table. Virtual Column: The \"fullname\" column is Virtual by default because the generated column type was not specified. DROP TABLE IF EXISTS contacts; CREATE TABLE contacts ( id INT AUTO_INCREMENT PRIMARY KEY, first_name VARCHAR(50) NOT NULL, last_name VARCHAR(50) NOT NULL, fullname varchar(101) GENERATED ALWAYS AS (CONCAT(first_name,' ',last_name)), email VARCHAR(100) NOT NULL ); MySQL provides two types of generated columns: stored and virtual. The virtual columns are calculated on the fly each time data is read whereas the stored column are calculated and stored physically when the data is updated. Based on this definition, the fullname column in the example above is a virtual column. Stored Column: (If the generated column is stored, you can define a unique constraint for it.) ALTER TABLE products ADD COLUMN stockValue DOUBLE GENERATED ALWAYS AS (buyprice*quantityinstock) STORED;","title":"Generated Columns"},{"location":"mysql/#grant","text":"","title":"Grant:"},{"location":"mysql/#grant-privileges","text":"grant all on *.* to 'rob'@'localhost'; show grants for 'root'@'localhost'; show grants for 'rob'@'localhost'; MySQL 8.0.X.X. Grant superuser privileges: use mysql; UPDATE `user` SET `Select_priv` = 'Y', `Insert_priv` = 'Y', `Update_priv` = 'Y', `Delete_priv` = 'Y', `Create_priv` = 'Y', `Drop_priv` = 'Y', `Reload_priv` = 'Y', `Shutdown_priv` = 'Y', `Process_priv` = 'Y', `File_priv` = 'Y', `Grant_priv` = 'Y', `References_priv` = 'Y', `Index_priv` = 'Y', `Alter_priv` = 'Y', `Show_db_priv` = 'Y', `Super_priv` = 'Y', `Create_tmp_table_priv` = 'Y', `Lock_tables_priv` = 'Y', `Execute_priv` = 'Y', `Repl_slave_priv` = 'Y', `Repl_client_priv` = 'Y', `Create_view_priv` = 'Y', `Show_view_priv` = 'Y', `Create_routine_priv` = 'Y', `Alter_routine_priv` = 'Y', `Create_user_priv` = 'Y', `Event_priv` = 'Y', `Trigger_priv` = 'Y', `Create_tablespace_priv` = 'Y', `Create_role_priv` = 'Y', `Drop_role_priv` = 'Y' WHERE `user`.`Host` = '%' AND `user`.`User` = 'rob'; https://lefred.be/content/how-to-grant-privileges-to-users-in-mysql-8-0/ Grant Privileges for a user to a database; grant alter,create,delete,drop,index,insert,select,update,trigger,alter routine, create routine, execute, create temporary tables on user1.* to 'user1'; grant alter,create,delete,drop,index,insert,select,update,trigger,alter routine, create routine, execute, create temporary tables on hillc1.* to 'theusername'; grant all privileges on thedatabasename.* to 'theusername'@'localhost' with grant option; flush privileges; grant all privileges on thedatabasename.* to 'theusername'@'%' with grant option; flush privileges; grant SELECT, INSERT, UPDATE, DELETE ON SomeDatabase TO 'theusername'@'localhost';","title":"Grant privileges."},{"location":"mysql/#group-by-uses-having-instead-of-where-clause","text":"","title":"Group By: (Uses \"Having\" instead of \"Where\" clause.)"},{"location":"mysql/#find-duplicate-data-in-a-column_1","text":"SELECT column1, COUNT(*) c FROM tablename GROUP BY column1 HAVING c > 1;","title":"Find duplicate data in a column."},{"location":"mysql/#show-number-of-presidents-from-each-state","text":"select state_born State, count(*) Number_of_Presidents from uspresidents group by state having Number_of_Presidents > 0 order by Number_of_Presidents, state;","title":"Show number of presidents from each state."},{"location":"mysql/#if-and-case-statements","text":"","title":"IF and CASE Statements:"},{"location":"mysql/#select-if","text":"There are times where running IF statements inside a query can be useful. MySQL provides a simple way to do this through the use of IF and CASE statements. The IF statement takes three arguments; the conditional, the true value, and the false value. False and true values may be static values or column values. For example: SELECT IF(score >= 100, \"Good Job\", score) AS score FROM exam_results; this will check if the value in the score column is 100 then print \"Good Job\" otherwise print the value of score. IF statements can also be nested: SELECT IF(score >= 100, \"Good Job\", IF(score < 100, \"You Failed!\", score)) score FROM exam_results;","title":"Select If:"},{"location":"mysql/#case-statements-switch-statements-for-those-c-programmers-are-much-like-if-statements-for-example","text":"CREATE TABLE `headcount` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `num_heads` int(11) NOT NULL, `active_ind` int(1) NOT NULL DEFAULT '1', PRIMARY KEY (`id`) ) ENGINE=InnoDB; SELECT CASE num_heads WHEN 0 THEN 'Zombie' WHEN 1 THEN 'Human' ELSE 'Alien' END AS race FROM headcount; This code checks the value in the num_heads column and deduces race from the values presented. CASE statements may also be nested in the same way as IF statements. I used this to prepend a zero in front of values that were less than 10. select concat(\"update yt_video_rename set day = \",if(day<10, concat(\"0\",day),day),\" where id = \", id,\";\") xyz from yt_video_rename order by day; Count the number of presidents from each party: select sum(if(party = 1, 1,0)) as Federalist, sum(if(party = 2, 1,0)) as \"Democratic-Republican\", sum(if(party = 3,1,0)) as Democrat, sum(if(party = 4,1,0)) as Whig, sum(if(party = 5,1,0)) Republican, sum(if(party = 6,1,0)) \"Democratic-Union\", sum(if(party = 7,1,0)) Republican1 from us_presidents; -- Start at 0 and increment by 1 for each party member found.","title":"CASE statements (switch statements for those C programmers) are much like if statements. For example:"},{"location":"mysql/#increment-results-numerically-count-results-good-for-displaying-first-second-third-place","text":"SELECT @n := @n + 1 \"Item#:\", firstname, lastname FROM test, (SELECT @n := 0) m ORDER BY firstname, lastname; My working example: select @n := @n + 1 place, person, medication, dose_unit, admin_dttm, temp_f, temp_c, symptom from vw_healthsummary, (select @n := 0) m order by temp_f desc limit 0, 50; Online Example for SQLServer: SELECT row_number() OVER (ORDER BY first_name, last_name) n, first_name, last_name FROM table1 Source: https://stackoverflow.com/questions/16555454/how-to-generate-auto-increment-field-in-select-query","title":"Increment results numerically (count results). Good for displaying first, second, third place:"},{"location":"mysql/#innodb-vs-myisam","text":"The main differences between InnoDB and MyISAM (\"with respect to designing a table or database\" you asked about) are support for \"referential integrity\" and \"transactions\". If you need the database to enforce foreign key constraints, or you need the database to support transactions (i.e. changes made by two or more DML operations handled as single unit of work, with all of the changes either applied, or all the changes reverted) then you would choose the InnoDB engine, since these features are absent from the MyISAM engine. Those are the two biggest differences. Another big difference is concurrency. With MyISAM, a DML statement will obtain an exclusive lock on the table, and while that lock is held, no other session can perform a SELECT or a DML operation on the table. Those two specific engines you asked about (InnoDB and MyISAM) have different design goals. MySQL also has other storage engines, with their own design goals. So, in choosing between InnoDB and MyISAM, the first step is in determining if you need the features provided by InnoDB. If not, then MyISAM is up for consideration. A more detailed discussion of differences is rather impractical (in this forum) absent a more detailed discussion of the problem space... how the application will use the database, how many tables, size of the tables, the transaction load, volumes of select, insert, updates, concurrency requirements, replication features, etc. The logical design of the database should be centered around data analysis and user requirements; the choice to use a relational database would come later, and even later would the the choice of MySQL as a relational database management system, and then the selection of a storage engine for each table.","title":"InnoDB vs MyISAM:"},{"location":"mysql/#myisam","text":"MYISAM supports Table-level Locking MyISAM designed for need of speed MyISAM does not support foreign keys hence we call MySQL with MYISAM is DBMS MyISAM stores its tables, data and indexes in diskspace using separate three different files. (tablename.FRM, tablename.MYD, tablename.MYI) MYISAM not supports transaction. You cannot commit and rollback with MYISAM. Once you issue a command it\u001as done. MYISAM supports fulltext search You can use MyISAM, if the table is more static with lots of select and less update and delete.","title":"MYISAM:"},{"location":"mysql/#innodb","text":"InnoDB supports Row-level Locking InnoDB designed for maximum performance when processing high volume of data InnoDB support foreign keys hence we call MySQL with InnoDB is RDBMS InnoDB stores its tables and indexes in a tablespace InnoDB supports transaction. You can commit and rollback with InnoDB Source: http://stackoverflow.com/questions/12614541/whats-the-difference-between-myisam-and-innodb","title":"INNODB:"},{"location":"mysql/#insert-into","text":"","title":"Insert Into:"},{"location":"mysql/#insert-into-another-table-from-current-table","text":"First, make an empty version (copy) of a table by using CREATE TABLE. Example: CREATE TABLE secondtable LIKE firsttable; -- This example inserts two columns into the secondtable table from the firsttable table. insert into secondtable (column1, column2) select column1, column2 from firsttable; -- Another method: CREATE TABLE secondtable AS SELECT columns FROM firsttable WHERE conditions;","title":"INSERT INTO ANOTHER TABLE FROM CURRENT TABLE"},{"location":"mysql/#int-vs-bigint","text":"-- http://stackoverflow.com/questions/3135804/types-in-mysql-bigint20-vs-int20-etcc INT is a four-byte signed integer. BIGINT is an eight-byte signed integer. The 20 in INT(20) and BIGINT(20) means almost nothing. It's a hint for display width, it has nothing to do with storage. Practically, it affects only the ZEROFILL option: CREATE TABLE foo ( bar INT(20) ZEROFILL ); INSERT INTO foo (bar) VALUES (1234); SELECT bar from foo; +----------------------+ | bar | +----------------------+ | 00000000000000001234 | +----------------------+ It's a common source of confusion for MySQL users to see INT(20) and assume it's a size limit, something analogous to CHAR(20).","title":"INT vs BIGINT:"},{"location":"mysql/#joins","text":"Left Inner Join Left Join Inner Join Right Inner Join Right Join Full Outer Join Full Inner Join","title":"Joins:"},{"location":"mysql/#join-with-no-where-clause","text":"I have two tables I want to join. I want all of the categories in the categories table and also all of the categories subscribed to by a user in the category_subscriptions table. essentially this is my query so far: SELECT * FROM categories LEFT JOIN user_category_subscriptions ON user_category_subscriptions.category_id = categories.category_id; This works fine however I want to add a where clause on the end of the query which then essentially makes it an inner/equi join. SELECT * FROM categories LEFT JOIN user_category_subscriptions ON user_category_subscriptions.category_id = categories.category_id WHERE user_category_subscriptions.user_id = 1; How do I get all the categories as well as all the categories subscribed to by a particular user using only one query? category_id being a key in both categories table and user_category_subscriptions. user_id residing in the user_category_subscriptions table. thanks","title":"Join with no where clause:"},{"location":"mysql/#join-with-no-where-clause-answer","text":"You need to put it in the join clause, not the where: SELECT * FROM categories LEFT JOIN user_category_subscriptions ON user_category_subscriptions.category_id = categories.category_id and user_category_subscriptions.user_id =1; See, with an inner join, putting a clause in the join or the where is equivalent. However, with an outer join, they are vastly different. As a join condition, you specify the rowset that you will be joining to the table. This means that it evaluates user_id = 1 first, and takes the subset of user_category_subscriptions with a user_id of 1 to join to all of the rows in categories. This will give you all of the rows in categories, while only the categories that this particular user has subscribed to will have any information in the user_category_subscriptions columns. Of course, all other categories will be populated with null in the user_category_subscriptions columns. Conversely, a where clause does the join, and then reduces the rowset. So, this does all of the joins and then eliminates all rows where user_id doesn't equal 1. You're left with an inefficient way to get an inner join.","title":"Join with no where clause ANSWER:"},{"location":"mysql/#last-insert-id","text":"","title":"Last Insert ID:"},{"location":"mysql/#getting-last-insert-id","text":"drop database lastinsert_id; create database lastinsert_id; use lastinsert_id; create table foo (id int(11) auto_increment primary key , text varchar(50) not null)engine=innodb; create table foo2 (id int(11) auto_increment primary key , foo_id int(11) not null, text varchar(50) not null)engine=innodb; -- https://dev.mysql.com/doc/c-api/5.6/en/getting-unique-id.html INSERT INTO foo (id,text) VALUES(NULL,'filename'); # generate ID by inserting NULL INSERT INTO foo2 (id,foo_id,text) VALUES(NULL,LAST_INSERT_ID(),'last_insert_id.sql'); # use ID in second table","title":"Getting Last Insert ID:"},{"location":"mysql/#last-insert-id-using-pdo","text":"-- https://stackoverflow.com/questions/10680943/pdo-get-the-last-id-inserted $stmt = $db->prepare(\"...\"); $stmt->execute(); $id = $db->lastInsertId(); If you want to do it with SQL instead of the PDO API, you would do it like a normal select query: $stmt = $db->query(\"SELECT LAST_INSERT_ID()\"); $lastId = $stmt->fetchColumn();","title":"Last Insert ID Using PDO:"},{"location":"mysql/#load-input-local_infile","text":"insert into cv (id,content) values (\"1\",LOAD_FILE('cv.doc')); MySQL 8.0 has the load data local_infile option off by default. You can enable it by logging into the MySQL server and running: mysql> show global variables like 'local_infile'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | local_infile | OFF | +---------------+-------+ 1 row in set (0.01 sec) mysql> set global local_infile = true; Query OK, 0 rows affected (0.00 sec) mysql> show global variables like 'local_infile'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | local_infile | ON | +---------------+-------+ 1 row in set (0.00 sec) Afterward, you will have to start the MySQL client with: /usr/local/mysql/bin/mysql -u USERNAME -p --local-infile DATABASENAME mysql -u USERNAME -p --local-infile DATABASENAME Source: https://stackoverflow.com/questions/10762239/mysql-enable-load-data-local-infile -- From the MySQL command prompt. -- It is easier to have the file you want to import located in the same directory where you start mysql. Then run load data local infile once you log in. -- I loaded the exported Bedrock .csv files into a database using the following: /* The database and table. create database bedrock; use bedrock; if exist drop table bedrock_csv; create table bedrock_csv (id int(11) unsigned auto_increment primary key, audit_type varchar(500) null, topic_name varchar(500) null, filter_sequence varchar(500) null, filter_meaning varchar(500) null, filter_type_meaning varchar(500) null, filter_name varchar(500) null, flex_display varchar(500) null, saved_value varchar(500) null, description varchar(500) null, event_set_name varchar(500) null, code_value_id varchar(500) null, value_type varchar(500) null, value_sequence varchar(500) null, value_group_sequence varchar(500) null, qualifier varchar(500) null, map_type varchar(500) null, mapped_to_code_1 varchar(500) null, mapped_to_description_1 varchar(500) null, mapped_to_code_2 varchar(500) null, mapped_to_description_2 varchar(500) null, last_update_date_time varchar(500) null, last_update_by varchar(500) null ) engine=innodb; */ -- I combined all of the exported Bedrock .csv files into one large file called allfiles.dat by using sed to remove the first header row. -- Example: sed '1d' Exported_CSV_FILE.csv >> allfiles.dat -- http://unix.stackexchange.com/questions/96226/delete-first-line-of-a-file load data local infile 'allfiles.dat' into table bedrock_csv fields terminated by ',' enclosed by '\"' lines terminated by '\\n' (audit_type, topic_name, filter_sequence, filter_meaning, filter_type_meaning, filter_name, flex_display, saved_value, description, event_set_name, code_value_id, value_type, value_sequence, value_group_sequence, qualifier, map_type, mapped_to_code_1, mapped_to_description_1, mapped_to_code_2, mapped_to_description_2, last_update_date_time, last_update_by); load data infile 'allfiles.dat' replace into table bedrock_csv; -- Using the \"local\" keyword helped me get past the error message: \"The MySQL server is running with the --secure-file-priv option so it cannot execute this statement\". -- https://stackoverflow.com/questions/32737478/how-should-i-tackle-secure-file-priv-in-mysql load data local infile 'US_States.csv' into table us_states fields terminated by '|' lines terminated by '\\n' (state,abbreviation,capital,largest_city,established,population,sq_mi,sq_km,land_area_mi,land_area_km,water_area_mi,water_area_km,representatives); /*Another example: I was stuck on a problem where the ImportXML3.xml file would not get imported into the database because the XML tag names were in different case on some of the lines. Once I made them the same case it was imported. -- This online link was helpful. http://dev.mysql.com/doc/refman/5.5/en/load-xml.html This statement supports three different XML formats: Column names as attributes and column values as attribute values: <row column1=\"value1\" column2=\"value2\" .../> Column names as tags and column values as the content of these tags: <row> <column1>value1</column1> <column2>value2</column2> </row> Column names are the name attributes of <field> tags, and values are the contents of these tags: <row> <field name='column1'>value1</field> <field name='column2'>value2</field> </row> This is the format used by other MySQL tools, such as mysqldump. All three formats can be used in the same XML file; the import routine automatically detects the format for each row and interprets it correctly. Tags are matched based on the tag or attribute name and the column name. */ LOAD XML LOCAL INFILE 'ImportXML3.xml' INTO TABLE xmlimport3 ROWS IDENTIFIED BY '<myfields>'; /*The ImportXML3.xml file looks like this: <rlh> <myfields><lastname>firstname01</lastname><firstname>lastname01</firstname></myfields> <myfields><lastname>firstname02</lastname><firstname>lastname02</firstname></myfields> <myfields><lastname>firstname03</lastname><firstname>lastname03</firstname></myfields> <myfields><lastname>firstname04</lastname><firstname>lastname04</firstname></myfields> <myfields><lastname>firstname05</lastname><firstname>lastname05</firstname></myfields> <myfields><lastname>firstname06</lastname><firstname>lastname06</firstname></myfields> <myfields><lastname>firstname07</lastname><firstname>lastname07</firstname></myfields> <myfields><lastname>firstname08</lastname><firstname>lastname08</firstname></myfields> <myfields><lastname>firstname09</lastname><firstname>lastname09</firstname></myfields> <myfields><lastname>firstname10</lastname><firstname>lastname10</firstname></myfields> <myfields><lastname>firstname11</lastname><firstname>lastname11</firstname></myfields> <myfields><lastname>firstname12</lastname><firstname>lastname12</firstname></myfields> <myfields><lastname>firstname13</lastname><firstname>lastname13</firstname></myfields> <myfields><lastname>firstname14</lastname><firstname>lastname14</firstname></myfields> <myfields><lastname>firstname15</lastname><firstname>lastname15</firstname></myfields> <myfields><lastname>firstname16</lastname><firstname>lastname16</firstname></myfields> <myfields><lastname>firstname17</lastname><firstname>lastname17</firstname></myfields> </rlh> */ I got an error when I tried to load some data exported from an Excel spreadsheet in .csv format. The error message was \"ERROR 1300 (HY000): Invalid utf8mb4 character string:\" I wasn't able to manually correct all of the invalid characters in the .csv file because there were too many. There is a command on Linux called \"file\" that will tell you the file type. When I ran it \"file -i filename.csv\" it displayed a message telling me unknown. file -i mpages1.csv I found a website that suggested that the file might be latin so I used another Linux command called \"iconv\" to convert it from latin to UTF8 and I was able to import the .csv into MySQL. iconv -f latin1 -t utf8 < mpages1.csv > mpages2.csv This worked: (Source: https://unix.stackexchange.com/questions/141539/iconv-illegal-input-sequence-why).","title":"Load input (local_infile):"},{"location":"mysql/#change-database-and-table-collation-and-char-set-to-utf8mb4-and-utf8mb4_unicode_ci","text":"ALTER DATABASE <db_name> CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; ALTER TABLE <table_name> CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; (Source: https://stackoverflow.com/questions/48270374/invalid-datetime-format-1366-incorrect-string-value)","title":"Change database and table collation and char set to utf8mb4 and utf8mb4_unicode_ci.:"},{"location":"mysql/#locate-mysql-database-files","text":"Typically the MySQL database files are located in /usr/local/mysql/data/databasename/ select @@datadir, @@innodb_data_home_dir;","title":"Locate MySQL Database Files:"},{"location":"mysql/#file-locations","text":"SELECT TABLESPACE_NAME, FILE_NAME FROM INFORMATION_SCHEMA.FILES \\G","title":"File locations:"},{"location":"mysql/#natural-sorting-of-numbers","text":"https://stackoverflow.com/questions/8557172/mysql-order-by-sorting-alphanumeric-correctly https://www.copterlabs.com/natural-sorting-in-mysql/ select lastname, firstname, salary, jobtitle, hiredate from payback order by cast(salary as unsigned), salary;","title":"Natural Sorting of Numbers:"},{"location":"mysql/#output-to-a-file","text":"","title":"Output to a file:"},{"location":"mysql/#from-the-mysql-command-prompt","text":"You can create an output file formatted with comma delimiters and fields enclosed by quotes. The mysql user must have privileges to the output file location. select * into outfile 'outputfilename.txt' fields terminated by ',' optionally enclosed by '\"' lines terminated by '\\n' from yourtablename where columnname = 'whatever'; If no path is specified, the file will be located in the default database folder. In my case (Fedora 12) it was located in /var/lib/mysql/thedatabasename/outputfilename.txt. -- You can specify where the output file will go: SELECT id, client, project, task, description, time, date INTO OUTFILE '/path/to/file.csv' --mysql user must have privileges to the location. FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '\"' LINES TERMINATED BY '\\n' FROM ts From outside of the mysql command prompt (ie. the command line) you can also run a query and create an output file with the results of that query. Create a query that you want to run and save it as an .sql file. Example: test.sql The content of the test.sql file looks like this: select * from tablename; To run test.sql type one of the following: -- If you want tab delimited output format (default): mysql databasename -u username -p < test.sql > output.tab Convert the tabs to comma delimited surrounded by quotes: mysql -u username -p -h computername.lan < test.sql |sed 's/\\t/\\\",\\\"/g'|sed 's/^/\\\"/g'|sed 's/$/\\\"/g' > output.csv -- XML output format: mysql databasename -u username -p --xml < test.sql > output.xml -- If you don't want to create the test.sql file and just want to run everything from one commandline statement and get XML output: mysql -u username -p --xml -e 'use databasename; select * from tablename' > output.xml -- You can also put the db_name in your script to avoid typing it on the command line (see below). mysql -u username -p --xml < test.sql > output.xml -- You can create a bash script named getdata and put the following in it. mysql -u username -p < test.sql > test.tab -- Then chmod +x getdata. then run it from the commandline: sh getdata. -- You will be prompted for your database password and the data will get dumped to test.tab. -- The contents of test.sql without the database name. select * from tablename order by columnName; -- The contents of test.sql with the database name. use thedatabase; select * from tablename order by columnName; -- Connect to a remote database server and directly to a database on that server. mysql -h hostname -u databaseuser -p -D databasename -- To Dump a database to a file and generate full insert statements: mysqldump -p -c -e databasename > DatabaseName.sql -- To Dump the database data without the database structure: mysqldump -u root -p thedatabasename --no-create-info > 20240609.sql -- To dump a table from a database and generate full insert statements: mysqldump -p -c -e databasename tablename > TableName.sql -- To dump multiple tables from a database: mysqldump -u theusername -p thedatabasename tablename1 tablename1 tablename2 tablename3 tablename4 tablename5 > thedate_thedatabasename_tables_on_`hostname`.sql -- To dump all databases on the database server: mysqldump -p -c -e --all-databases > AllDatabases.sql -- To dump all databases on the database server without the data (just a skeleton). mysqldump -p -c -e --no-data --all-databases > AllDatabases_Skeleton.sql -- To dump a database from a remote server: mysqldump -h hostname -u username -p -c -e databasename > NameOfDatabaseDumpFile.sql -- To dump a table from a database on a remote server: mysqldump -h hostname -u username -p -c -e databasename tablename > NameOfTableDumpFile.sql -- To dump all databases on a remote server: mysqldump -h hostname -u username -p -c -e --all-databases > NameOfEntireDatabaseDumpFile.sql -- Restore database from a file: mysql -u root -p thedatabasename < 20200424_thedatabasename.sql","title":"From the mysql command prompt:"},{"location":"mysql/#padding-numbers-with-zeros","text":"","title":"Padding numbers with zeros:"},{"location":"mysql/#number-padding","text":"-- Prepend zeros to numbers. There are some links that I saw that said you will need to convert the column to non-numerical to get this to work but I did it on an integer field and it worked. -- The 8 means to pad up to 8 characters, the zero is the character you want to pad with. SELECT LPAD('1234567', 8, '0');","title":"Number padding"},{"location":"mysql/#password-change","text":"use mysql; -- Method 1 (Deprecated): update mysql.user set password('thepassword') where user = 'root'; FLUSH PRIVILEGES; -- Method 2 (MySQL 5.7+): update mysql.user set authentication_string=PASSWORD('thepassword') where user='root'; FLUSH PRIVILEGES; -- Method 3 (Preferred method for current user.): alter user set password = 'thepassword'; FLUSH PRIVILEGES; -- MySQL 5.7: alter user 'root'@'localhost' identified by 'thepassword'; alter user 'root'@'%' identified by 'thepassword'; -- Method 4 (Preferred method for another user.): alter user set password for 'root'@'localhost' = 'thepassword'; FLUSH PRIVILEGES; -- Remote user password change: alter user set password for 'root'@'%' = 'thepassword'; FLUSH PRIVILEGES;","title":"Password Change:"},{"location":"mysql/#path-to-mysql-files","text":"On my MAC: MySQL program: /usr/local/mysql/bin/mysql Databases: /usr/local/mysql/data/ On Ubuntu: MySQL program: /usr/bin/mysql Databases (need to be root): /var/lib/mysql/","title":"Path to MySQL files:"},{"location":"mysql/#prompt-mysql","text":"Change the default mysql> prompt to something functional and useful. 1. Display username, hostname and current database name in the mysql prompt The MYSQL_PS1 in this example displays the following three information in the prompt: \\u - Username \\h - Hostname \\d - Current mysql database $ export MYSQL_PS1=\"\\u@\\h [\\d]> \" $ mysql -u root -pyour-password -D sugarcrm root@dev-db [sugarcrm]> 2. Change the mysql> prompt interactively You can also change the mysql> prompt interactively from inside the mysql as shown below. $ mysql -u root -pyour-password -D sugarcrm mysql> prompt \\u@\\h [\\d]> PROMPT set to '\\u@\\h [\\d]> ' root@dev-db [sugarcrm]> 3. Change the mysql> prompt from mysql command line Instead of using the MYSQL_PS1 variable, you can also pass the prompt as an argument to the mysql command line as shown below. $ mysql --prompt=\"\\u@\\h [\\d]> \" -u root -pyour-password -D sugarcrm root@dev-db [sugarcrm]> 4. Display Current Time in the mysql> prompt Use \\D to display full date in the mysql prompt as shown below. $ export MYSQL_PS1=\"\\u@\\h [\\D]> \" $ mysql -u root -pyour-password -D sugarcrm root@dev-db [Sat Dec 26 19:56:33 2009]> 5. Change the mysql> prompt using /etc/my.cnf or .my.cnf file You can also use either the global /etc/my.cnf (or) your local ~/.my.cnf file to set the prompt as shown below. $ vi ~/.my.cnf [mysql] prompt=\\\\u@\\\\h [\\\\d]>\\\\_ $ mysql -u root -pyour-password -D sugarcrm root@dev-db [sugarcrm]> 6. Customize mysql> prompt any way you want it Use the following variables and customize the mysql prompt as you see fit. These variables are somewhat similar to the Unix PS1 variables (but not exactly the same). Generic variables: \\S displays semicolon \\' displays single quote \\\" displays double quote \\v displays server version \\p displays port \\\\ displays backslash \\n displays newline \\t displays tab \\ displays space (there is a space after \\ ) \\d displays default database \\h displays default host \\_ displays space (there is a underscore after \\ ) \\c displays a mysql statement counter. keeps increasing as you type commands. \\u displays username \\U displays username@hostname accountname Date related variables: \\D displays full current date (as shown in the above example) \\w displays 3 letter day of the week (e.g. Mon) \\y displays the two digit year \\Y displays the four digit year \\o displays month in number \\O displays 3 letter month (e.g. Jan) \\R displays current time in 24 HR format \\r displays current time in 12 hour format \\m displays the minutes \\s displays the seconds \\P displays AM or PM Note: You can go back to the regular boring mysql> prompt at anytime by simply typing prompt in the mysql> prompt as shown below. root@dev-db [sugarcrm]> prompt Returning to default PROMPT of mysql> mysql> <a href='http://www.thegeekstuff.com/2010/02/mysql_ps1-6-examples-to-make-your-mysql-prompt-like-angelina-jolie/'>Source</a> mysql -h localhost -u rob_com1 -p -D robcom1","title":"Prompt (MySQL):"},{"location":"mysql/#remote-connection-from-commandline","text":"","title":"Remote connection from commandline:"},{"location":"mysql/#you-should-only-use-this-command-on-a-secure-ssh-connection","text":"Syntax: mysql -h RemoteServerName -u myusername -p Connect to a remote database server and directly to a database on that server. mysql -h hostname -u databaseuser -p -D databasename","title":"You should only use this command on a secure SSH connection."},{"location":"mysql/#rename-a-database_1","text":"The normal way to rename a database is to dump it then import the data to a new database name. Make sure you check the definer for any views that were created in the database. To rename a table type: RENAME TABLE tb1 TO tb2; Another way to rename a table; ALTER TABLE exampletable RENAME TO new_table_name; The commands below are what I copied from a Stack Exchange article but they did not work for me. I am only leaving them here so that I can study them at some other time. /* mysql -e \"CREATE DATABASE \\`new_database\\`;\" for table in `mysql -B -N -e \"SHOW TABLES;\" old_database` do mysql -e \"RENAME TABLE \\`old_database\\`.\\`$table\\` to \\`new_database\\`.\\`$table\\`\" done mysql -e \"DROP DATABASE \\`old_database\\`;\" */ mysql -u robertme -p mysql -e \"CREATE DATABASE \\`united_states\\`;\" for table in `mysql -B -N -e \"SHOW TABLES;\" test` do mysql -e \"RENAME TABLE \\`test\\`.\\`$table\\` to \\`united_states\\`.\\`$table\\`\" done mysql -e \"DROP DATABASE \\`test\\`;\"","title":"Rename a Database"},{"location":"mysql/#revoke","text":"https://mariadb.com/kb/en/revoke/ https://www.techonthenet.com/mariadb/grant_revoke.php revoke all privileges, grant option from 'SomeUser'@'%'; revoke all privileges, grant option from 'SomeUser'@'localhost'; revoke SELECT, INSERT, UPDATE, DELETE ON SomeDatabase TO 'SomeUser'@'localhost';","title":"Revoke:"},{"location":"mysql/#select","text":"","title":"Select:"},{"location":"mysql/#select-across-databases","text":"select mysql.user.user from mysql.user; -- Example on https://stackoverflow.com/questions/674115/select-columns-across-different-databases SELECT mydatabase1.tblUsers.UserID, mydatabse2.tblUsers.UserID FROM mydatabase1.tblUsers INNER JOIN mydatabase2.tblUsers ON mydatabase1.tblUsers.UserID = mydatabase2.tblUsers.UserID","title":"Select across databases;"},{"location":"mysql/#select-blobdata","text":"SELECT SUBSTRING(<BLOB COLUMN_NAME>,1,2500) FROM <Table_name>;","title":"Select Blobdata:"},{"location":"mysql/#null-and-not-null","text":"Show what IS NOT NULL: SELECT * FROM table WHERE YourColumn IS NOT NULL; This seems to show what IS NULL: SELECT * FROM table WHERE NOT (YourColumn <=> NULL); http://stackoverflow.com/questions/5285448/mysql-select-only-not-null-values","title":"Null and Not NULL:"},{"location":"mysql/#shell-commands","text":"If you want to run shell commands from within the MySQL command prompt use a backslash and exclaimation mark: Example: \\! ls -al","title":"Shell Commands:"},{"location":"mysql/#show-columnstablesdatabases","text":"To show columns: show columns from <table> from <database>; or (if you are already in the database) desc <table>; To show tables: show tables from <database>; or (if you are already in the database) show tables; To show databases: show databases; or (if you are already in the database) show schemas; To show database file location: show variables where Variable_name like '%datadir%';","title":"Show columns/tables/databases:"},{"location":"mysql/#service-mysql","text":"","title":"Service (MySQL):"},{"location":"mysql/#linux-andor-mac","text":"Restart, Start, Stop MySQL from the Command Line macOS, OSX, Linux November 19, 2015 24 Comments To restart, start or stop MySQL server from the command line, type the following at the shell prompt\u001a On Linux start/stop/restart from the command line: /etc/init.d/mysqld start /etc/init.d/mysqld stop /etc/init.d/mysqld restart Some Linux flavors offer the service command too service mysqld start service mysqld stop service mysqld restart or service mysql start service mysql stop service mysql restart On macOS Sierra & OS to start/stop/restart MySQL post 5.7 from the command line: Start: sudo launchctl load -F /Library/LaunchDaemons/com.oracle.oss.mysql.mysqld.plist Stop: sudo launchctl unload -F /Library/LaunchDaemons/com.oracle.oss.mysql.mysqld.plist On OS X to start/stop/restart MySQL pre 5.7 from the command line: sudo /usr/local/mysql/support-files/mysql.server start sudo /usr/local/mysql/support-files/mysql.server stop sudo /usr/local/mysql/support-files/mysql.server restart","title":"Linux and/or MAC:"},{"location":"mysql/#source","text":"Use \"source\" to run a query from outside the database command prompt window. Example: if you have a query file named \"bigdata.sql\" that contains valid MySQL statements that you want to run. Example: source bigdata.sql; or \\. bigdata.sql","title":"Source:"},{"location":"mysql/#flush-privileges-error","text":"ERROR 1227 (42000): Access denied; you need (at least one of) the RELOAD privilege(s) for this operation Solution: GRANT RELOAD ON *.* TO 'your_user'@'localhost'; GRANT RELOAD ON *.* TO 'rob'@'localhost'; GRANT RELOAD ON *.* TO 'rob'@'%';","title":"Flush Privileges Error:"},{"location":"mysql/#statements-and-clauses-mysql","text":"","title":"Statements and Clauses (MySQL):"},{"location":"mysql/#mysql-statements-and-clauses","text":"ALTER DATABASE ALTER TABLE ALTER VIEW ANALYZE TABLE BACKUP TABLE CACHE INDEX CHANGE MASTER TO CHECK TABLE CHECKSUM TABLE COMMIT CREATE DATABASE CREATE INDEX CREATE TABLE CREATE VIEW DELETE DESCRIBE DO DROP DATABASE DROP INDEX DROP TABLE DROP USER DROP VIEW EXPLAIN FLUSH GRANT HANDLER INSERT JOIN KILL LOAD DATA FROM MASTER LOAD DATA INFILE LOAD INDEX INTO CACHE LOAD TABLE...FROM MASTER LOCK TABLES OPTIMIZE TABLE PURGE MASTER LOGS RENAME TABLE REPAIR TABLE REPLACE RESET RESET MASTER RESET SLAVE RESTORE TABLE REVOKE ROLLBACK ROLLBACK TO SAVEPOINT SAVEPOINT SELECT SET SET PASSWORD SET SQL_LOG_BIN SET TRANSACTION SHOW BINLOG EVENTS SHOW CHARACTER SET SHOW COLLATION SHOW COLUMNS SHOW CREATE DATABASE SHOW CREATE TABLE SHOW CREATE VIEW SHOW DATABASES SHOW ENGINES SHOW ERRORS SHOW GRANTS SHOW INDEX SHOW INNODB STATUS SHOW LOGS SHOW MASTER LOGS SHOW MASTER STATUS SHOW PRIVILEGES SHOW PROCESSLIST SHOW SLAVE HOSTS SHOW SLAVE STATUS SHOW STATUS SHOW TABLE STATUS SHOW TABLES show tables like 'abc%'; SHOW VARIABLES SHOW WARNINGS START SLAVE START TRANSACTION STOP SLAVE TRUNCATE TABLE UNION UNLOCK TABLES USE","title":"MYSQL Statements and clauses"},{"location":"mysql/#string-functions","text":"AES_DECRYPT AES_ENCRYPT ASCII BIN BINARY BIT_LENGTH CHAR CHAR_LENGTH CHARACTER_LENGTH COMPRESS CONCAT CONCAT_WS CONV DECODE DES_DECRYPT DES_ENCRYPT ELT ENCODE ENCRYPT EXPORT_SET FIELD FIND_IN_SET HEX INET_ATON INET_NTOA INSERT INSTR LCASE LEFT LENGTH LOAD_FILE LOCATE LOWER LPAD LTRIM MAKE_SET MATCH AGAINST MD5 MID OCT OCTET_LENGTH OLD_PASSWORD ORD PASSWORD POSITION QUOTE REPEAT REPLACE REVERSE RIGHT RPAD RTRIM SHA SHA1 SOUNDEX SPACE STRCMP SUBSTRING SUBSTRING_INDEX TRIM UCASE UNCOMPRESS UNCOMPRESSED_LENGTH UNHEX UPPER","title":"String Functions"},{"location":"mysql/#date-and-time-functions","text":"ADDDATE ADDTIME CONVERT_TZ CURDATE CURRENT_DATE CURRENT_TIME CURRENT_TIMESTAMP CURTIME DATE DATE_ADD DATE_FORMAT DATE_SUB DATEDIFF DAY DAYNAME DAYOFMONTH DAYOFWEEK DAYOFYEAR EXTRACT FROM_DAYS FROM_UNIXTIME GET_FORMAT HOUR LAST_DAY LOCALTIME LOCALTIMESTAMP MAKEDATE MAKETIME MICROSECOND MINUTE MONTH MONTHNAME NOW PERIOD_ADD PERIOD_DIFF QUARTER SEC_TO_TIME SECOND STR_TO_DATE SUBDATE SUBTIME SYSDATE TIME TIMEDIFF TIMESTAMP TIMESTAMPDIFF TIMESTAMPADD TIME_FORMAT TIME_TO_SEC TO_DAYS UNIX_TIMESTAMP UTC_DATE UTC_TIME UTC_TIMESTAMP WEEK WEEKDAY WEEKOFYEAR YEAR YEARWEEK","title":"Date and Time Functions"},{"location":"mysql/#mathematical-and-aggregate-functions","text":"ABS ACOS ASIN ATAN ATAN2 AVG BIT_AND BIT_OR BIT_XOR CEIL CEILING COS COT COUNT CRC32 DEGREES EXP FLOOR FORMAT GREATEST GROUP_CONCAT LEAST LN LOG LOG2 LOG10 MAX MIN MOD PI POW POWER RADIANS RAND ROUND SIGN SIN SQRT STD STDDEV SUM TAN TRUNCATE VARIANCE","title":"Mathematical and Aggregate Functions"},{"location":"mysql/#flow-control-functions","text":"CASE IF IFNULL NULLIF","title":"Flow Control Functions"},{"location":"mysql/#command-line-utilities","text":"comp_err isamchk make_binary_distribution msql2mysql my_print_defaults myisamchk myisamlog myisampack mysqlaccess mysqladmin mysqlbinlog mysqlbug mysqlcheck mysqldump mysqldumpslow mysqlhotcopy mysqlimport mysqlshow perror","title":"Command-Line Utilities"},{"location":"mysql/#perl-api-using-functions-and-methods-built-into-the-perl-dbi-with-mysql","text":"available_drivers begin_work bind_col bind_columns bind_param bind_param_array bind_param_inout can clone column_info commit connect connect_cached data_sources disconnect do dump_results err errstr execute execute_array execute_for_fetch fetch fetchall_arrayref fetchall_hashref fetchrow_array fetchrow_arrayref fetchrow_hashref finish foreign_key_info func get_info installed_versions last_insert_id looks_like_number neat neat_list parse_dsn parse_trace_flag parse_trace_flags ping prepare prepare_cached primary_key primary_key_info quote quote_identifier rollback rows selectall_arrayref selectall_hashref selectcol_arrayref selectrow_array selectrow_arrayref selectrow_hashref set_err state table_info table_info_all tables trace trace_msg type_info type_info_all Attributes for Handles","title":"Perl API - using functions and methods built into the Perl DBI with MySQL"},{"location":"mysql/#php-api-using-functions-built-into-php-with-mysql","text":"mysql_affected_rows mysql_change_user mysql_client_encoding mysql_close mysql_connect mysql_create_db mysql_data_seek mysql_db_name mysql_db_query mysql_drop_db mysql_errno mysql_error mysql_escape_string mysql_fetch_array mysql_fetch_assoc mysql_fetch_field mysql_fetch_lengths mysql_fetch_object mysql_fetch_row mysql_field_flags mysql_field_len mysql_field_name mysql_field_seek mysql_field_table mysql_field_type mysql_free_result mysql_get_client_info mysql_get_host_info mysql_get_proto_info mysql_get_server_info mysql_info mysql_insert_id mysql_list_dbs mysql_list_fields mysql_list_processes mysql_list_tables mysql_num_fields mysql_num_rows mysql_pconnect mysql_ping mysql_query mysql_real_escape_string mysql_result mysql_select_db mysql_stat mysql_tablename mysql_thread_id mysql_unbuffered_query","title":"PHP API - using functions built into PHP with MySQL"},{"location":"mysql/#time-timezones","text":"SELECT CONVERT_TZ(displaytime,'GMT','MET'); should work if your column type is timestamp, or date You need to have the timezones loaded. See below if you don't have the timezones loaded. ```","title":"Time / Timezones:"},{"location":"openvpn/","text":"OPENVPN Settings->Network->VPN->Add+ Import from file... Browse to RLH_OpenVPN_Server.ovpn","title":"OpenVPN"},{"location":"openvpn/#openvpn","text":"Settings->Network->VPN->Add+ Import from file... Browse to RLH_OpenVPN_Server.ovpn","title":"OPENVPN"},{"location":"pgp/","text":"PGP: The GNU Privacy Handbook Archlinux Wiki GnuPG GnuPG Website Public PGP Global Directory Youtube Videos: GnuPG Part One GnuPG Part Two GnuPG Part Three NITC-GnuPG Part 3 Generate/Create GPG/PGP Key: gpg2 --full-gen-key gpg --gen-key Versions older than 2.1.17 use: gpg --default-new-key-algo rsa4096 --gen-key Change your password if you want to: gpg --edit-key YourKeyID Then type: passwd Send key to default key server: gpg --send-key KEYNAME gpg --export your_address@example.net | curl -T - https://keys.openpgp.org gpg --export your_address@example.net > my_key.pub You can upload your key to this PGP site: https://keyserver.pgp.com You can check if your key is on the PGP website here: https://keyserver.pgp.com To send your public key to a keyserver: gpg --keyserver the.keyserver.name.com --send-keys YOURKEYID Example: gpg --keyserver keyserver.ubuntu.com --send-keys 5DD98B3E Example: gpg --keyserver hkp://pgp.mit.edu --send-keys YOURKEYID Example: gpg --keyserver hkps.pool.sks-keyservers.net --send-keys YOURKEYID To receive a public key from a keyserver: Example: gpg --keyserver the.keyserver.name.com --recv-keys THEKEYID Example: gpg --keyserver keyserver.ubuntu.com --recv-keys 5DD98B3E To locate the key of a user, by email address: Example: gpg --auto-key-locate keyserver --locate-keys user@example.net To refresh all your keys (e.g. new revocation certificates and subkeys): Example: gpg --refresh-keys Export ascii armored key: gpg --export --armor jqdoe@example.com > jqdoe-pubkey.asc gpg --export-secret-keys --armor jqdoe@example.com >> jqdoe-privkey.asc Use a double greater than symbol to export both public and private to the same file \">>\". Encrypt a message to standard output: gpg -ea Enter your recipients and end with an empty line. Type your message that you want to encrypt. Press Control+D and your encrypted message will appear onscreen. Encrypt message to a file you can type: gpg -ea > filename.txt then do the steps above. Enter your recipients and end with an empty line. Type your message that you want to encrypt. Press Control+D and your encrypted message will be sent to filename.txt. Encrypt a single file (creates a binary file). This option may be combined with --sign. gpg -e filename or gpg --encrypt filename Encrypt a single file (creates an ASCII file). This option may be combined with --sign. gpg -a -e filename or gpg --armor --encrypt filename or gpg -ea filename This is a special version of the --encrypt command. The command expects the files to be encrypted either on the command line or reads the filenames from stdin; each name must be on separate line. The command is intended for a quick encryption of multiple files. Encrypt multiple files. This option may be combined with --sign. This will prompt you for your password for each file. gpg --encrypt-files file1 file2 file3 or add a recipient (your own key) to not be prompted. gpg --encrypt-files -r A1B2C3D4E5F6 *.txt Batch encrypt using --multi-file: gpg --multifile --encrypt --armor -r brothers *.txtrh Bash script to batch encrypt multiple files: for file in *.txtrh do # echo \"gpg --encrypt --armor -r 7FEBFF2F6AB4F024 -r D1BD917D4AF9F0EC\" > ~/\"$file\" # gpg --encrypt --armor -r 7FEBFF2F6AB4F024 -r D1BD917D4AF9F0EC \"$file\" gpg --encrypt --armor -r brothers \"$file\" # echo \"============== $file\" done Encrypt with symmetric cipher only. This command asks for a passphrase. (May also be combined with --sign -- see GnuPG 1.0.7 released.) gpg -c filename or gpg --symmetric filename Batch Encrypt multiple files to specified recipients (encrypt.sh). Make sure your $file variable is surrounded by quotes so that files with spaces in their names will get picked up. for file in *.txt do gpg --encrypt -r A1B2C3D4E5F6G7H8 -r I1J2K3L4M5N6O7P8 \"$file\" done Encrypt to a recipient. gpg -e -r recipient filename or gpg --encrypt -r recipient filename or encrypt and sign. gpg -e -r recipient -s filename Use -u to specify the secret key to be used, and -r to specify the public key of the recipient. **Note: This doesn't seem to work when you have a default sender and recipient key established in gpg.conf because the default sender and recipient overwrite the \"-u\" option. gpg -e -u \"Sender User Name\" -r \"Receiver User Name\" somefile Example 1: gpg -e -u \"me@example.com\" -r \"you@example.com\" -r \"them@example.com\" somefile Example 2: gpg -e -u \"Billy Bob\" -r \"Nancy Bob\" mydata.tar Example 3: gpg -s --default-key ABCD1234 -ea yyy.txt Password encrypt and sign a file: gpg -c -s filename Password encrypt and sign a message that can be decrypted by passphrase or secret key: gpg -c --sign --encrypt filename or gpg -c -s -e filename UUEncode a file before ascii encrypting: uuencode filename filename > filename.uue gpg -a -e filename.uue UUEncode a file before normal encrypting: uuencode filename filename > filename.uue gpg --encrypt filename.uue Decrypt UUEncoded file with normal encryption then UUDecode it: gpg --decrypt filename > filename.uue uudecode filename.uue Decrypt a message in standard out (stout) type: gpg You will see a message similar to this: gpg: Go ahead and type your message ... At this point you can paste in the encrypted text and you will be prompted for your passphrase. Once you enter your passphrase, press Control+D to see the decrypted message. Decrypt file (or stdin if no file is specified) and write it to stdout (or the file specified with --output). If the decrypted file is signed, the signature is also verified. This command differs from the default operation, as it never writes to the filename which is included in the file and it rejects files which don't begin with an encrypted message. gpg --decrypt filenames Decrypt a file that has been binary or ascii encrypted and output the decrypted content to a file: gpg --output decrypted.txt --decrypt encrypted.txt.gpg or gpg -o decrypted.txt -d encrypted.txt.gpg This is a special version of the --decrypt command. The command expects the files to be decrypted either on the command line or reads the filenames from stdin; each name must be on separate line. The command is intended for a quick decryption of multiple files. gpg --decrypt-files file1 file2 file3 Multiple Private Keys. When encrypting or decrypting it is possible to have more than one private key in use. To use a different private key other than the default use the option -u UID or use the option --local-user UID. This causes the default key used to be replaced by the wanted key. gpg -u <KEY ID> -r recipient --armor --sign --encrypt filename or gpg -u <KEY ID> -r recipient -a -s -e filename or (this should prompt you for recipients) gpg -u nameofprivatekey -a -s -e filename Signing / Verifying: Make a signature. This command may be combined with --encrypt. (May also be combined with --symmetric (see GnuPG 1.0.7 released.) gpg -s filename or gpg --sign filename Both -s and --sign make an illegible signature that you can't read. This is OK because GPG/PGP can still read it (not humans). Make a clear text signature. gpg --clearsign filename or cat filename.txt| gpg --clearsign > some_file.txt or echo \"The message\" | gpg --clearsign > The_message.txt Make a detached signature. gpg -b filename or gpg --detach-sign filename Verify a signature file without generating any output. With no arguments, the signature packet is read from stdin. If only a sigfile is given, it may be a complete signature or a detached signature, in which case the signed stuff is expected in a file without the \".sig\" or \".asc\" extension. With more than 1 argument, the first should be a detached signature and the remaining files are the signed stuff. To read the signed stuff from stdin, use - as the second filename. For security reasons a detached signature cannot read the signed material from stdin without denoting it in the above way. gpg --verify sigfile signed_files This is a special version of the --verify command which does not work with detached signatures. The command expects the files to be verified either on the command line or reads the filenames from stdin; each name must be on separate line. The command is intended for quick checking of many files. gpg --verify-files filenames Create ASCII armored output. gpg -a -e filename or gpg --armor -e filename Assume the input data is not in ASCII armored format. gpg --no-armor Use canonical text mode. If -t (but not --textmode) is used together with armoring and signing, this enables clearsigned messages. This kludge is needed for PGP compatibility; normally you would use --sign or --clearsign to select the type of the signature. gpg -t or gpg --textmode Encrypt for user id name. If this option is not specified, GnuPG asks for the user-id unless --default-recipient is given. gpg -r nameofkey or gpg --recipient nameofkey Groups Set up a name group, which is similar to aliases in email programs. Any time the group name is a receipient (-r or --recipient), it will be expanded to the values specified. The values are key IDs or fingerprints, but any key description is accepted. Note that a value with spaces in it will be treated as two different values. Note also there is only one level of expansion -- you cannot make a group that points to another group. gpg --group name=value Use name as default recipient if option --recipient is not used and don't ask if this is a valid one. name must be non-empty. gpg --default-recipient nameofkey Use the default key as default recipient if option --recipient is not used and don't ask if this is a valid one. The default key is the first one from the secret keyring or the one set with --default-key. gpg --default-recipient-self Reset --default-recipient and --default-recipient-self. gpg --no-default-recipient Use name as default user ID for signatures. If this is not used the default user ID is the first user ID found in the secret keyring. gpg --default-key nameofkey Same as --recipient but this one is intended for use in the options file and may be used with your own user-id as an \"encrypt-to-self.\" These keys are only used when there are other recipients given either by use of --recipient or by the asked user id. No trust checking is performed for these user ids and even disabled keys can be used. gpg --encrypt-to name Disable the use of all --encrypt-to keys. gpg --no-encrypt-to Comments & Versions Use string as comment string in clear text signatures. The default is not to write a comment string. gpg --comment string Force to write the standard comment string in clear text signatures. Use this to overwrite a --comment from a config file. This option is now obsolete because there is no default comment string anymore. gpg --default-comment Omit the version string in clear text signatures. gpg --no-version Force to write the version string in clear text signatures. Use this to overwrite a previous --no-version from a config file. gpg --emit-version Special \"for your eyes only\" Set the \"for your eyes only\" flag in the message. This causes GnuPG to refuse to save the file unless the --output option is given, and PGP to use the \"secure viewer\" with a Tempest-resistant font to display the message. This option overrides --set-filename. --for-your-eyes-only Resets the --for-your-eyes-only flag. --no-for-your-eyes-only Set compression level to n. A value of 0 for n disables compression. Default is to use the default compression level of zlib (normally 6). -z n, --compress n Skip the signature verification step. This may be used to make the decryption faster if the signature verification is not needed. --skip-verify When making a data signature, prompt for an expiration time. If this option is not specified, the expiration time is \"never.\" gpg --ask-sig-expire Resets the --ask-sig-expire option. gpg --no-ask-sig-expire Do not put the keyid into encrypted packets. This option hides the receiver of the message and is a countermeasure against traffic analysis. It may slow down the decryption process because all available secret keys are tried. gpg --throw-keyid Don't look at the key ID as stored in the message but try all secret keys in turn to find the right decryption key. This option forces the behaviour as used by anonymous recipients (created by using --throw-keyid) and might come handy in case where an encrypted message contains a bogus key ID. gpg --try-all-secrets Put the name value pair into the signature as notation data. Name must consist only of alphanumeric characters, digits or the underscore; the first character must not be a digit. Value may be any printable string; it will be encoded in UTF8, so you should check that your --charset is set correctly. If you prefix name with an exclamation mark, the notation data will be flagged as critical (rfc2440:5.2.3.15). gpg -N gpg --notation-data name=value This option changes the behavior of cleartext signatures so that they can be used for patch files. You should not send such an armored file via email because all spaces and line endings are hashed too. You can not use this option for data which has 5 dashes at the beginning of a line, patch files don't have this. A special armor header line tells GnuPG about this cleartext signature option. gpg --not-dash-escaped Because some mailers change lines starting with \"From \" to \"<From \" it is good to handle such lines in a special way when creating cleartext signatures. All other PGP versions do it this way too. This option is not enabled by default because it would violate rfc2440. gpg --escape-from-lines Use string as the name of file which is stored in messages. gpg --set-filename string Try to create a file with a name as embedded in the data. This can be a dangerous option as it allows to overwrite files. gpg --use-embedded-filename This option enables a mode in which filenames of the form \"-&n,\" where n is a non-negative decimal number, refer to the file descriptor n and not to a file with that name. gpg --enable-special-filenames Revoke a Key. gpg --gen-revoke THEKEYID > revoked.key This creates a revocation certificate. To be able to do this, you need a secret key, otherwise anyone could revoke your certificate. This has one disadvantage. If you do not know the passphrase for the secret key, the revocation key will become useless and you cannot revoke the secret key! To overcome this problem it is wise to create a revoke license when you create a key pair. And if you do so, keep it safe! This can be on disk, paper, etc. Make sure that this certificate will not fall into wrong hands!!!! If you don't someone else can issue the revoke certificate for your key and make it useless. You will need to enter the revoke reason for the key and an optional comment. Once you have the revocation certificate, you will need to import it so that the key will get revoked. gpg --import revoked.key Type: gpg --list-keys and you will see that the key has been revoked. Next, you will have to send the revoked key to the key server. This is the same method as sending a normal key except this one has been revoked. When the server receives the revoked key, it will be removed from the server. Remove/Revoke a specific email address from your key. gpg --edit-key 01234567 uid 4 (This is the uid of the email address that you want to revoke). revuid Really revoke this user ID? (y/N) y Please select the reason for the revocation: 0 = No reason specified 4 = User ID is no longer valid Q = Cancel (Probably you want to select 4 here) Your decision? 4 Enter an optional description; end it with an empty line: > Reason for revocation: User ID is no longer valid (No description given) Is this okay? (y/N) y You need a passphrase to unlock the secret key for user: \"John Doe <john@doe.tld>\" [ultimate] (1). John Doe <john@doe.tld> [ revoked] (2) John Doe (Corp) <john.doe@corp.tld> gpg> save Next, send your updated key to the keyservers. gpg --send-keys 01234567 gpg: sending key 01234567 to hkp server keys.gnupg.net There are three main rings of keyservers out there ( Source ). Each group syncs within it's own pool well, and to the other pools with varying levels of success, so I recommend uploading to one of each. Something like this will work. servers=\"x-hkp://pool.sks-keyservers.net pgp.mit.edu wwwkeys.ch.pgp.net\" for server in $servers; do gpg --keyserver $server --send-key <your_keyid> done Key Administration: With the GnuPG system comes a file that acts as some kind of database. In this file all data regarding keys with the information that comes with the keys is stored. List all the keys: This will show you the key IDs and other information: gpg --list-keys To show the \"Short Key\" ID: gpg -K --with-fingerprint --with-colons | grep \"sec\" | cut -f5 -d ':' To show the \"HEX Key\" ID (last 16 characters with 0x prepended): gpg -K --with-fingerprint --with-colons | grep \"sec\" | cut -f5 -d ':'|awk '{print \"0x\" $1}' List all the keys and see the signatures as well type: gpg --list-sigs To see the fingerprints type: gpg --fingerprint You want to see \"Fingerprints\" to ensure that somebody is really the person they claim (like in a telephone call). This command will result in a list of relatively small numbers. To list the secret keys you type: gpg --list-secret-keys Note that listing fingerprints and signatures from private keys has no use whatsoever. To delete a public key you type: gpg --delete-key UID To delete a secret key you type: gpg --delete-secret-key UID (You have to delete the private key before deleting the public key) There is one more important command that is relevant for working with keys. gpg --edit-key <HEX KEY ID> Using this you can edit (among other things) the expiration date, add a fingerprint and sign your key. When in this mode you can press the question mark key to see the options available to you. Import a key: gpg --import filename You might get an error with the newer version of GPG (gpg: error building skey array: Permission denied) or (gpg: error building skey array: No pinentry). Try using (--batch): gpg --batch --import your.secret.key.asc Export your key: Export public key in binary format: gpg --export <KEY ID> Export public key in ascii format: gpg --export -a <KEY ID> Export secret key in binary format: gpg --export-secret-key <KEY ID> Export secret key in ascii format: gpg --export-secret-key -a <KEY ID> Source: https://www.gnupg.org/gph/en/manual/x110.html http://www.dewinter.com/gnupg_howto/english/GPGMiniHowto-3.html#ss3.5 https://www.gnupg.org/documentation/howtos.html https://github.com/rldutch1/pgp/blob/master/commandline_switches.html Shell Function for PGP: Here is a PGP function that I have created and use on my Mac and Linux computers (it works on Windows too with Git or Cygwin installed). I named it \"pgp\" so that it is different from gpg on Linux/Mac and will not conflict. pgp(){ clear case $1 in ascii) echo \"ASCII Encrypting... \" $2 gpg -a -e $2 echo \"...\" >> $2;rm -f $2 echo $2 \" has been deleted!\" ;; clearsign) echo \"Signing...\" $2 gpg --clearsign $2 echo $2 \" has been signed!\" ;; decrypt) #gpg --decrypt $2 if [ ! $2 ] || [ ! $3 ]; then echo \"Syntax: pgp decrypt outputfile encryptedfile.asc\" else gpg --output $2 --decrypt $3 fi ;; delete-keys) echo \"Deleting...\" $2 gpg --delete-keys $2 gpg --list-keys ;; detachedsig) echo \"Creating signature file...\" $2 gpg --output $2.sig --detach-sig $2 ;; encrypt) echo \"Encrypting...\" $2 gpg --encrypt $2 echo \"...\" > $2;rm -f $2 echo $2 \" has been deleted!\" ;; exportpublic) echo \"Exporting Public Key...\" $2 gpg --export --armor $2 > $2.asc ;; exportprivate) echo \"Exporting PRIVATE KEY...\" $2 gpg --export --armor $2 > $2.asc gpg --export-secret-keys --armor $2 >> $2.asc ;; fingerprint) gpg --fingerprint $2 ;; fingerprint_from_file) gpg --with-fingerprint $2 ;; import) echo \"Importing...\" $2 gpg --import $2 echo $2 \" has been imported!\" ;; list) gpg --list-keys ;; listdirs) gpgconf --list-dirs ;; message) cd ~/Documents/PGP/messages xyzrh1=message.`date +\"%Y%m%d%H%M%S%Z\"` vi $xyzrh1.txt; pgp ascii $xyzrh1.txt ;; passencrypt) echo \"Encrypting...\" $2 gpg -c -s $2 echo $2 \" has been password encrypted!\" ;; releasecache) gpgconf --kill gpg-agent;gpgconf --launch gpg-agent ;; receivekeys) gpg --keyserver $2 --recv-keys $3 ;; revoke_key) gpg --gen-revoke $2 > revoke.$2.asc ;; sign) echo \"Signing...\" $2 gpg --sign $2 echo $2 \" has been signed!\" ;; sendkeys) if [ ! $2 ]; then echo \"Example: gpg --keyserver hkp://pgp.mit.edu --send-keys 6EE89C2D\" else gpg --keyserver $2 --send-keys $3 fi ;; showphoto) if [ ! $2 ]; then echo \"Should have xloadimage installed:\" echo \"Example:\" echo \"showphoto 6EE89C2D\" echo \"showphoto user@example.com\" else gpg --list-options show-photos --fingerprint $2 fi ;; update) gpg --update-trustdb ;; uue) echo \"UUEncoding...\" $2 uuencode $2 $2 > $2.uue echo \"ASCII Encrypting...\" $2.uue gpg -a -e $2.uue echo \"...\" > $2.uue;rm -f $2 $2.uue echo $2 \" has been deleted!\" ;; uuegpg) echo \"UUEncoding...\" $2 uuencode $2 $2 > $2.uue echo \"Encrypting...\" $2.uue gpg --encrypt $2.uue echo \"...\" > $2.uue;rm -f $2 $2.uue echo $2 \" has been deleted!\" ;; uuedecrypt) #echo \"Decrypting...\" $2 gpg --decrypt $2 > $2.uue echo \"Decoding...\" $2 uudecode $2.uue; echo \"...\" > $2.uue;rm -f $2.uue echo $2 \" has been decoded!\" ;; verify) echo \"Signing...\" $2 gpg --verify $2 echo $2 \" verify status!\" ;; *) message00=\"gpg --edit-key 5DD98B3E\" message01=\"pgp ascii textfile (gpg -a -e thefilename)\" message02=\"pgp clearsign textfile (gpg --clearsign thefilename)\" message03=\"pgp decrypt outputfile.tar encryptedfile.tar.gpg (gpg -o outputfile -d encryptedfile)\" message04=\"pgp delete-keys 5DD98B3E (gpg --delete-keys keyname)\" message05=\"pgp detachedsig filename (gpg --output doc.sig --detach-sig doc.txt)\" message06=\"pgp encrypt filename (gpg --encrypt thefilename)\" message07=\"pgp exportpublic keyname (gpg --export --armor thekeyname)\" message08=\"pgp exportprivate keyname (gpg --export-secret-keys --armor ABCD1234 >> ABCD1234.asc)\" message09=\"pgp fingerprint 5DD98B3E (gpg --fingerprint key)\" message10=\"pgp fingerprint_from_file file_with_key (gpg --with-fingerprint thefilename)\" message11=\"pgp import filename.asc (gpg --import keyfile / gpg2 --import keyfile)\" message12=\"pgp list (gpg --list-keys)\" message13=\"pgp listdirs (gpgconf --list-dirs)\" message14=\"pgp message\" message15=\"pgp passencrypt textfile (gpg -c -s thefilename)\" message16=\"pgp receivekeys theservername thekeyname (gpg --keyserver keyserver.ubuntu.com --recv-keys 6EE89C2D)\" message17=\"pgp releasecache (gpgconf --kill gpg-agent;gpgconf --launch gpg-agent)\" message18=\"pgp revoke_key (gpg --gen-revoke thekeyname > revoke.thekeyname.asc)\" message19=\"pgp sendkeys theservername thekeyname (gpg --keyserver hkp://pgp.mit.edu --send-keys 6EE89C2D)\" message20=\"pgp showphoto 6EE89C2D (gpg --list-options show-photos --fingerprint 6EE89C2D)\" message21=\"pgp sign textfile (gpg --sign thefilename)\" message22=\"pgp update (gpg --update-trustdb)\" message23=\"pgp uue filename (uuencode thefilename thefilename > thefilename.uue;gpg -a -e thefilename.uue)\" message24=\"pgp uuedecrypt filename (gpg --decrypt thefilename > thefilename.uue;uudecode thefilename.uue)\" message25=\"pgp uuegpg filename (uuencode thefilename thefilename > thefilename.uue;gpg --encrypt thefilename.uue)\" message26=\"pgp verify filename (gpg --verify signaturefile)\" echo $message00 echo $message01 echo $message02 echo $message03 echo $message04 echo $message05 echo $message06 echo $message07 echo $message08 echo $message09 echo $message10 echo $message11 echo $message12 echo $message13 echo $message14 echo $message15 echo $message16 echo $message17 echo $message18 echo $message19 echo $message20 echo $message21 echo $message22 echo $message23 echo $message24 echo $message25 echo $message26 echo \" \" ;; esac } View your trust database: View your trust database and see the marginal and other trust information type: gpg --update-trustdb Before a key can be trusted it must be signed and the trust level applied by the key owner. Marginally (Marginal) trusted keys can also be trusted if 3 or more people you trust have chosen to trust the same key that you have marginally trusted. Or if 3 or more marginally trusted people marginally trust the same key then it will be considered trusted by your key. GPG Privacy Assistant (GPA): Graphical user interface for GnuPG called GPG Privacy Assistant (GPA). It can be installed by typing: sudo apt-get -y install gpa sudo dnf -y install gpa Passphrase cache timeout: On Fedora Linux, the passphrase cache timeout was 300 seconds (5 minutes). I couldn't find where I could change that setting. I ended up installing dconf-editor and I was able to change the passphrase cache. I added screenshots (dconf-editor_settings##.png. I installed Open GnuPG on my Mac using: sudo port install gnupg2 I like it a lot better thant the GPG Suite that I was previously using because I can encrypt and decrypt from an SSH session without the GUI password prompt preventing me from decrypting something. I have also discovered that I no longer seem to be able to use the command 'gpg < encryptedfile'. I get a message that says it doesn't understand what I am trying to do. I actually have to paste in the encrypted content and press control+d. How can I force the system to ask the passphrase every time? Old versions of GnuPG uses the gpg-agent, which caches the passphrase for a given time. Use the option --no-use-agent or add a line no-use-agent to ~/.gnupg/gpg.conf to prevent using the agent. Note: --no-use-agent is obsolete in gpg2 and has no effect. Removing the passphrase cacheing and setting it to 1 second. I haven't tried this but it has a green checkmark on stackexchange. Edit: ~/.gnupg/gpg-agent.conf Add: default-cache-ttl 1 max-cache-ttl 1 Reload the gpg agent: echo RELOADAGENT | gpg-connect-agent or Type: gpg-connect-agent At the prompt type: RELOADAGENT Response should be: OK At the prompt type: BYE Reponse should be: OK closing connection Restart the gpg agent: Type: gpg-connect-agent At the prompt type: KILLAGENT Reponse should be: OK closing connection List PGP/GPG directories: gpgconf --list-dirs Miscellaneous: gpg options --debug-level guru --debug-all --verbose gpg --debug-level guru --debug-all --verbose I was having trouble importing my private key because it was in an older version of GPG. I was getting the following errors: gpg: error building skey array: No such file or directory gpg import error sending to agent no such file or directory gpg: error building skey array: permission denied gpg: decryption failed: no secret key I had to decrypt my passphrase encrypted key using a user that did not have GPG enabled (root). I also renamed my .gnupg directory and ran gpg again so that a new .gnupg folder would get created. Inside that directory I had to manually create the private-keys-v1.d directory so the \"No such file or directory\" error would go away. I was still having issues and kept seeing a message telling me no private key present whenever I tried to decrypt something. I ended up restoring the .gnupg folder from a backup and restarting the gpg agent. Pinentry Running gpg through SSH session sometimes will error when performing tasks. When I used the pinentry-mode, the password was cached but I was able to decrypt. gpg --decrypt --pinentry-mode=loopback <file> gpg -c -s --pinentry-mode=loopback <file> Keybase error adding PGP/GPG key: https://github.com/keybase/client/issues/22458 gpgconf: Options Starting with GnuPG 1.1.92 (incl. GnuPG 1.2.1, 1.2.0 and 1.1.92), long options can be put in an options file (default \"~/.gnupg/gpg.conf\"). In GnuPG versions up through GnuPG 1.1.91 (incl. 1.0.6, 1.0.7, and 1.1.91), long options can be put in an \"old style\" configuration file (default \"~/.gnupg/options\"). Short option names will not work -- for example, armor is a valid option for the options file, while a is not. Do not write the 2 dashes, but simply the name of the option and any required arguments. Lines with a hash as the first non-white-space character are ignored. Commands may be put in this file too, but that does not make sense. Two useful entries for .gnupg/gpg.conf file. These entries will force GPG to use your key as default and automatically encrypt to your key. default-key 1A2B3CD4 encrypt-to 1A2B3CD4 #gpg-connect-agent gpg.conf Example File # These first three lines are not copied to the gpg.conf file in # the users home directory. # $Id$ # Options for GnuPG # Copyright 1998, 1999, 2000, 2001, 2002, 2003, # 2010 Free Software Foundation, Inc. # # This file is free software; as a special exception the author gives # unlimited permission to copy and/or distribute it, with or without # modifications, as long as this notice is preserved. # # This file is distributed in the hope that it will be useful, but # WITHOUT ANY WARRANTY, to the extent permitted by law; without even the # implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. # # Unless you specify which option file to use (with the command line # option \"--options filename\"), GnuPG uses the file ~/.gnupg/gpg.conf # by default. # # An options file can contain any long options which are available in # GnuPG. If the first non white space character of a line is a '#', # this line is ignored. Empty lines are also ignored. # # See the man page for a list of options. # Uncomment the following option to get rid of the copyright notice #no-greeting # If you have more than 1 secret key in your keyring, you may want to # uncomment the following option and set your preferred keyid. default-key ABCD1234 encrypt-to ABCD1234 # If you do not pass a recipient to gpg, it will ask for one. Using # this option you can encrypt to a default key. Key validation will # not be done in this case. The second form uses the default key as # default recipient. #default-recipient some-user-id #default-recipient-self #default-recipient ABCD1234 # By default GnuPG creates version 4 signatures for data files as # specified by OpenPGP. Some earlier (PGP 6, PGP 7) versions of PGP # require the older version 3 signatures. Setting this option forces # GnuPG to create version 3 signatures. #force-v3-sigs # Because some mailers change lines starting with \"From \" to \">From \" # it is good to handle such lines in a special way when creating # cleartext signatures; all other PGP versions do it this way too. # To enable full OpenPGP compliance you may want to use this option. no-escape-from-lines # When verifying a signature made from a subkey, ensure that the cross # certification \"back signature\" on the subkey is present and valid. # This protects against a subtle attack against subkeys that can sign. # Defaults to --no-require-cross-certification. However for new # installations it should be enabled. require-cross-certification # If you do not use the Latin-1 (ISO-8859-1) charset, you should tell # GnuPG which is the native character set. Please check the man page # for supported character sets. This character set is only used for # metadata and not for the actual message which does not undergo any # translation. Note that future version of GnuPG will change to UTF-8 # as default character set. #charset utf-8 # Group names may be defined like this: # group mynames = paige 0x12345678 joe patti # # Any time \"mynames\" is a recipient (-r or --recipient), it will be # expanded to the names \"paige\", \"joe\", and \"patti\", and the key ID # \"0x12345678\". Note there is only one level of expansion - you # cannot make an group that points to another group. Note also that # if there are spaces in the recipient name, this will appear as two # recipients. In these cases it is better to use the key ID. #group mynames = paige 0x12345678 joe patti group myfriends = BD4054DAC61AB7BB B1BC917D4AF9F0EC #no-mangle-dos-filenames # Lock the file only once for the lifetime of a process. If you do # not define this, the lock will be obtained and released every time # it is needed - normally this is not needed. #lock-once # GnuPG can send and receive keys to and from a keyserver. These # servers can be HKP, email, or LDAP (if GnuPG is built with LDAP # support). # # Example HKP keyservers: # hkp://keys.gnupg.net # # Example LDAP keyservers: # ldap://pgp.surfnet.nl:11370 # # Regular URL syntax applies, and you can set an alternate port # through the usual method: # hkp://keyserver.example.net:22742 # # If you have problems connecting to a HKP server through a buggy http # proxy, you can use keyserver option broken-http-proxy (see below), # but first you should make sure that you have read the man page # regarding proxies (keyserver option honor-http-proxy) # # Most users just set the name and type of their preferred keyserver. # Note that most servers (with the notable exception of # ldap://keyserver.pgp.com) synchronize changes with each other. Note # also that a single server name may actually point to multiple # servers via DNS round-robin. hkp://keys.gnupg.net is an example of # such a \"server\", which spreads the load over a number of physical # servers. To see the IP address of the server actually used, you may use # the \"--keyserver-options debug\". keyserver hkp://pgp.mit.edu #keyserver hkps://hkps.pool.sks-keyservers.net #keyserver http://http-keys.gnupg.net #keyserver mailto:pgp-public-keys@keys.nl.pgp.net # Common options for keyserver functions: # # include-disabled = when searching, include keys marked as \"disabled\" # on the keyserver (not all keyservers support this). # # no-include-revoked = when searching, do not include keys marked as # \"revoked\" on the keyserver. # # verbose = show more information as the keys are fetched. # Can be used more than once to increase the amount # of information shown. # # use-temp-files = use temporary files instead of a pipe to talk to the # keyserver. Some platforms (Win32 for one) always # have this on. # # keep-temp-files = do not delete temporary files after using them # (really only useful for debugging) # # honor-http-proxy = if the keyserver uses HTTP, honor the http_proxy # environment variable # # broken-http-proxy = try to work around a buggy HTTP proxy # # auto-key-retrieve = automatically fetch keys as needed from the keyserver # when verifying signatures or when importing keys that # have been revoked by a revocation key that is not # present on the keyring. # # no-include-attributes = do not include attribute IDs (aka \"photo IDs\") # when sending keys to the keyserver. keyserver-options auto-key-retrieve # Uncomment this line to display photo user IDs in key listings and # when a signature from a key with a photo is verified. #show-photos # Use this program to display photo user IDs # # %i is expanded to a temporary file that contains the photo. # %I is the same as %i, but the file isn't deleted afterwards by GnuPG. # %k is expanded to the key ID of the key. # %K is expanded to the long OpenPGP key ID of the key. # %t is expanded to the extension of the image (e.g. \"jpg\"). # %T is expanded to the MIME type of the image (e.g. \"image/jpeg\"). # %f is expanded to the fingerprint of the key. # %% is %, of course. # # If %i or %I are not present, then the photo is supplied to the # viewer on standard input. If your platform supports it, standard # input is the best way to do this as it avoids the time and effort in # generating and then cleaning up a secure temp file. # # The default program is \"xloadimage -fork -quiet -title 'KeyID 0x%k' stdin\" # On Mac OS X and Windows, the default is to use your regular JPEG image # viewer. # # Some other viewers: # photo-viewer \"qiv %i\" # photo-viewer \"ee %i\" # photo-viewer \"display -title 'KeyID 0x%k'\" # # This one saves a copy of the photo ID in your home directory: # photo-viewer \"cat > ~/photoid-for-key-%k.%t\" # # Use your MIME handler to view photos: # photo-viewer \"metamail -q -d -b -c %T -s 'KeyID 0x%k' -f GnuPG\" # *** Options for GPGTools *** # Automatic key location # # GnuPG can automatically locate and retrieve keys as needed using the # auto-key-locate option. This happens when encrypting to an email # address (in the \"user@example.com\" form), and there are no # user@example.com keys on the local keyring. This option takes the # following arguments, in the order they are to be tried: # # cert = locate a key using DNS CERT, as specified in RFC-4398. # GnuPG can handle both the PGP (key) and IPGP (URL + fingerprint) # CERT methods. # # pka = locate a key using DNS PKA. # # ldap = locate a key using the PGP Universal method of checking # \"ldap://keys.(thedomain)\". For example, encrypting to # user@example.com will check ldap://keys.example.com. # # keyserver = locate a key using whatever keyserver is defined using # the keyserver option. # # You may also list arbitrary keyservers here by URL. # # Try CERT, then PKA, then LDAP, then hkp://keys.gnupg.net: auto-key-locate keyserver comment An encrypted message received, deserves an encrypted reply! cert-digest-algo SHA512 default-preference-list SHA512 SHA384 SHA256 SHA224 AES256 AES192 AES CAST5 ZLIB BZIP2 ZIP Uncompressed personal-digest-preferences SHA512 SHA384 SHA256 SHA224 no-emit-version cipher-algo AES256 digest-algo SHA512 #pinentry-program /usr/bin/pinentry-curses","title":"PGP"},{"location":"pgp/#pgp","text":"","title":"PGP:"},{"location":"pgp/#public-pgp-global-directory","text":"","title":"Public PGP Global Directory"},{"location":"pgp/#youtube-videos","text":"GnuPG Part One GnuPG Part Two GnuPG Part Three NITC-GnuPG Part 3","title":"Youtube Videos:"},{"location":"pgp/#generatecreate-gpgpgp-key","text":"gpg2 --full-gen-key gpg --gen-key Versions older than 2.1.17 use: gpg --default-new-key-algo rsa4096 --gen-key","title":"Generate/Create GPG/PGP Key:"},{"location":"pgp/#change-your-password-if-you-want-to","text":"gpg --edit-key YourKeyID Then type: passwd","title":"Change your password if you want to:"},{"location":"pgp/#send-key-to-default-key-server","text":"gpg --send-key KEYNAME gpg --export your_address@example.net | curl -T - https://keys.openpgp.org gpg --export your_address@example.net > my_key.pub You can upload your key to this PGP site: https://keyserver.pgp.com You can check if your key is on the PGP website here: https://keyserver.pgp.com","title":"Send key to default key server:"},{"location":"pgp/#to-send-your-public-key-to-a-keyserver","text":"gpg --keyserver the.keyserver.name.com --send-keys YOURKEYID Example: gpg --keyserver keyserver.ubuntu.com --send-keys 5DD98B3E Example: gpg --keyserver hkp://pgp.mit.edu --send-keys YOURKEYID Example: gpg --keyserver hkps.pool.sks-keyservers.net --send-keys YOURKEYID","title":"To send your public key to a keyserver:"},{"location":"pgp/#to-receive-a-public-key-from-a-keyserver","text":"Example: gpg --keyserver the.keyserver.name.com --recv-keys THEKEYID Example: gpg --keyserver keyserver.ubuntu.com --recv-keys 5DD98B3E","title":"To receive a public key from a keyserver:"},{"location":"pgp/#to-locate-the-key-of-a-user-by-email-address","text":"Example: gpg --auto-key-locate keyserver --locate-keys user@example.net","title":"To locate the key of a user, by email address:"},{"location":"pgp/#to-refresh-all-your-keys-eg-new-revocation-certificates-and-subkeys","text":"Example: gpg --refresh-keys","title":"To refresh all your keys (e.g. new revocation certificates and subkeys):"},{"location":"pgp/#export-ascii-armored-key","text":"gpg --export --armor jqdoe@example.com > jqdoe-pubkey.asc gpg --export-secret-keys --armor jqdoe@example.com >> jqdoe-privkey.asc Use a double greater than symbol to export both public and private to the same file \">>\".","title":"Export ascii armored key:"},{"location":"pgp/#encrypt-a-message-to-standard-output","text":"gpg -ea Enter your recipients and end with an empty line. Type your message that you want to encrypt. Press Control+D and your encrypted message will appear onscreen.","title":"Encrypt a message to standard output:"},{"location":"pgp/#encrypt-message-to-a-file-you-can-type","text":"gpg -ea > filename.txt then do the steps above. Enter your recipients and end with an empty line. Type your message that you want to encrypt. Press Control+D and your encrypted message will be sent to filename.txt.","title":"Encrypt message to a file you can type:"},{"location":"pgp/#encrypt-a-single-file-creates-a-binary-file-this-option-may-be-combined-with-sign","text":"gpg -e filename or gpg --encrypt filename","title":"Encrypt a single file (creates a binary file). This option may be combined with --sign."},{"location":"pgp/#encrypt-a-single-file-creates-an-ascii-file-this-option-may-be-combined-with-sign","text":"gpg -a -e filename or gpg --armor --encrypt filename or gpg -ea filename This is a special version of the --encrypt command. The command expects the files to be encrypted either on the command line or reads the filenames from stdin; each name must be on separate line. The command is intended for a quick encryption of multiple files.","title":"Encrypt a single file (creates an ASCII file). This option may be combined with --sign."},{"location":"pgp/#encrypt-multiple-files-this-option-may-be-combined-with-sign","text":"This will prompt you for your password for each file. gpg --encrypt-files file1 file2 file3 or add a recipient (your own key) to not be prompted. gpg --encrypt-files -r A1B2C3D4E5F6 *.txt","title":"Encrypt multiple files. This option may be combined with --sign."},{"location":"pgp/#batch-encrypt-using-multi-file","text":"gpg --multifile --encrypt --armor -r brothers *.txtrh","title":"Batch encrypt using --multi-file:"},{"location":"pgp/#bash-script-to-batch-encrypt-multiple-files","text":"for file in *.txtrh do # echo \"gpg --encrypt --armor -r 7FEBFF2F6AB4F024 -r D1BD917D4AF9F0EC\" > ~/\"$file\" # gpg --encrypt --armor -r 7FEBFF2F6AB4F024 -r D1BD917D4AF9F0EC \"$file\" gpg --encrypt --armor -r brothers \"$file\" # echo \"============== $file\" done","title":"Bash script to batch encrypt multiple files:"},{"location":"pgp/#encrypt-with-symmetric-cipher-only-this-command-asks-for-a-passphrase-may-also-be-combined-with-sign-see-gnupg-107-released","text":"gpg -c filename or gpg --symmetric filename","title":"Encrypt with symmetric cipher only. This command asks for a passphrase. (May also be combined with --sign -- see GnuPG 1.0.7 released.)"},{"location":"pgp/#batch-encrypt-multiple-files-to-specified-recipients-encryptsh-make-sure-your-file-variable-is-surrounded-by-quotes-so-that-files-with-spaces-in-their-names-will-get-picked-up","text":"for file in *.txt do gpg --encrypt -r A1B2C3D4E5F6G7H8 -r I1J2K3L4M5N6O7P8 \"$file\" done","title":"Batch Encrypt multiple files to specified recipients (encrypt.sh). Make sure your $file variable is surrounded by quotes so that files with spaces in their names will get picked up."},{"location":"pgp/#encrypt-to-a-recipient","text":"gpg -e -r recipient filename or gpg --encrypt -r recipient filename or encrypt and sign. gpg -e -r recipient -s filename Use -u to specify the secret key to be used, and -r to specify the public key of the recipient. **Note: This doesn't seem to work when you have a default sender and recipient key established in gpg.conf because the default sender and recipient overwrite the \"-u\" option. gpg -e -u \"Sender User Name\" -r \"Receiver User Name\" somefile Example 1: gpg -e -u \"me@example.com\" -r \"you@example.com\" -r \"them@example.com\" somefile Example 2: gpg -e -u \"Billy Bob\" -r \"Nancy Bob\" mydata.tar Example 3: gpg -s --default-key ABCD1234 -ea yyy.txt","title":"Encrypt to a recipient."},{"location":"pgp/#password-encrypt-and-sign-a-file","text":"gpg -c -s filename","title":"Password encrypt and sign a file:"},{"location":"pgp/#password-encrypt-and-sign-a-message-that-can-be-decrypted-by-passphrase-or-secret-key","text":"gpg -c --sign --encrypt filename or gpg -c -s -e filename","title":"Password encrypt and sign a message that can be decrypted by passphrase or secret key:"},{"location":"pgp/#uuencode-a-file-before-ascii-encrypting","text":"uuencode filename filename > filename.uue gpg -a -e filename.uue","title":"UUEncode a file before ascii encrypting:"},{"location":"pgp/#uuencode-a-file-before-normal-encrypting","text":"uuencode filename filename > filename.uue gpg --encrypt filename.uue","title":"UUEncode a file before normal encrypting:"},{"location":"pgp/#decrypt-uuencoded-file-with-normal-encryption-then-uudecode-it","text":"gpg --decrypt filename > filename.uue uudecode filename.uue","title":"Decrypt UUEncoded file with normal encryption then UUDecode it:"},{"location":"pgp/#decrypt-a-message-in-standard-out-stout-type","text":"gpg You will see a message similar to this: gpg: Go ahead and type your message ... At this point you can paste in the encrypted text and you will be prompted for your passphrase. Once you enter your passphrase, press Control+D to see the decrypted message. Decrypt file (or stdin if no file is specified) and write it to stdout (or the file specified with --output). If the decrypted file is signed, the signature is also verified. This command differs from the default operation, as it never writes to the filename which is included in the file and it rejects files which don't begin with an encrypted message. gpg --decrypt filenames","title":"Decrypt a message in standard out (stout) type:"},{"location":"pgp/#decrypt-a-file-that-has-been-binary-or-ascii-encrypted-and-output-the-decrypted-content-to-a-file","text":"gpg --output decrypted.txt --decrypt encrypted.txt.gpg or gpg -o decrypted.txt -d encrypted.txt.gpg This is a special version of the --decrypt command. The command expects the files to be decrypted either on the command line or reads the filenames from stdin; each name must be on separate line. The command is intended for a quick decryption of multiple files. gpg --decrypt-files file1 file2 file3","title":"Decrypt a file that has been binary or ascii encrypted and output the decrypted content to a file:"},{"location":"pgp/#multiple-private-keys","text":"When encrypting or decrypting it is possible to have more than one private key in use. To use a different private key other than the default use the option -u UID or use the option --local-user UID. This causes the default key used to be replaced by the wanted key. gpg -u <KEY ID> -r recipient --armor --sign --encrypt filename or gpg -u <KEY ID> -r recipient -a -s -e filename or (this should prompt you for recipients) gpg -u nameofprivatekey -a -s -e filename","title":"Multiple Private Keys."},{"location":"pgp/#signing-verifying","text":"Make a signature. This command may be combined with --encrypt. (May also be combined with --symmetric (see GnuPG 1.0.7 released.) gpg -s filename or gpg --sign filename Both -s and --sign make an illegible signature that you can't read. This is OK because GPG/PGP can still read it (not humans).","title":"Signing / Verifying:"},{"location":"pgp/#make-a-clear-text-signature","text":"gpg --clearsign filename or cat filename.txt| gpg --clearsign > some_file.txt or echo \"The message\" | gpg --clearsign > The_message.txt","title":"Make a clear text signature."},{"location":"pgp/#make-a-detached-signature","text":"gpg -b filename or gpg --detach-sign filename","title":"Make a detached signature."},{"location":"pgp/#verify-a-signature-file-without-generating-any-output","text":"With no arguments, the signature packet is read from stdin. If only a sigfile is given, it may be a complete signature or a detached signature, in which case the signed stuff is expected in a file without the \".sig\" or \".asc\" extension. With more than 1 argument, the first should be a detached signature and the remaining files are the signed stuff. To read the signed stuff from stdin, use - as the second filename. For security reasons a detached signature cannot read the signed material from stdin without denoting it in the above way. gpg --verify sigfile signed_files This is a special version of the --verify command which does not work with detached signatures. The command expects the files to be verified either on the command line or reads the filenames from stdin; each name must be on separate line. The command is intended for quick checking of many files. gpg --verify-files filenames","title":"Verify a signature file without generating any output."},{"location":"pgp/#create-ascii-armored-output","text":"gpg -a -e filename or gpg --armor -e filename Assume the input data is not in ASCII armored format. gpg --no-armor Use canonical text mode. If -t (but not --textmode) is used together with armoring and signing, this enables clearsigned messages. This kludge is needed for PGP compatibility; normally you would use --sign or --clearsign to select the type of the signature. gpg -t or gpg --textmode Encrypt for user id name. If this option is not specified, GnuPG asks for the user-id unless --default-recipient is given. gpg -r nameofkey or gpg --recipient nameofkey","title":"Create ASCII armored output."},{"location":"pgp/#groups","text":"Set up a name group, which is similar to aliases in email programs. Any time the group name is a receipient (-r or --recipient), it will be expanded to the values specified. The values are key IDs or fingerprints, but any key description is accepted. Note that a value with spaces in it will be treated as two different values. Note also there is only one level of expansion -- you cannot make a group that points to another group. gpg --group name=value Use name as default recipient if option --recipient is not used and don't ask if this is a valid one. name must be non-empty. gpg --default-recipient nameofkey Use the default key as default recipient if option --recipient is not used and don't ask if this is a valid one. The default key is the first one from the secret keyring or the one set with --default-key. gpg --default-recipient-self Reset --default-recipient and --default-recipient-self. gpg --no-default-recipient Use name as default user ID for signatures. If this is not used the default user ID is the first user ID found in the secret keyring. gpg --default-key nameofkey Same as --recipient but this one is intended for use in the options file and may be used with your own user-id as an \"encrypt-to-self.\" These keys are only used when there are other recipients given either by use of --recipient or by the asked user id. No trust checking is performed for these user ids and even disabled keys can be used. gpg --encrypt-to name Disable the use of all --encrypt-to keys. gpg --no-encrypt-to","title":"Groups"},{"location":"pgp/#comments-versions","text":"Use string as comment string in clear text signatures. The default is not to write a comment string. gpg --comment string Force to write the standard comment string in clear text signatures. Use this to overwrite a --comment from a config file. This option is now obsolete because there is no default comment string anymore. gpg --default-comment Omit the version string in clear text signatures. gpg --no-version Force to write the version string in clear text signatures. Use this to overwrite a previous --no-version from a config file. gpg --emit-version","title":"Comments &amp; Versions"},{"location":"pgp/#special-for-your-eyes-only","text":"Set the \"for your eyes only\" flag in the message. This causes GnuPG to refuse to save the file unless the --output option is given, and PGP to use the \"secure viewer\" with a Tempest-resistant font to display the message. This option overrides --set-filename. --for-your-eyes-only Resets the --for-your-eyes-only flag. --no-for-your-eyes-only Set compression level to n. A value of 0 for n disables compression. Default is to use the default compression level of zlib (normally 6). -z n, --compress n Skip the signature verification step. This may be used to make the decryption faster if the signature verification is not needed. --skip-verify When making a data signature, prompt for an expiration time. If this option is not specified, the expiration time is \"never.\" gpg --ask-sig-expire Resets the --ask-sig-expire option. gpg --no-ask-sig-expire Do not put the keyid into encrypted packets. This option hides the receiver of the message and is a countermeasure against traffic analysis. It may slow down the decryption process because all available secret keys are tried. gpg --throw-keyid Don't look at the key ID as stored in the message but try all secret keys in turn to find the right decryption key. This option forces the behaviour as used by anonymous recipients (created by using --throw-keyid) and might come handy in case where an encrypted message contains a bogus key ID. gpg --try-all-secrets Put the name value pair into the signature as notation data. Name must consist only of alphanumeric characters, digits or the underscore; the first character must not be a digit. Value may be any printable string; it will be encoded in UTF8, so you should check that your --charset is set correctly. If you prefix name with an exclamation mark, the notation data will be flagged as critical (rfc2440:5.2.3.15). gpg -N gpg --notation-data name=value This option changes the behavior of cleartext signatures so that they can be used for patch files. You should not send such an armored file via email because all spaces and line endings are hashed too. You can not use this option for data which has 5 dashes at the beginning of a line, patch files don't have this. A special armor header line tells GnuPG about this cleartext signature option. gpg --not-dash-escaped Because some mailers change lines starting with \"From \" to \"<From \" it is good to handle such lines in a special way when creating cleartext signatures. All other PGP versions do it this way too. This option is not enabled by default because it would violate rfc2440. gpg --escape-from-lines Use string as the name of file which is stored in messages. gpg --set-filename string Try to create a file with a name as embedded in the data. This can be a dangerous option as it allows to overwrite files. gpg --use-embedded-filename This option enables a mode in which filenames of the form \"-&n,\" where n is a non-negative decimal number, refer to the file descriptor n and not to a file with that name. gpg --enable-special-filenames","title":"Special \"for your eyes only\""},{"location":"pgp/#revoke-a-key","text":"gpg --gen-revoke THEKEYID > revoked.key This creates a revocation certificate. To be able to do this, you need a secret key, otherwise anyone could revoke your certificate. This has one disadvantage. If you do not know the passphrase for the secret key, the revocation key will become useless and you cannot revoke the secret key! To overcome this problem it is wise to create a revoke license when you create a key pair. And if you do so, keep it safe! This can be on disk, paper, etc. Make sure that this certificate will not fall into wrong hands!!!! If you don't someone else can issue the revoke certificate for your key and make it useless. You will need to enter the revoke reason for the key and an optional comment. Once you have the revocation certificate, you will need to import it so that the key will get revoked. gpg --import revoked.key Type: gpg --list-keys and you will see that the key has been revoked. Next, you will have to send the revoked key to the key server. This is the same method as sending a normal key except this one has been revoked. When the server receives the revoked key, it will be removed from the server.","title":"Revoke a Key."},{"location":"pgp/#removerevoke-a-specific-email-address-from-your-key","text":"gpg --edit-key 01234567 uid 4 (This is the uid of the email address that you want to revoke). revuid Really revoke this user ID? (y/N) y Please select the reason for the revocation: 0 = No reason specified 4 = User ID is no longer valid Q = Cancel (Probably you want to select 4 here) Your decision? 4 Enter an optional description; end it with an empty line: > Reason for revocation: User ID is no longer valid (No description given) Is this okay? (y/N) y You need a passphrase to unlock the secret key for user: \"John Doe <john@doe.tld>\" [ultimate] (1). John Doe <john@doe.tld> [ revoked] (2) John Doe (Corp) <john.doe@corp.tld> gpg> save Next, send your updated key to the keyservers. gpg --send-keys 01234567 gpg: sending key 01234567 to hkp server keys.gnupg.net There are three main rings of keyservers out there ( Source ). Each group syncs within it's own pool well, and to the other pools with varying levels of success, so I recommend uploading to one of each. Something like this will work. servers=\"x-hkp://pool.sks-keyservers.net pgp.mit.edu wwwkeys.ch.pgp.net\" for server in $servers; do gpg --keyserver $server --send-key <your_keyid> done","title":"Remove/Revoke a specific email address from your key."},{"location":"pgp/#key-administration","text":"With the GnuPG system comes a file that acts as some kind of database. In this file all data regarding keys with the information that comes with the keys is stored.","title":"Key Administration:"},{"location":"pgp/#list-all-the-keys","text":"This will show you the key IDs and other information: gpg --list-keys To show the \"Short Key\" ID: gpg -K --with-fingerprint --with-colons | grep \"sec\" | cut -f5 -d ':' To show the \"HEX Key\" ID (last 16 characters with 0x prepended): gpg -K --with-fingerprint --with-colons | grep \"sec\" | cut -f5 -d ':'|awk '{print \"0x\" $1}' List all the keys and see the signatures as well type: gpg --list-sigs To see the fingerprints type: gpg --fingerprint You want to see \"Fingerprints\" to ensure that somebody is really the person they claim (like in a telephone call). This command will result in a list of relatively small numbers. To list the secret keys you type: gpg --list-secret-keys Note that listing fingerprints and signatures from private keys has no use whatsoever. To delete a public key you type: gpg --delete-key UID To delete a secret key you type: gpg --delete-secret-key UID (You have to delete the private key before deleting the public key) There is one more important command that is relevant for working with keys. gpg --edit-key <HEX KEY ID> Using this you can edit (among other things) the expiration date, add a fingerprint and sign your key. When in this mode you can press the question mark key to see the options available to you. Import a key: gpg --import filename You might get an error with the newer version of GPG (gpg: error building skey array: Permission denied) or (gpg: error building skey array: No pinentry). Try using (--batch): gpg --batch --import your.secret.key.asc Export your key: Export public key in binary format: gpg --export <KEY ID> Export public key in ascii format: gpg --export -a <KEY ID> Export secret key in binary format: gpg --export-secret-key <KEY ID> Export secret key in ascii format: gpg --export-secret-key -a <KEY ID>","title":"List all the keys:"},{"location":"pgp/#source","text":"https://www.gnupg.org/gph/en/manual/x110.html http://www.dewinter.com/gnupg_howto/english/GPGMiniHowto-3.html#ss3.5 https://www.gnupg.org/documentation/howtos.html https://github.com/rldutch1/pgp/blob/master/commandline_switches.html","title":"Source:"},{"location":"pgp/#shell-function-for-pgp","text":"Here is a PGP function that I have created and use on my Mac and Linux computers (it works on Windows too with Git or Cygwin installed). I named it \"pgp\" so that it is different from gpg on Linux/Mac and will not conflict. pgp(){ clear case $1 in ascii) echo \"ASCII Encrypting... \" $2 gpg -a -e $2 echo \"...\" >> $2;rm -f $2 echo $2 \" has been deleted!\" ;; clearsign) echo \"Signing...\" $2 gpg --clearsign $2 echo $2 \" has been signed!\" ;; decrypt) #gpg --decrypt $2 if [ ! $2 ] || [ ! $3 ]; then echo \"Syntax: pgp decrypt outputfile encryptedfile.asc\" else gpg --output $2 --decrypt $3 fi ;; delete-keys) echo \"Deleting...\" $2 gpg --delete-keys $2 gpg --list-keys ;; detachedsig) echo \"Creating signature file...\" $2 gpg --output $2.sig --detach-sig $2 ;; encrypt) echo \"Encrypting...\" $2 gpg --encrypt $2 echo \"...\" > $2;rm -f $2 echo $2 \" has been deleted!\" ;; exportpublic) echo \"Exporting Public Key...\" $2 gpg --export --armor $2 > $2.asc ;; exportprivate) echo \"Exporting PRIVATE KEY...\" $2 gpg --export --armor $2 > $2.asc gpg --export-secret-keys --armor $2 >> $2.asc ;; fingerprint) gpg --fingerprint $2 ;; fingerprint_from_file) gpg --with-fingerprint $2 ;; import) echo \"Importing...\" $2 gpg --import $2 echo $2 \" has been imported!\" ;; list) gpg --list-keys ;; listdirs) gpgconf --list-dirs ;; message) cd ~/Documents/PGP/messages xyzrh1=message.`date +\"%Y%m%d%H%M%S%Z\"` vi $xyzrh1.txt; pgp ascii $xyzrh1.txt ;; passencrypt) echo \"Encrypting...\" $2 gpg -c -s $2 echo $2 \" has been password encrypted!\" ;; releasecache) gpgconf --kill gpg-agent;gpgconf --launch gpg-agent ;; receivekeys) gpg --keyserver $2 --recv-keys $3 ;; revoke_key) gpg --gen-revoke $2 > revoke.$2.asc ;; sign) echo \"Signing...\" $2 gpg --sign $2 echo $2 \" has been signed!\" ;; sendkeys) if [ ! $2 ]; then echo \"Example: gpg --keyserver hkp://pgp.mit.edu --send-keys 6EE89C2D\" else gpg --keyserver $2 --send-keys $3 fi ;; showphoto) if [ ! $2 ]; then echo \"Should have xloadimage installed:\" echo \"Example:\" echo \"showphoto 6EE89C2D\" echo \"showphoto user@example.com\" else gpg --list-options show-photos --fingerprint $2 fi ;; update) gpg --update-trustdb ;; uue) echo \"UUEncoding...\" $2 uuencode $2 $2 > $2.uue echo \"ASCII Encrypting...\" $2.uue gpg -a -e $2.uue echo \"...\" > $2.uue;rm -f $2 $2.uue echo $2 \" has been deleted!\" ;; uuegpg) echo \"UUEncoding...\" $2 uuencode $2 $2 > $2.uue echo \"Encrypting...\" $2.uue gpg --encrypt $2.uue echo \"...\" > $2.uue;rm -f $2 $2.uue echo $2 \" has been deleted!\" ;; uuedecrypt) #echo \"Decrypting...\" $2 gpg --decrypt $2 > $2.uue echo \"Decoding...\" $2 uudecode $2.uue; echo \"...\" > $2.uue;rm -f $2.uue echo $2 \" has been decoded!\" ;; verify) echo \"Signing...\" $2 gpg --verify $2 echo $2 \" verify status!\" ;; *) message00=\"gpg --edit-key 5DD98B3E\" message01=\"pgp ascii textfile (gpg -a -e thefilename)\" message02=\"pgp clearsign textfile (gpg --clearsign thefilename)\" message03=\"pgp decrypt outputfile.tar encryptedfile.tar.gpg (gpg -o outputfile -d encryptedfile)\" message04=\"pgp delete-keys 5DD98B3E (gpg --delete-keys keyname)\" message05=\"pgp detachedsig filename (gpg --output doc.sig --detach-sig doc.txt)\" message06=\"pgp encrypt filename (gpg --encrypt thefilename)\" message07=\"pgp exportpublic keyname (gpg --export --armor thekeyname)\" message08=\"pgp exportprivate keyname (gpg --export-secret-keys --armor ABCD1234 >> ABCD1234.asc)\" message09=\"pgp fingerprint 5DD98B3E (gpg --fingerprint key)\" message10=\"pgp fingerprint_from_file file_with_key (gpg --with-fingerprint thefilename)\" message11=\"pgp import filename.asc (gpg --import keyfile / gpg2 --import keyfile)\" message12=\"pgp list (gpg --list-keys)\" message13=\"pgp listdirs (gpgconf --list-dirs)\" message14=\"pgp message\" message15=\"pgp passencrypt textfile (gpg -c -s thefilename)\" message16=\"pgp receivekeys theservername thekeyname (gpg --keyserver keyserver.ubuntu.com --recv-keys 6EE89C2D)\" message17=\"pgp releasecache (gpgconf --kill gpg-agent;gpgconf --launch gpg-agent)\" message18=\"pgp revoke_key (gpg --gen-revoke thekeyname > revoke.thekeyname.asc)\" message19=\"pgp sendkeys theservername thekeyname (gpg --keyserver hkp://pgp.mit.edu --send-keys 6EE89C2D)\" message20=\"pgp showphoto 6EE89C2D (gpg --list-options show-photos --fingerprint 6EE89C2D)\" message21=\"pgp sign textfile (gpg --sign thefilename)\" message22=\"pgp update (gpg --update-trustdb)\" message23=\"pgp uue filename (uuencode thefilename thefilename > thefilename.uue;gpg -a -e thefilename.uue)\" message24=\"pgp uuedecrypt filename (gpg --decrypt thefilename > thefilename.uue;uudecode thefilename.uue)\" message25=\"pgp uuegpg filename (uuencode thefilename thefilename > thefilename.uue;gpg --encrypt thefilename.uue)\" message26=\"pgp verify filename (gpg --verify signaturefile)\" echo $message00 echo $message01 echo $message02 echo $message03 echo $message04 echo $message05 echo $message06 echo $message07 echo $message08 echo $message09 echo $message10 echo $message11 echo $message12 echo $message13 echo $message14 echo $message15 echo $message16 echo $message17 echo $message18 echo $message19 echo $message20 echo $message21 echo $message22 echo $message23 echo $message24 echo $message25 echo $message26 echo \" \" ;; esac }","title":"Shell Function for PGP:"},{"location":"pgp/#view-your-trust-database","text":"View your trust database and see the marginal and other trust information type: gpg --update-trustdb Before a key can be trusted it must be signed and the trust level applied by the key owner. Marginally (Marginal) trusted keys can also be trusted if 3 or more people you trust have chosen to trust the same key that you have marginally trusted. Or if 3 or more marginally trusted people marginally trust the same key then it will be considered trusted by your key.","title":"View your trust database:"},{"location":"pgp/#gpg-privacy-assistant-gpa","text":"Graphical user interface for GnuPG called GPG Privacy Assistant (GPA). It can be installed by typing: sudo apt-get -y install gpa sudo dnf -y install gpa","title":"GPG Privacy Assistant (GPA):"},{"location":"pgp/#passphrase-cache-timeout","text":"On Fedora Linux, the passphrase cache timeout was 300 seconds (5 minutes). I couldn't find where I could change that setting. I ended up installing dconf-editor and I was able to change the passphrase cache. I added screenshots (dconf-editor_settings##.png. I installed Open GnuPG on my Mac using: sudo port install gnupg2 I like it a lot better thant the GPG Suite that I was previously using because I can encrypt and decrypt from an SSH session without the GUI password prompt preventing me from decrypting something. I have also discovered that I no longer seem to be able to use the command 'gpg < encryptedfile'. I get a message that says it doesn't understand what I am trying to do. I actually have to paste in the encrypted content and press control+d. How can I force the system to ask the passphrase every time? Old versions of GnuPG uses the gpg-agent, which caches the passphrase for a given time. Use the option --no-use-agent or add a line no-use-agent to ~/.gnupg/gpg.conf to prevent using the agent. Note: --no-use-agent is obsolete in gpg2 and has no effect. Removing the passphrase cacheing and setting it to 1 second. I haven't tried this but it has a green checkmark on stackexchange. Edit: ~/.gnupg/gpg-agent.conf Add: default-cache-ttl 1 max-cache-ttl 1","title":"Passphrase cache timeout:"},{"location":"pgp/#reload-the-gpg-agent","text":"echo RELOADAGENT | gpg-connect-agent or Type: gpg-connect-agent At the prompt type: RELOADAGENT Response should be: OK At the prompt type: BYE Reponse should be: OK closing connection","title":"Reload the gpg agent:"},{"location":"pgp/#restart-the-gpg-agent","text":"Type: gpg-connect-agent At the prompt type: KILLAGENT Reponse should be: OK closing connection","title":"Restart the gpg agent:"},{"location":"pgp/#list-pgpgpg-directories","text":"gpgconf --list-dirs","title":"List PGP/GPG directories:"},{"location":"pgp/#miscellaneous","text":"gpg options --debug-level guru --debug-all --verbose gpg --debug-level guru --debug-all --verbose I was having trouble importing my private key because it was in an older version of GPG. I was getting the following errors: gpg: error building skey array: No such file or directory gpg import error sending to agent no such file or directory gpg: error building skey array: permission denied gpg: decryption failed: no secret key I had to decrypt my passphrase encrypted key using a user that did not have GPG enabled (root). I also renamed my .gnupg directory and ran gpg again so that a new .gnupg folder would get created. Inside that directory I had to manually create the private-keys-v1.d directory so the \"No such file or directory\" error would go away. I was still having issues and kept seeing a message telling me no private key present whenever I tried to decrypt something. I ended up restoring the .gnupg folder from a backup and restarting the gpg agent.","title":"Miscellaneous:"},{"location":"pgp/#pinentry","text":"Running gpg through SSH session sometimes will error when performing tasks. When I used the pinentry-mode, the password was cached but I was able to decrypt. gpg --decrypt --pinentry-mode=loopback <file> gpg -c -s --pinentry-mode=loopback <file>","title":"Pinentry"},{"location":"pgp/#keybase-error-adding-pgpgpg-key","text":"https://github.com/keybase/client/issues/22458","title":"Keybase error adding PGP/GPG key:"},{"location":"pgp/#gpgconf","text":"","title":"gpgconf:"},{"location":"pgp/#options","text":"Starting with GnuPG 1.1.92 (incl. GnuPG 1.2.1, 1.2.0 and 1.1.92), long options can be put in an options file (default \"~/.gnupg/gpg.conf\"). In GnuPG versions up through GnuPG 1.1.91 (incl. 1.0.6, 1.0.7, and 1.1.91), long options can be put in an \"old style\" configuration file (default \"~/.gnupg/options\"). Short option names will not work -- for example, armor is a valid option for the options file, while a is not. Do not write the 2 dashes, but simply the name of the option and any required arguments. Lines with a hash as the first non-white-space character are ignored. Commands may be put in this file too, but that does not make sense. Two useful entries for .gnupg/gpg.conf file. These entries will force GPG to use your key as default and automatically encrypt to your key. default-key 1A2B3CD4 encrypt-to 1A2B3CD4 #gpg-connect-agent","title":"Options"},{"location":"pgp/#gpgconf-example-file","text":"# These first three lines are not copied to the gpg.conf file in # the users home directory. # $Id$ # Options for GnuPG # Copyright 1998, 1999, 2000, 2001, 2002, 2003, # 2010 Free Software Foundation, Inc. # # This file is free software; as a special exception the author gives # unlimited permission to copy and/or distribute it, with or without # modifications, as long as this notice is preserved. # # This file is distributed in the hope that it will be useful, but # WITHOUT ANY WARRANTY, to the extent permitted by law; without even the # implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. # # Unless you specify which option file to use (with the command line # option \"--options filename\"), GnuPG uses the file ~/.gnupg/gpg.conf # by default. # # An options file can contain any long options which are available in # GnuPG. If the first non white space character of a line is a '#', # this line is ignored. Empty lines are also ignored. # # See the man page for a list of options. # Uncomment the following option to get rid of the copyright notice #no-greeting # If you have more than 1 secret key in your keyring, you may want to # uncomment the following option and set your preferred keyid. default-key ABCD1234 encrypt-to ABCD1234 # If you do not pass a recipient to gpg, it will ask for one. Using # this option you can encrypt to a default key. Key validation will # not be done in this case. The second form uses the default key as # default recipient. #default-recipient some-user-id #default-recipient-self #default-recipient ABCD1234 # By default GnuPG creates version 4 signatures for data files as # specified by OpenPGP. Some earlier (PGP 6, PGP 7) versions of PGP # require the older version 3 signatures. Setting this option forces # GnuPG to create version 3 signatures. #force-v3-sigs # Because some mailers change lines starting with \"From \" to \">From \" # it is good to handle such lines in a special way when creating # cleartext signatures; all other PGP versions do it this way too. # To enable full OpenPGP compliance you may want to use this option. no-escape-from-lines # When verifying a signature made from a subkey, ensure that the cross # certification \"back signature\" on the subkey is present and valid. # This protects against a subtle attack against subkeys that can sign. # Defaults to --no-require-cross-certification. However for new # installations it should be enabled. require-cross-certification # If you do not use the Latin-1 (ISO-8859-1) charset, you should tell # GnuPG which is the native character set. Please check the man page # for supported character sets. This character set is only used for # metadata and not for the actual message which does not undergo any # translation. Note that future version of GnuPG will change to UTF-8 # as default character set. #charset utf-8 # Group names may be defined like this: # group mynames = paige 0x12345678 joe patti # # Any time \"mynames\" is a recipient (-r or --recipient), it will be # expanded to the names \"paige\", \"joe\", and \"patti\", and the key ID # \"0x12345678\". Note there is only one level of expansion - you # cannot make an group that points to another group. Note also that # if there are spaces in the recipient name, this will appear as two # recipients. In these cases it is better to use the key ID. #group mynames = paige 0x12345678 joe patti group myfriends = BD4054DAC61AB7BB B1BC917D4AF9F0EC #no-mangle-dos-filenames # Lock the file only once for the lifetime of a process. If you do # not define this, the lock will be obtained and released every time # it is needed - normally this is not needed. #lock-once # GnuPG can send and receive keys to and from a keyserver. These # servers can be HKP, email, or LDAP (if GnuPG is built with LDAP # support). # # Example HKP keyservers: # hkp://keys.gnupg.net # # Example LDAP keyservers: # ldap://pgp.surfnet.nl:11370 # # Regular URL syntax applies, and you can set an alternate port # through the usual method: # hkp://keyserver.example.net:22742 # # If you have problems connecting to a HKP server through a buggy http # proxy, you can use keyserver option broken-http-proxy (see below), # but first you should make sure that you have read the man page # regarding proxies (keyserver option honor-http-proxy) # # Most users just set the name and type of their preferred keyserver. # Note that most servers (with the notable exception of # ldap://keyserver.pgp.com) synchronize changes with each other. Note # also that a single server name may actually point to multiple # servers via DNS round-robin. hkp://keys.gnupg.net is an example of # such a \"server\", which spreads the load over a number of physical # servers. To see the IP address of the server actually used, you may use # the \"--keyserver-options debug\". keyserver hkp://pgp.mit.edu #keyserver hkps://hkps.pool.sks-keyservers.net #keyserver http://http-keys.gnupg.net #keyserver mailto:pgp-public-keys@keys.nl.pgp.net # Common options for keyserver functions: # # include-disabled = when searching, include keys marked as \"disabled\" # on the keyserver (not all keyservers support this). # # no-include-revoked = when searching, do not include keys marked as # \"revoked\" on the keyserver. # # verbose = show more information as the keys are fetched. # Can be used more than once to increase the amount # of information shown. # # use-temp-files = use temporary files instead of a pipe to talk to the # keyserver. Some platforms (Win32 for one) always # have this on. # # keep-temp-files = do not delete temporary files after using them # (really only useful for debugging) # # honor-http-proxy = if the keyserver uses HTTP, honor the http_proxy # environment variable # # broken-http-proxy = try to work around a buggy HTTP proxy # # auto-key-retrieve = automatically fetch keys as needed from the keyserver # when verifying signatures or when importing keys that # have been revoked by a revocation key that is not # present on the keyring. # # no-include-attributes = do not include attribute IDs (aka \"photo IDs\") # when sending keys to the keyserver. keyserver-options auto-key-retrieve # Uncomment this line to display photo user IDs in key listings and # when a signature from a key with a photo is verified. #show-photos # Use this program to display photo user IDs # # %i is expanded to a temporary file that contains the photo. # %I is the same as %i, but the file isn't deleted afterwards by GnuPG. # %k is expanded to the key ID of the key. # %K is expanded to the long OpenPGP key ID of the key. # %t is expanded to the extension of the image (e.g. \"jpg\"). # %T is expanded to the MIME type of the image (e.g. \"image/jpeg\"). # %f is expanded to the fingerprint of the key. # %% is %, of course. # # If %i or %I are not present, then the photo is supplied to the # viewer on standard input. If your platform supports it, standard # input is the best way to do this as it avoids the time and effort in # generating and then cleaning up a secure temp file. # # The default program is \"xloadimage -fork -quiet -title 'KeyID 0x%k' stdin\" # On Mac OS X and Windows, the default is to use your regular JPEG image # viewer. # # Some other viewers: # photo-viewer \"qiv %i\" # photo-viewer \"ee %i\" # photo-viewer \"display -title 'KeyID 0x%k'\" # # This one saves a copy of the photo ID in your home directory: # photo-viewer \"cat > ~/photoid-for-key-%k.%t\" # # Use your MIME handler to view photos: # photo-viewer \"metamail -q -d -b -c %T -s 'KeyID 0x%k' -f GnuPG\" # *** Options for GPGTools *** # Automatic key location # # GnuPG can automatically locate and retrieve keys as needed using the # auto-key-locate option. This happens when encrypting to an email # address (in the \"user@example.com\" form), and there are no # user@example.com keys on the local keyring. This option takes the # following arguments, in the order they are to be tried: # # cert = locate a key using DNS CERT, as specified in RFC-4398. # GnuPG can handle both the PGP (key) and IPGP (URL + fingerprint) # CERT methods. # # pka = locate a key using DNS PKA. # # ldap = locate a key using the PGP Universal method of checking # \"ldap://keys.(thedomain)\". For example, encrypting to # user@example.com will check ldap://keys.example.com. # # keyserver = locate a key using whatever keyserver is defined using # the keyserver option. # # You may also list arbitrary keyservers here by URL. # # Try CERT, then PKA, then LDAP, then hkp://keys.gnupg.net: auto-key-locate keyserver comment An encrypted message received, deserves an encrypted reply! cert-digest-algo SHA512 default-preference-list SHA512 SHA384 SHA256 SHA224 AES256 AES192 AES CAST5 ZLIB BZIP2 ZIP Uncompressed personal-digest-preferences SHA512 SHA384 SHA256 SHA224 no-emit-version cipher-algo AES256 digest-algo SHA512 #pinentry-program /usr/bin/pinentry-curses","title":"gpg.conf Example File"},{"location":"rdesktop/","text":"RDESKTOP Large files: rdesktop -v -k en-us -a 32 -u rob -4 backup.lan:3389 rdesktop -v -k en-us -a 32 -u administrator -4 -g 1600x800 backup.lan:3389","title":"RDesktop"},{"location":"rdesktop/#rdesktop","text":"Large files: rdesktop -v -k en-us -a 32 -u rob -4 backup.lan:3389 rdesktop -v -k en-us -a 32 -u administrator -4 -g 1600x800 backup.lan:3389","title":"RDESKTOP"},{"location":"se_linux/","text":"Source: Places to search for AVC messages: Messages via Rsyslog are generated with \"kern\" facility. CentOS default Rsyslog setting is written as \"*.info;xxx /var/log/messages\", so AVC Denial Log is recorded to /var/log/messages. grep \"avc: .denied\" /var/log/messages Messages via Auditd are generated to /var/log/audit/audit.log. grep \"avc: .denied\" /var/log/audit/audit.log For Messages via Auditd, it's possible to search them with ausearch command. ausearch -m AVC For Messages via Auditd, it's possible to show summary reports with aureport command. aureport --avc --summary STAT command to show SE_Linux status: stat -c \"%a %n %C\" * Allow apache to receive files to an uploads folder/directory: sudo chown apache:apache -R /uploads sudo chcon -Rv --type=httpd_sys_rw_content_t uploads/ With /srv/ as the base directory you must adjust the SELinux labels. htdocs is where the index.php/html file goes. [\u2026]# /usr/sbin/semanage fcontext -a -t httpd_sys_content_t -s system_u \"/srv/SITENAME/htdocs(/.*)?\" [\u2026]# /sbin/restorecon -R -vF /srv/SITENAME/htdocs Relabeled /srv/SITENAME/htdocs from unconfined_u:object_r:var_t:s0 to system_u:object_r:httpd_sys_content_t:s0 Source: https://docs.fedoraproject.org/en-US/fedora-server/services/httpd-basic-setup/#_installation Change the SE Linux properties of a file: (Source: https://www.thegeekstuff.com/2017/07/chcon-command-examples/) Example: this Test2a.php file was displaying \"Access Denied\" error on my website. Check and change the SELinux properties: Check the current SELinux properties with: ls -Z The properties were: unconfined_u:object_r:user_home_t:s0 Test2a.php I changed the SELinux properties using: sudo chcon unconfined_u:object_r:httpd_user_content_t:s0 Test2a.php If you want to copy the SE_Linux settings from one directory that is working to another: # semanage fcontext --add --equal /var/www/html /opt/www/html # restorecon -rv /opt/www/html If you are using a non-standard directory for web files, like /opt/www/html, then you may not be able to use restorecon to automatically fix the SELinux context. You will have to set the context using chcon and save the change using semanage to make the change permanent: # chcon -R system_u:object_r:httpd_sys_content_t:s0 /opt/www # semanage fcontext -a -t httpd_sys_content_t \"/opt/www(/.*)?\" # restorecon -rv /opt/www If you get \"SQLSTATE[HY000] [2002] Permission denied\" message. You need to enable the httpd service to network connect. You must check in the SELinux if port 80 is managed in. You can check it by typing # semanage port -l | grep http_port_t for a list and check: semanage port -l | grep http_port_t If you need to add the required port, just type: # semanage port -a -t http_port_t -p tcp 80 Stop the httpd service set the SE_Linux permission and start the http service. Down the httpd service # service httpd stop Enable the httpd service to connect to the network: # setsebool -P httpd_can_network_connect 1 # setsebool -P httpd_can_network_connect_db 1 Check if the service is enabled: getsebool httpd_can_network_connect getsebool httpd_can_network_connect_db Up the httpd service # service httpd start","title":"SE Linux"},{"location":"se_linux/#places-to-search-for-avc-messages","text":"Messages via Rsyslog are generated with \"kern\" facility. CentOS default Rsyslog setting is written as \"*.info;xxx /var/log/messages\", so AVC Denial Log is recorded to /var/log/messages. grep \"avc: .denied\" /var/log/messages Messages via Auditd are generated to /var/log/audit/audit.log. grep \"avc: .denied\" /var/log/audit/audit.log For Messages via Auditd, it's possible to search them with ausearch command. ausearch -m AVC For Messages via Auditd, it's possible to show summary reports with aureport command. aureport --avc --summary STAT command to show SE_Linux status: stat -c \"%a %n %C\" * Allow apache to receive files to an uploads folder/directory: sudo chown apache:apache -R /uploads sudo chcon -Rv --type=httpd_sys_rw_content_t uploads/ With /srv/ as the base directory you must adjust the SELinux labels. htdocs is where the index.php/html file goes. [\u2026]# /usr/sbin/semanage fcontext -a -t httpd_sys_content_t -s system_u \"/srv/SITENAME/htdocs(/.*)?\" [\u2026]# /sbin/restorecon -R -vF /srv/SITENAME/htdocs Relabeled /srv/SITENAME/htdocs from unconfined_u:object_r:var_t:s0 to system_u:object_r:httpd_sys_content_t:s0 Source: https://docs.fedoraproject.org/en-US/fedora-server/services/httpd-basic-setup/#_installation Change the SE Linux properties of a file: (Source: https://www.thegeekstuff.com/2017/07/chcon-command-examples/) Example: this Test2a.php file was displaying \"Access Denied\" error on my website. Check and change the SELinux properties: Check the current SELinux properties with: ls -Z The properties were: unconfined_u:object_r:user_home_t:s0 Test2a.php I changed the SELinux properties using: sudo chcon unconfined_u:object_r:httpd_user_content_t:s0 Test2a.php If you want to copy the SE_Linux settings from one directory that is working to another: # semanage fcontext --add --equal /var/www/html /opt/www/html # restorecon -rv /opt/www/html If you are using a non-standard directory for web files, like /opt/www/html, then you may not be able to use restorecon to automatically fix the SELinux context. You will have to set the context using chcon and save the change using semanage to make the change permanent: # chcon -R system_u:object_r:httpd_sys_content_t:s0 /opt/www # semanage fcontext -a -t httpd_sys_content_t \"/opt/www(/.*)?\" # restorecon -rv /opt/www If you get \"SQLSTATE[HY000] [2002] Permission denied\" message. You need to enable the httpd service to network connect. You must check in the SELinux if port 80 is managed in. You can check it by typing # semanage port -l | grep http_port_t for a list and check: semanage port -l | grep http_port_t If you need to add the required port, just type: # semanage port -a -t http_port_t -p tcp 80 Stop the httpd service set the SE_Linux permission and start the http service. Down the httpd service # service httpd stop Enable the httpd service to connect to the network: # setsebool -P httpd_can_network_connect 1 # setsebool -P httpd_can_network_connect_db 1 Check if the service is enabled: getsebool httpd_can_network_connect getsebool httpd_can_network_connect_db Up the httpd service # service httpd start","title":"Places to search for AVC messages:"},{"location":"ssh/","text":"SSH Enable service to run at boot: systemctl enable sshd.service Start the SSH service: systemctl start sshd.service Offending ECDSA key in /home/someuser/.ssh/known_hosts:4 Remove with: ssh-keygen -f \"/home/someuser/.ssh/known_hosts\" -R \"theservername.com\" Copy SSH public key to remote computer: ssh-copy-id -i ~/.ssh/id_rsa.pub user@hostname SSH: Broadcast message: The system will suspend now! client_loop: send disconnect: Broken pipe You can display the current sleep/suspend settings with a command like this one: sudo -u gdm dbus-run-session gsettings list-recursively org.gnome.settings-daemon.plugins.power | grep sleep The problem of getting kicked out of the remote computer when the computer goes into hybernate mode was solved with the following: systemctl mask sleep.target suspend.target hibernate.target hybrid-sleep.target Source:","title":"SSH"},{"location":"ssh/#ssh","text":"Enable service to run at boot: systemctl enable sshd.service Start the SSH service: systemctl start sshd.service Offending ECDSA key in /home/someuser/.ssh/known_hosts:4 Remove with: ssh-keygen -f \"/home/someuser/.ssh/known_hosts\" -R \"theservername.com\" Copy SSH public key to remote computer: ssh-copy-id -i ~/.ssh/id_rsa.pub user@hostname","title":"SSH"},{"location":"ssh/#ssh-broadcast-message-the-system-will-suspend-now-client_loop-send-disconnect-broken-pipe","text":"You can display the current sleep/suspend settings with a command like this one: sudo -u gdm dbus-run-session gsettings list-recursively org.gnome.settings-daemon.plugins.power | grep sleep The problem of getting kicked out of the remote computer when the computer goes into hybernate mode was solved with the following: systemctl mask sleep.target suspend.target hibernate.target hybrid-sleep.target Source:","title":"SSH: Broadcast message: The system will suspend now! client_loop: send disconnect: Broken pipe"},{"location":"vi_editor/","text":"Write specific lines from a file to a new file. Example to write lines 230 through 300 to a new file: :230,300w filename.txt General Startup To use vi: vi filename To exit vi and save changes: ZZ or :wq To exit vi without saving changes: :q! To enter vi command mode: [esc] Counts A number preceding any vi command tells vi to repeat that command that many times. Cursor Movement h move left (backspace) j move down k move up l move right (spacebar) [return] move to the beginning of the next line $ last column on the current line 0 move cursor to the first column on the current line ^ move cursor to first nonblank column on the current line w move to the beginning of the next word or punctuation mark W move past the next space b move to the beginning of the previous word or punctuation mark B move to the beginning of the previous word, ignores punctuation e end of next word or punctuation mark E end of next word, ignoring punctuation H move cursor to the top of the screen M move cursor to the middle of the screen L move cursor to the bottom of the screen Screen Movement G move to the last line in the file xG move to line x z+ move current line to top of screen z move current line to the middle of screen z- move current line to the bottom of screen ^F move forward one screen ^B move backward one line ^D move forward one half screen ^U move backward one half screen ^R redraw screen ( does not work with VT100 type terminals ) ^L redraw screen ( does not work with Televideo terminals ) Inserting r replace character under cursor with next character typed R keep replacing character until [esc] is hit i insert before cursor a append after cursor A append at end of line O open line above cursor and enter append mode Deleting x delete character under cursor dd delete line under cursor dw delete word under cursor db delete word before cursor Copying Code yy (yank)'copies' line which may then be put by the p(put) command. Precede with a count for multiple lines. :t. will duplicate the line. :t 7 will copy it after line 7. :,+t0 will copy current and next line at the beginning of the file. :1,t$ will copy lines from beginning of the file to the current cursor position, to the end of the file. Put Command brings back previous deletion or yank of lines, words, or characters P bring back before cursor p bring back after cursor Find Commands ? finds a word going backwards / finds a word going forwards f finds a character on the line under the cursor going forward F finds a character on the line under the cursor going backwards t find a character on the current line going forward and stop one character before it T find a character on the current line going backward and stop one character before it ; repeat last f, F, t, T Find and Replace Commands :%s/hello/goodbye/g find hello and replace with goodbye :%s/^\\(.*\\)\\n\\1$/g delete duplicate lines :%s/\\n/ /g join lines together Miscellaneous Commands . repeat last command u undo last command issued U undoes all commands on one line xp deletes first character and inserts after second (swap) J join current line with the next line ^G display current line number % if at one parenthesis, will jump to its mate mx mark current line with character x 'x find line marked with character x NOTE: Marks are internal and not written to the file. Line Editor Mode Any commands from the line editor ex can be issued upon entering line mode. To enter: type ' : ' To exit: press [return] or [esc] ex Commands For a complete list consult the UNIX Programmer's Manual READING FILES copies (reads) filename after cursor in file currently editing :r filename WRITE FILE :w saves the current file without quitting :20,40w filename write the contents of the lines numbered 20 through 40 to a new file named filename MOVING :# move to line # :$ move to last line of file SHELL ESCAPE executes 'cmd' as a shell command. :!'cmd' Source :","title":"VI Editor"},{"location":"vi_editor/#write-specific-lines-from-a-file-to-a-new-file","text":"Example to write lines 230 through 300 to a new file: :230,300w filename.txt General Startup To use vi: vi filename To exit vi and save changes: ZZ or :wq To exit vi without saving changes: :q! To enter vi command mode: [esc] Counts A number preceding any vi command tells vi to repeat that command that many times. Cursor Movement h move left (backspace) j move down k move up l move right (spacebar) [return] move to the beginning of the next line $ last column on the current line 0 move cursor to the first column on the current line ^ move cursor to first nonblank column on the current line w move to the beginning of the next word or punctuation mark W move past the next space b move to the beginning of the previous word or punctuation mark B move to the beginning of the previous word, ignores punctuation e end of next word or punctuation mark E end of next word, ignoring punctuation H move cursor to the top of the screen M move cursor to the middle of the screen L move cursor to the bottom of the screen Screen Movement G move to the last line in the file xG move to line x z+ move current line to top of screen z move current line to the middle of screen z- move current line to the bottom of screen ^F move forward one screen ^B move backward one line ^D move forward one half screen ^U move backward one half screen ^R redraw screen ( does not work with VT100 type terminals ) ^L redraw screen ( does not work with Televideo terminals ) Inserting r replace character under cursor with next character typed R keep replacing character until [esc] is hit i insert before cursor a append after cursor A append at end of line O open line above cursor and enter append mode Deleting x delete character under cursor dd delete line under cursor dw delete word under cursor db delete word before cursor Copying Code yy (yank)'copies' line which may then be put by the p(put) command. Precede with a count for multiple lines. :t. will duplicate the line. :t 7 will copy it after line 7. :,+t0 will copy current and next line at the beginning of the file. :1,t$ will copy lines from beginning of the file to the current cursor position, to the end of the file. Put Command brings back previous deletion or yank of lines, words, or characters P bring back before cursor p bring back after cursor Find Commands ? finds a word going backwards / finds a word going forwards f finds a character on the line under the cursor going forward F finds a character on the line under the cursor going backwards t find a character on the current line going forward and stop one character before it T find a character on the current line going backward and stop one character before it ; repeat last f, F, t, T Find and Replace Commands :%s/hello/goodbye/g find hello and replace with goodbye :%s/^\\(.*\\)\\n\\1$/g delete duplicate lines :%s/\\n/ /g join lines together Miscellaneous Commands . repeat last command u undo last command issued U undoes all commands on one line xp deletes first character and inserts after second (swap) J join current line with the next line ^G display current line number % if at one parenthesis, will jump to its mate mx mark current line with character x 'x find line marked with character x NOTE: Marks are internal and not written to the file. Line Editor Mode Any commands from the line editor ex can be issued upon entering line mode. To enter: type ' : ' To exit: press [return] or [esc] ex Commands For a complete list consult the UNIX Programmer's Manual READING FILES copies (reads) filename after cursor in file currently editing :r filename WRITE FILE :w saves the current file without quitting :20,40w filename write the contents of the lines numbered 20 through 40 to a new file named filename MOVING :# move to line # :$ move to last line of file SHELL ESCAPE executes 'cmd' as a shell command. :!'cmd' Source :","title":"Write specific lines from a file to a new file."},{"location":"windows/","text":"Check what programs need to be upgraded: winget upgrade Upgrade all programs that need to be upgraded: winget upgrade --all MSC Files and Program Definition: DevModeRunAsUserConfig.msc - DevModeRunAsUserConfig WmiMgmt.msc - Windows Management Interface Management adsiedit.msc - Actice Directory Services Interface Management azman.msc - Authorization Manager certlm.msc - Certificates (Local Computer) certmgr.msc - Certificate Manager certsrv.msc - Certificate Service comexp.msc - Component Services compmgmt.msc - Component Manager devmgmt.msc - Device Manager devmoderunasuserconfig.msc diskmgmt.msc - Disk Management dnsmgmt.msc - DNS Management eventvwr.msc - Event Viewer fsmgmt.msc - File System Management gpedit.msc - Group Policy Editor gpmc.msc - Group Policy Management Console iis.msc - Internet Information Services iis6.msc - Internet Information Services 6 lusrmgr.msc - Local User Manager nfsmgmt.msc - NFS Managment perfmon.msc - Performance Monitor printmanagement.msc - Print Managment rsop.msc - Resultant Set of Policy secpol.msc - Security Policy services.msc - Services taskschd.msc - Task Scheduler tpm.msc - Trusted Platform Module wf.msc - Windows Firewall wsus.msc - Windows Software Update Services Shutdown a computer from the commandline: Old School: shutdown -m \\TargetComputer -r -t 0 -f & ping TargetComputer -t or runas /noprofile /user:BHS\\a-rlholland \"shutdown -m \\TargetComputer -r -t 0 -f\" & ping TargetComputer -t New School: Event Viewer Data for shutdown: Level=Information; Event ID=1074; Source=User32 shutdown /m \\TargetComputer /c \"incident#_or_message\" /d p:4:1 /r /t 0 /f & ping TargetComputer -t or runas /noprofile /user:BHS\\a-rlholland \"shutdown /m \\TargetComputer /c \\\"incident#_or_message\\\" /d p:4:1 /r /t 0 /f\" & ping TargetComputer -t From Administrator Command Prompt: net use A: \\TargetComputer\\c$ Remember to Flush and Register the computer in DNS. Tucson DNS 10.109.0.202 (TUSNS01) and 10.109.64.202 (TUSNS02) are the ones to use. runas /noprofile /user:BHS\\a-rlholland \"ipconfig /flushdns\" runas /noprofile /user:BHS\\a-rlholland \"ipconfig /registerdns\" Map a drive letter to Microsoft OneDrive. @echo off REM ---------------------------------------------------------------------------- REM Author: Robert Holland REM Name: MapH.cmd REM Creation Date: Thu Oct 14 2021 08:53:25 GMT-0700 (US Mountain Standard Time) REM Last Modified: REM Copyright (c)2021 REM Purpose: Locally Map H: drive to OneDrive REM ---------------------------------------------------------------------------- subst H: \"C:\\Users\\%username%\\OneDrive\\\" Run a command that causes all files and folders beginning with a period (to include period-underscore files) to become invisible, open Command Prompt, then run this: attrib +H J:.* /S /D (but be sure to change the drive from J: to the drive letter of your choice) Note that this attrib option will run through every file and folder on your drive, so this could take quite a long time, depending on the size of your disk.","title":"Windows"},{"location":"windows/#check-what-programs-need-to-be-upgraded","text":"winget upgrade","title":"Check what programs need to be upgraded:"},{"location":"windows/#upgrade-all-programs-that-need-to-be-upgraded","text":"winget upgrade --all","title":"Upgrade all programs that need to be upgraded:"},{"location":"windows/#msc-files-and-program-definition","text":"DevModeRunAsUserConfig.msc - DevModeRunAsUserConfig WmiMgmt.msc - Windows Management Interface Management adsiedit.msc - Actice Directory Services Interface Management azman.msc - Authorization Manager certlm.msc - Certificates (Local Computer) certmgr.msc - Certificate Manager certsrv.msc - Certificate Service comexp.msc - Component Services compmgmt.msc - Component Manager devmgmt.msc - Device Manager devmoderunasuserconfig.msc diskmgmt.msc - Disk Management dnsmgmt.msc - DNS Management eventvwr.msc - Event Viewer fsmgmt.msc - File System Management gpedit.msc - Group Policy Editor gpmc.msc - Group Policy Management Console iis.msc - Internet Information Services iis6.msc - Internet Information Services 6 lusrmgr.msc - Local User Manager nfsmgmt.msc - NFS Managment perfmon.msc - Performance Monitor printmanagement.msc - Print Managment rsop.msc - Resultant Set of Policy secpol.msc - Security Policy services.msc - Services taskschd.msc - Task Scheduler tpm.msc - Trusted Platform Module wf.msc - Windows Firewall wsus.msc - Windows Software Update Services","title":"MSC Files and Program Definition:"},{"location":"windows/#shutdown-a-computer-from-the-commandline","text":"Old School: shutdown -m \\TargetComputer -r -t 0 -f & ping TargetComputer -t or runas /noprofile /user:BHS\\a-rlholland \"shutdown -m \\TargetComputer -r -t 0 -f\" & ping TargetComputer -t New School: Event Viewer Data for shutdown: Level=Information; Event ID=1074; Source=User32 shutdown /m \\TargetComputer /c \"incident#_or_message\" /d p:4:1 /r /t 0 /f & ping TargetComputer -t or runas /noprofile /user:BHS\\a-rlholland \"shutdown /m \\TargetComputer /c \\\"incident#_or_message\\\" /d p:4:1 /r /t 0 /f\" & ping TargetComputer -t From Administrator Command Prompt: net use A: \\TargetComputer\\c$ Remember to Flush and Register the computer in DNS. Tucson DNS 10.109.0.202 (TUSNS01) and 10.109.64.202 (TUSNS02) are the ones to use. runas /noprofile /user:BHS\\a-rlholland \"ipconfig /flushdns\" runas /noprofile /user:BHS\\a-rlholland \"ipconfig /registerdns\" Map a drive letter to Microsoft OneDrive. @echo off REM ---------------------------------------------------------------------------- REM Author: Robert Holland REM Name: MapH.cmd REM Creation Date: Thu Oct 14 2021 08:53:25 GMT-0700 (US Mountain Standard Time) REM Last Modified: REM Copyright (c)2021 REM Purpose: Locally Map H: drive to OneDrive REM ---------------------------------------------------------------------------- subst H: \"C:\\Users\\%username%\\OneDrive\\\" Run a command that causes all files and folders beginning with a period (to include period-underscore files) to become invisible, open Command Prompt, then run this: attrib +H J:.* /S /D (but be sure to change the drive from J: to the drive letter of your choice) Note that this attrib option will run through every file and folder on your drive, so this could take quite a long time, depending on the size of your disk.","title":"Shutdown a computer from the commandline:"},{"location":"x11_forwarding/","text":"Enable X11 on Server Edit /etc/ssh/ssh_config ForwardX11 yes X11Forwarding yes Uncomment: X11DisplayOffset On Client: (This is all I needed for Fedora). Start Terminal and connect to the SSH server which is enabled X11 Forwarding with ssh -XC username@hostname For CentOS: After connecting, input commands like follows. $ eval dbus-launch --sh-syntax $ export DBUS_SESSION_BUS_ADDRESS $ export DBUS_SESSION_BUS_PID","title":"X11 Forwarding"},{"location":"youtube_dl/","text":"Youtube-DL (YT-DLP) To download a single video or an entire playlist from YouTube, simply enter the URL in the following format: yt-dlp https://www.youtube.com/watch?v=t5b20oLaIaw To download a video or playlist to a specific location, use the -o flag followed by the target directory. For example: yt-dlp -o '~/Downloads/Abdul Kalam Biography' https://www.youtube.com/watch?v=t5b20oLaIaw To include additional details in the filename, such as the title, uploader name, upload date, and playlist name, use the following format: yt-dlp -o '%(title)s by %(uploader)s on %(upload_date)s in %(playlist)s.%(ext)s' https://www.youtube.com/watch?v=t5b20oLaIaw Here is a breakdown of the different options used in the above commands: yt-dlp: The name of the command-line tool used to download videos and playlists. -o: The flag used to specify the output filename or directory. %(title)s: The title of the video or playlist. %(uploader)s: The name of the video or playlist uploader. %(upload_date)s: The date on which the video or playlist was uploaded. %(playlist)s: The name of the playlist, if the video is part of a playlist. %(ext)s: The file extension of the downloaded video or audio file. You can download multiple videos by specifying their URLs in the command, separated by spaces like so: yt-dlp or use a text file yt-dlp -a url.txt Download Audio-only from a Video: To download a video as Audio i.e. extract audio from a video, use -x flag like below. yt-dlp -x https://www.youtube.com/watch?v=t5b20oLaIaw You can also specify the output audio format using the -x --audio-format flag. yt-dlp -x --audio-format mp3 https://www.youtube.com/watch?v=t5b20oLaIaw To download a video along with its accompanying details, including description, metadata, annotations, subtitles, and thumbnail, use the following command: yt-dlp --write-description --write-info-json --write-annotations --write-sub --write-thumbnail These commands provide you with an overview of the various formats in which the content is accessible, assisting you in making an informed selection. To view a comprehensive list of all the available formats for a video or playlist, utilize the following command: yt-dlp --list-formats https://www.youtube.com/watch?v=t5b20oLaIaw Alternatively, you can achieve the same result with -F flag: yt-dlp -F https://www.youtube.com/watch?v=t5b20oLaIaw As you see from the output, yt-dlp presents a comprehensive display of all the accessible video formats in an organized tabular column. Moving from left to right, this display includes essential details such as ID, Extension (EXT), Resolution, Frames Per Second (FPS), Channel (CH), Filesize, Total Bitrate (TBR), Protocol (PROTO), Video Codec (VCODEC), Video Bitrate (VBR), Audio Codec (ACODEC), Audio Bitrate (ABR), Audio Sampling Rate (ASR), and additional information. Download vidoes by ID or video format: By ID: yt-dlp -f 247 https://www.youtube.com/watch?v=t5b20oLaIaw using -f 22/17/18 means it will attempt to download format 22 if available, then format 17 if format 22 is not available, and so on. By Format: To download video(s) in your preferred format, such as MP4, simply execute the following command: yt-dlp -f mp4 https://www.youtube.com/watch?v=t5b20oLaIaw yt-dlp -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best' https://www.youtube.com/watch?v=t5b20oLaIaw yt-dlp -f mp4 -o '%(title)s.f%(format_id)s.%(ext)s' https://www.youtube.com/watch?v=t5b20oLaIaw Source:","title":"Youtube-dl"},{"location":"youtube_dl/#youtube-dl-yt-dlp","text":"","title":"Youtube-DL (YT-DLP)"},{"location":"youtube_dl/#to-download-a-single-video-or-an-entire-playlist-from-youtube-simply-enter-the-url-in-the-following-format","text":"yt-dlp https://www.youtube.com/watch?v=t5b20oLaIaw","title":"To download a single video or an entire playlist from YouTube, simply enter the URL in the following format:"},{"location":"youtube_dl/#to-download-a-video-or-playlist-to-a-specific-location-use-the-o-flag-followed-by-the-target-directory-for-example","text":"yt-dlp -o '~/Downloads/Abdul Kalam Biography' https://www.youtube.com/watch?v=t5b20oLaIaw","title":"To download a video or playlist to a specific location, use the -o flag followed by the target directory. For example:"},{"location":"youtube_dl/#to-include-additional-details-in-the-filename-such-as-the-title-uploader-name-upload-date-and-playlist-name-use-the-following-format","text":"yt-dlp -o '%(title)s by %(uploader)s on %(upload_date)s in %(playlist)s.%(ext)s' https://www.youtube.com/watch?v=t5b20oLaIaw Here is a breakdown of the different options used in the above commands: yt-dlp: The name of the command-line tool used to download videos and playlists. -o: The flag used to specify the output filename or directory. %(title)s: The title of the video or playlist. %(uploader)s: The name of the video or playlist uploader. %(upload_date)s: The date on which the video or playlist was uploaded. %(playlist)s: The name of the playlist, if the video is part of a playlist. %(ext)s: The file extension of the downloaded video or audio file.","title":"To include additional details in the filename, such as the title, uploader name, upload date, and playlist name, use the following format:"},{"location":"youtube_dl/#you-can-download-multiple-videos-by-specifying-their-urls-in-the-command-separated-by-spaces-like-so","text":"yt-dlp or use a text file yt-dlp -a url.txt","title":"You can download multiple videos by specifying their URLs in the command, separated by spaces like so:"},{"location":"youtube_dl/#download-audio-only-from-a-video","text":"","title":"Download Audio-only from a Video:"},{"location":"youtube_dl/#to-download-a-video-as-audio-ie-extract-audio-from-a-video-use-x-flag-like-below","text":"yt-dlp -x https://www.youtube.com/watch?v=t5b20oLaIaw","title":"To download a video as Audio i.e. extract audio from a video, use -x flag like below."},{"location":"youtube_dl/#you-can-also-specify-the-output-audio-format-using-the-x-audio-format-flag","text":"yt-dlp -x --audio-format mp3 https://www.youtube.com/watch?v=t5b20oLaIaw","title":"You can also specify the output audio format using the -x --audio-format flag."},{"location":"youtube_dl/#to-download-a-video-along-with-its-accompanying-details-including-description-metadata-annotations-subtitles-and-thumbnail-use-the-following-command","text":"yt-dlp --write-description --write-info-json --write-annotations --write-sub --write-thumbnail","title":"To download a video along with its accompanying details, including description, metadata, annotations, subtitles, and thumbnail, use the following command:"},{"location":"youtube_dl/#these-commands-provide-you-with-an-overview-of-the-various-formats-in-which-the-content-is-accessible-assisting-you-in-making-an-informed-selection","text":"","title":"These commands provide you with an overview of the various formats in which the content is accessible, assisting you in making an informed selection."},{"location":"youtube_dl/#to-view-a-comprehensive-list-of-all-the-available-formats-for-a-video-or-playlist-utilize-the-following-command","text":"yt-dlp --list-formats https://www.youtube.com/watch?v=t5b20oLaIaw Alternatively, you can achieve the same result with -F flag: yt-dlp -F https://www.youtube.com/watch?v=t5b20oLaIaw As you see from the output, yt-dlp presents a comprehensive display of all the accessible video formats in an organized tabular column. Moving from left to right, this display includes essential details such as ID, Extension (EXT), Resolution, Frames Per Second (FPS), Channel (CH), Filesize, Total Bitrate (TBR), Protocol (PROTO), Video Codec (VCODEC), Video Bitrate (VBR), Audio Codec (ACODEC), Audio Bitrate (ABR), Audio Sampling Rate (ASR), and additional information.","title":"To view a comprehensive list of all the available formats for a video or playlist, utilize the following command:"},{"location":"youtube_dl/#download-vidoes-by-id-or-video-format","text":"By ID: yt-dlp -f 247 https://www.youtube.com/watch?v=t5b20oLaIaw using -f 22/17/18 means it will attempt to download format 22 if available, then format 17 if format 22 is not available, and so on. By Format: To download video(s) in your preferred format, such as MP4, simply execute the following command: yt-dlp -f mp4 https://www.youtube.com/watch?v=t5b20oLaIaw yt-dlp -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best' https://www.youtube.com/watch?v=t5b20oLaIaw yt-dlp -f mp4 -o '%(title)s.f%(format_id)s.%(ext)s' https://www.youtube.com/watch?v=t5b20oLaIaw Source:","title":"Download vidoes by ID or video format:"}]}